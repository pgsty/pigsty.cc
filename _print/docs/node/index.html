<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-cn class=no-js data-theme-init><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=color-scheme content="light dark"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#000000"><style>html{background:Canvas;color:CanvasText}@media(prefers-color-scheme:dark){html{background:#0b0d12;color:#e6e6e6}}html[data-theme-init] *{transition:none!important}</style><script>(function(){const t="td-color-theme",n=localStorage.getItem(t);let e=n||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");e==="auto"&&(e=window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-bs-theme",e)})()</script><link rel=canonical type=text/html href=https://pigsty.cc/docs/node/><link rel=alternate type=application/rss+xml href=https://pigsty.cc/docs/node/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>模块：NODE | PIGSTY</title><meta name=description content="配置目标服务器，纳管主机节点，并将其调整至描述的状态。也包括节点上的 VIP，HAProxy 以及监控组件。"><meta property="og:url" content="https://pigsty.cc/docs/node/"><meta property="og:site_name" content="PIGSTY"><meta property="og:title" content="模块：NODE"><meta property="og:description" content="配置目标服务器，纳管主机节点，并将其调整至描述的状态。也包括节点上的 VIP，HAProxy 以及监控组件。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="website"><meta itemprop=name content="模块：NODE"><meta itemprop=description content="配置目标服务器，纳管主机节点，并将其调整至描述的状态。也包括节点上的 VIP，HAProxy 以及监控组件。"><meta itemprop=dateModified content="2026-02-05T14:43:56+08:00"><meta itemprop=wordCount content="3"><meta itemprop=keywords content="参考"><meta name=twitter:card content="summary"><meta name=twitter:title content="模块：NODE"><meta name=twitter:description content="配置目标服务器，纳管主机节点，并将其调整至描述的状态。也包括节点上的 VIP，HAProxy 以及监控组件。"><link rel=preload href=/scss/main.min.3858138289ee11ec3386acfac6cdb648f958d81bdf477441fa83b86e29a55a1b.css as=style integrity="sha256-OFgTgonuEewzhqz6xs22SPlY2BvfR3RB+oO4bimlWhs=" crossorigin=anonymous><link href=/scss/main.min.3858138289ee11ec3386acfac6cdb648f958d81bdf477441fa83b86e29a55a1b.css rel=stylesheet integrity="sha256-OFgTgonuEewzhqz6xs22SPlY2BvfR3RB+oO4bimlWhs=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-LG1V9WTKGE"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LG1V9WTKGE")}</script></head><body class=td-section><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="td-navbar-container container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"><svg viewBox="0 0 24 24" width="24" height="24"><defs/><g id="32" fill="none" stroke-dasharray="none" fill-opacity="1" stroke-opacity="1" stroke="none"><title>32</title><g id="32_图层_2"><title>图层 2</title><g id="Group_17"><g id="Graphic_16"/><g id="Graphic_15"><path d="M7.666187 11.971335l2.165064-3.75H14.16138l2.165065 3.75-2.165065 3.75H9.831251z" fill="#bbb" fill-opacity=".9526367"/><path d="M7.666187 11.971335l2.165064-3.75H14.16138l2.165065 3.75-2.165065 3.75H9.831251z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_14"><path d="M7.666187 19.474806l2.165064-3.75H14.16138l2.165065 3.75-2.165065 3.75H9.831251z" fill="#de372c" fill-opacity=".8545852"/><path d="M7.666187 19.474806l2.165064-3.75H14.16138l2.165065 3.75-2.165065 3.75H9.831251z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_13"><path d="M14.161476 15.751202l2.165064-3.75h4.33013l2.165064 3.75-2.165064 3.75H16.32654z" fill="#424242" fill-opacity=".9016462"/><path d="M14.161476 15.751202l2.165064-3.75h4.33013l2.165064 3.75-2.165064 3.75H16.32654z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_12"><path d="M14.161476 8.226008 16.32654 4.4760076h4.33013L22.821734 8.226008l-2.165064 3.75H16.32654z" fill="#ffa269" fill-opacity=".8975772"/><path d="M14.161476 8.226008 16.32654 4.4760076h4.33013L22.821734 8.226008l-2.165064 3.75H16.32654z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_11"><path d="M7.666187 4.5 9.831251.75H14.16138L16.326445 4.5 14.16138 8.25H9.831251z" fill="#419edb" fill-opacity=".8979957"/><path d="M7.666187 4.5 9.831251.75H14.16138L16.326445 4.5 14.16138 8.25H9.831251z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_10"><path d="M1.1491742 8.226008 3.3142388 4.4760076H7.644368L9.809432 8.226008l-2.165064 3.75H3.3142388z" fill="#2f6793" fill-opacity=".9002511"/><path d="M1.1491742 8.226008 3.3142388 4.4760076H7.644368L9.809432 8.226008l-2.165064 3.75H3.3142388z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_9"><path d="M1.182071 15.741036l2.1650645-3.75h4.330129l2.1650645 3.75-2.1650645 3.75H3.3471355z" fill="#53ac79" fill-opacity=".9"/><path d="M1.182071 15.741036l2.1650645-3.75h4.330129l2.1650645 3.75-2.1650645 3.75H3.3471355z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g></g></g></g></svg></span><span class=navbar-brand__name>PIGSTY</span></a><div class="td-navbar-nav-scroll td-navbar-nav-scroll--indicator" id=main_navbar><div class="scroll-indicator scroll-left"></div><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/docs/><i class='fa-solid fa-book'></i><span>文档</span></a></li><li class=nav-item><a class=nav-link href=/blog/><i class="fas fa-blog"></i><span>博客</span></a></li><li class="nav-item dropdown d-none d-lg-block td-navbar__version-menu"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>版本</a><ul class=dropdown-menu><li><a class=dropdown-item href=https://pigsty.io>Pigsty English Site</a></li><li><a class=dropdown-item href=https://doc.pgsty.com/zh>Pigsty v3.7 文档</a></li><li><a class=dropdown-item href=https://v34.pigsty.cc/zh>Pigsty v3.4 文档</a></li><li><a class=dropdown-item href=https://v27.pigsty.cc>Pigsty v2.7 文档</a></li><li><a class=dropdown-item href=https://v15.pigsty.cc/docs>Pigsty v1.5 文档</a></li></ul></div></li><li class=nav-item><a class=nav-link href=https://pgext.cloud target=_blank rel=noopener><i class='fa-solid fa-puzzle-piece'></i><span>扩展</span></a></li><li class="nav-item td-navbar__light-dark-menu"><div class="td-light-dark-menu dropdown"><svg class="d-none"><symbol id="check2" viewBox="0 0 16 16"><path d="M13.854 3.646a.5.5.0 010 .708l-7 7a.5.5.0 01-.708.0l-3.5-3.5a.5.5.0 11.708-.708L6.5 10.293l6.646-6.647a.5.5.0 01.708.0z"/></symbol><symbol id="circle-half" viewBox="0 0 16 16"><path d="M8 15A7 7 0 108 1v14zm0 1A8 8 0 118 0a8 8 0 010 16z"/></symbol><symbol id="moon-stars-fill" viewBox="0 0 16 16"><path d="M6 .278a.768.768.0 01.08.858 7.208 7.208.0 00-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527.0 1.04-.055 1.533-.16a.787.787.0 01.81.316.733.733.0 01-.031.893A8.349 8.349.0 018.344 16C3.734 16 0 12.286.0 7.71.0 4.266 2.114 1.312 5.124.06A.752.752.0 016 .278z"/><path d="M10.794 3.148a.217.217.0 01.412.0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217.0 010 .412l-1.162.387A1.734 1.734.0 0011.593 7.69l-.387 1.162a.217.217.0 01-.412.0l-.387-1.162A1.734 1.734.0 009.31 6.593l-1.162-.387a.217.217.0 010-.412l1.162-.387a1.734 1.734.0 001.097-1.097l.387-1.162zM13.863.099a.145.145.0 01.274.0l.258.774c.115.346.386.617.732.732l.774.258a.145.145.0 010 .274l-.774.258a1.156 1.156.0 00-.732.732l-.258.774a.145.145.0 01-.274.0l-.258-.774a1.156 1.156.0 00-.732-.732l-.774-.258a.145.145.0 010-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"/></symbol><symbol id="sun-fill" viewBox="0 0 16 16"><path d="M8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 0zm0 13a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 13zm8-5a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2a.5.5.0 01.5.5zM3 8a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2A.5.5.0 013 8zm10.657-5.657a.5.5.0 010 .707l-1.414 1.415a.5.5.0 11-.707-.708l1.414-1.414a.5.5.0 01.707.0zm-9.193 9.193a.5.5.0 010 .707L3.05 13.657a.5.5.0 01-.707-.707l1.414-1.414a.5.5.0 01.707.0zm9.193 2.121a.5.5.0 01-.707.0l-1.414-1.414a.5.5.0 01.707-.707l1.414 1.414a.5.5.0 010 .707zM4.464 4.465a.5.5.0 01-.707.0L2.343 3.05a.5.5.0 11.707-.707l1.414 1.414a.5.5.0 010 .708z"/></symbol></svg>
<button class="btn btn-link nav-link dropdown-toggle d-flex align-items-center" id=bd-theme type=button aria-expanded=false data-bs-toggle=dropdown aria-label="Toggle theme (auto)">
<svg class="bi my-1 theme-icon-active"><use href="#circle-half"/></svg></button><ul class=dropdown-menu aria-labelledby=bd-theme><li><button type=button class="dropdown-item d-flex align-items-center" data-bs-theme-value=light aria-pressed=false>
<svg class="bi me-2 opacity-50"><use href="#sun-fill"/></svg>
Light
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li><li><button type=button class="dropdown-item d-flex align-items-center" data-bs-theme-value=dark aria-pressed=false>
<svg class="bi me-2 opacity-50"><use href="#moon-stars-fill"/></svg>
Dark
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li><li><button type=button class="dropdown-item d-flex align-items-center active" data-bs-theme-value=auto aria-pressed=true>
<svg class="bi me-2 opacity-50"><use href="#circle-half"/></svg>
Auto
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li></ul></div></li><li class=nav-item><a class=nav-link href=# onclick="return switchLang(),!1" title="Switch to English / 切换语言"><i class="fas fa-language"></i></a></li></ul><div class="scroll-indicator scroll-right"></div></div><div class="d-none d-lg-block td-navbar__search"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder=站内搜索…… aria-label=站内搜索…… autocomplete=off data-offline-search-index-json-src=/offline-search-index.83c025000675b1802d158b8a9cff5b2a.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav><script>function switchLang(){var t=window.location.host,e=window.location.pathname+window.location.search+window.location.hash;t.indexOf("pigsty.cc")!==-1?window.location.href="https://pigsty.io"+e:t.indexOf("pigsty.io")!==-1?window.location.href="https://pigsty.cc"+e:window.location.href="https://pigsty.io"+e}</script></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>这是本节的多页打印视图。
<a href=# onclick="return print(),!1">点击此处打印</a>.</p><p><a href=/docs/node/>返回本页常规视图</a>.</p></div><h1 class=title>模块：NODE</h1><div class=lead>配置目标服务器，纳管主机节点，并将其调整至描述的状态。也包括节点上的 VIP，HAProxy 以及监控组件。</div><ul><li>1: <a href=#pg-7d9d56f5e4ad9aceb9988138f1b29161>集群配置</a></li><li>2: <a href=#pg-9bce3100e169915a4d53169df43c90f4>参数列表</a></li><li>3: <a href=#pg-82bbb07e4b385ccd2f29e3417328b1c8>预置剧本</a></li><li>4: <a href=#pg-f85610345b10eb3ebcd5b3f4d040bbb5>管理预案</a></li><li>5: <a href=#pg-09468f551281e08aa947b92b9aa4f1a7>监控告警</a></li><li>6: <a href=#pg-21159d62f30ba4efa931b151d5790100>指标列表</a></li><li>7: <a href=#pg-239230a82e0955081c7a4e1b76e4c445>常见问题</a></li></ul><div class=content><p>配置目标服务器，纳管主机节点，并将其调整至描述的状态。也包括节点上的 VIP，HAProxy 以及监控组件。</p></div></div><div class=td-content style=page-break-before:always><h1 id=pg-7d9d56f5e4ad9aceb9988138f1b29161>1 - 集群配置</h1><div class=lead>根据需求场景选择合适的 Node 部署类型，并对外提供可靠的接入。</div><p>Pigsty 使用 <strong>IP地址</strong> 作为 <strong>节点</strong> 的唯一身份标识，<strong>该IP地址应当是数据库实例监听并对外提供服务的内网IP地址</strong>。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node-test</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>10.10.10.11</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>nodename</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>node-test-1 }</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>10.10.10.12</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>nodename</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>node-test-2 }</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>10.10.10.13</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>nodename</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>node-test-3 }</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>vars</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>node_cluster</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>node-test</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>该IP地址必须是数据库实例监听并对外提供服务的IP地址，但不宜使用公网IP地址。尽管如此，用户并不一定非要通过该IP地址连接至该数据库。例如，通过SSH隧道或跳板机中转的方式间接操作管理目标节点也是可行的。但在标识数据库节点时，首要IPv4地址依然是节点的核心标识符。<strong>这一点非常重要，用户应当在配置时保证这一点</strong>。</p><p>IP地址即配置清单中主机的 <code>inventory_hostname</code>，体现为 <code>&lt;cluster>.hosts</code> 对象中的 <code>key</code>。除此之外，每个节点还有两个额外的身份参数：</p><table class=full-width><thead><tr><th style=text-align:center>名称</th><th style=text-align:center>类型</th><th style=text-align:center>层级</th><th>必要性</th><th>说明</th></tr></thead><tbody><tr><td style=text-align:center><code>inventory_hostname</code></td><td style=text-align:center><code>ip</code></td><td style=text-align:center><strong>-</strong></td><td><strong>必选</strong></td><td><strong>节点IP地址</strong></td></tr><tr><td style=text-align:center><a href=/docs/node/param/#nodename><code>nodename</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><strong>I</strong></td><td>可选</td><td><strong>节点名称</strong></td></tr><tr><td style=text-align:center><a href=/docs/node/param/#node_cluster><code>node_cluster</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><strong>C</strong></td><td>可选</td><td><strong>节点集群名称</strong></td></tr></tbody></table><p><a href=/docs/node/param/#nodename><code>nodename</code></a> 与 <a href=/docs/node/param/#node_cluster><code>node_cluster</code></a> 两个参数是可选的，如果不提供，会使用节点现有的主机名，和固定值 <code>nodes</code> 作为默认值。在 Pigsty 的监控系统中，这两者将会被用作节点的 <strong>集群标识</strong>（<code>cls</code>）与 <strong>实例标识</strong>（<code>ins</code>）。</p><p>对于 <a href=/docs/concept/arch/node#pgsql%E8%8A%82%E7%82%B9><strong>PGSQL节点</strong></a> 来说，因为Pigsty默认采用PG:节点独占1:1部署，因此可以通过 <a href=/docs/node/param/#node_id_from_pg><strong><code>node_id_from_pg</code></strong></a> 参数，将 PostgreSQL 实例的身份参数（<a href=/docs/pgsql/param/#pg_cluster><code>pg_cluster</code></a> 与 <a href=/docs/pgsql/param/#pg_seq><code>pg_seq</code></a>）借用至节点的 <code>ins</code> 与 <code>cls</code> 标签上，从而让数据库与节点的监控指标拥有相同的标签，便于交叉分析。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#8f5902;font-style:italic>#nodename:                # [实例] # 节点实例标识，如缺失则使用现有主机名，可选，无默认值</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_cluster</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>nodes       # [集群]</span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># 节点集群标识，如缺失则使用默认值&#39;nodes&#39;，可选</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>nodename_overwrite</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># 用 nodename 覆盖节点的主机名吗？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>nodename_exchange</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># 在剧本主机之间交换 nodename 吗？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_id_from_pg</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>             </span><span style=color:#8f5902;font-style:italic># 如果可行，是否借用 postgres 身份作为节点身份？</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>您还可以为主机集群配置丰富的功能参数，例如，使用节点集群上的 HAProxy 对外提供负载均衡，暴露服务，或者为集群绑定一个 L2 VIP。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9bce3100e169915a4d53169df43c90f4>2 - 参数列表</h1><div class=lead>NODE 模块提供了 11 组共 85 个配置参数</div><p><a href=/docs/node>NODE</a> 模块负责将主机节点调整到期待的目标状态，并将其纳入 Pigsty 的监控系统中。</p><hr><table class=full-width><thead><tr><th style=text-align:left>参数组</th><th style=text-align:left>功能说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#node_id><code>NODE_ID</code></a></td><td style=text-align:left>NODE_ID 相关参数</td></tr><tr><td style=text-align:left><a href=#node_dns><code>NODE_DNS</code></a></td><td style=text-align:left>NODE_DNS 相关参数</td></tr><tr><td style=text-align:left><a href=#node_package><code>NODE_PACKAGE</code></a></td><td style=text-align:left>NODE_PACKAGE 相关参数</td></tr><tr><td style=text-align:left><a href=#node_tune><code>NODE_TUNE</code></a></td><td style=text-align:left>NODE_TUNE 相关参数</td></tr><tr><td style=text-align:left><a href=#node_sec><code>NODE_SEC</code></a></td><td style=text-align:left>NODE_SEC 安全相关参数</td></tr><tr><td style=text-align:left><a href=#node_admin><code>NODE_ADMIN</code></a></td><td style=text-align:left>NODE_ADMIN 相关参数</td></tr><tr><td style=text-align:left><a href=#node_time><code>NODE_TIME</code></a></td><td style=text-align:left>NODE_TIME 相关参数</td></tr><tr><td style=text-align:left><a href=#node_vip><code>NODE_VIP</code></a></td><td style=text-align:left>NODE_VIP 相关参数</td></tr><tr><td style=text-align:left><a href=#haproxy><code>HAPROXY</code></a></td><td style=text-align:left>HAPROXY 相关参数</td></tr><tr><td style=text-align:left><a href=#node_exporter><code>NODE_EXPORTER</code></a></td><td style=text-align:left>NODE_EXPORTER 相关参数</td></tr><tr><td style=text-align:left><a href=#vector><code>VECTOR</code></a></td><td style=text-align:left>VECTOR 日志收集相关参数</td></tr></tbody></table><hr><h2 id=参数概览>参数概览</h2><p><a href=#node_id><code>NODE_ID</code></a> 参数组用于定义节点的身份标识参数，包括节点名称、集群名称，以及是否从 PostgreSQL 借用身份。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#nodename><code>nodename</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><code>I</code></td><td style=text-align:left>node 实例标识，如缺失则使用主机名，可选</td></tr><tr><td style=text-align:left><a href=#node_cluster><code>node_cluster</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>node 集群标识，如缺失则使用默认值&rsquo;nodes&rsquo;，可选</td></tr><tr><td style=text-align:left><a href=#nodename_overwrite><code>nodename_overwrite</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>用 nodename 覆盖节点的主机名吗？</td></tr><tr><td style=text-align:left><a href=#nodename_exchange><code>nodename_exchange</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在剧本主机之间交换 nodename 吗？</td></tr><tr><td style=text-align:left><a href=#node_id_from_pg><code>node_id_from_pg</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>如果可行，是否借用 postgres 身份作为节点身份？</td></tr></tbody></table><p><a href=#node_dns><code>NODE_DNS</code></a> 参数组用于配置节点的 DNS 解析，包括静态 hosts 记录与动态 DNS 服务器。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#node_write_etc_hosts><code>node_write_etc_hosts</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>G/C/I</code></td><td style=text-align:left>是否修改目标节点上的 <code>/etc/hosts</code>？</td></tr><tr><td style=text-align:left><a href=#node_default_etc_hosts><code>node_default_etc_hosts</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>G</code></td><td style=text-align:left>/etc/hosts 中的静态 DNS 记录</td></tr><tr><td style=text-align:left><a href=#node_etc_hosts><code>node_etc_hosts</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>/etc/hosts 中的额外静态 DNS 记录</td></tr><tr><td style=text-align:left><a href=#node_dns_method><code>node_dns_method</code></a></td><td style=text-align:center><code>enum</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>如何处理现有DNS服务器：add,none,overwrite</td></tr><tr><td style=text-align:left><a href=#node_dns_servers><code>node_dns_servers</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>/etc/resolv.conf 中的动态域名服务器列表</td></tr><tr><td style=text-align:left><a href=#node_dns_options><code>node_dns_options</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>/etc/resolv.conf 中的DNS解析选项</td></tr></tbody></table><p><a href=#node_package><code>NODE_PACKAGE</code></a> 参数组用于配置节点的软件源与软件包安装，以及 uv Python 虚拟环境。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#node_repo_modules><code>node_repo_modules</code></a></td><td style=text-align:center><code>enum</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在节点上启用哪些软件源模块？默认为 local</td></tr><tr><td style=text-align:left><a href=#node_repo_remove><code>node_repo_remove</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>配置节点软件仓库时，删除节点上现有的仓库吗？</td></tr><tr><td style=text-align:left><a href=#node_packages><code>node_packages</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>要在当前节点上安装的软件包列表</td></tr><tr><td style=text-align:left><a href=#node_default_packages><code>node_default_packages</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>G</code></td><td style=text-align:left>默认在所有节点上安装的软件包列表</td></tr><tr><td style=text-align:left><a href=#node_uv_env><code>node_uv_env</code></a></td><td style=text-align:center><code>path</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>uv venv 路径，默认 /data/venv，空则跳过</td></tr><tr><td style=text-align:left><a href=#node_pip_packages><code>node_pip_packages</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在 uv venv 中安装的 pip 包</td></tr></tbody></table><p><a href=#node_tune><code>NODE_TUNE</code></a> 参数组用于配置节点的内核参数、特性开关与性能调优模板。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#node_disable_numa><code>node_disable_numa</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>禁用节点 numa，禁用需要重启</td></tr><tr><td style=text-align:left><a href=#node_disable_swap><code>node_disable_swap</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>禁用节点 Swap，谨慎使用</td></tr><tr><td style=text-align:left><a href=#node_static_network><code>node_static_network</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>重启后保留 DNS 解析器设置，即静态网络，默认启用</td></tr><tr><td style=text-align:left><a href=#node_disk_prefetch><code>node_disk_prefetch</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在 HDD 上配置磁盘预取以提高性能</td></tr><tr><td style=text-align:left><a href=#node_kernel_modules><code>node_kernel_modules</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在此节点上启用的内核模块列表</td></tr><tr><td style=text-align:left><a href=#node_hugepage_count><code>node_hugepage_count</code></a></td><td style=text-align:center><code>int</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>主机节点分配的 2MB 大页数量，优先级比比例更高</td></tr><tr><td style=text-align:left><a href=#node_hugepage_ratio><code>node_hugepage_ratio</code></a></td><td style=text-align:center><code>float</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>主机节点分配的内存大页占总内存比例，0 默认禁用</td></tr><tr><td style=text-align:left><a href=#node_overcommit_ratio><code>node_overcommit_ratio</code></a></td><td style=text-align:center><code>float</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>节点内存允许的 OverCommit 超额比率 (50-100)，0 默认禁用</td></tr><tr><td style=text-align:left><a href=#node_tune><code>node_tune</code></a></td><td style=text-align:center><code>enum</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>节点调优配置文件：无，oltp,olap,crit,tiny</td></tr><tr><td style=text-align:left><a href=#node_sysctl_params><code>node_sysctl_params</code></a></td><td style=text-align:center><code>dict</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>额外的 sysctl 配置参数，k:v 格式</td></tr></tbody></table><p><a href=#node_sec><code>NODE_SEC</code></a> 参数组用于配置节点的安全相关选项，包括 SELinux、防火墙等。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#node_selinux_mode><code>node_selinux_mode</code></a></td><td style=text-align:center><code>enum</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>SELinux 模式：disabled, permissive, enforcing</td></tr><tr><td style=text-align:left><a href=#node_firewall_mode><code>node_firewall_mode</code></a></td><td style=text-align:center><code>enum</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>防火墙模式：zone（默认启用）, off（关闭）, none（自管）</td></tr><tr><td style=text-align:left><a href=#node_firewall_intranet><code>node_firewall_intranet</code></a></td><td style=text-align:center><code>cidr[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>内网 CIDR 列表，用于配置防火墙规则</td></tr><tr><td style=text-align:left><a href=#node_firewall_public_port><code>node_firewall_public_port</code></a></td><td style=text-align:center><code>port[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>公网开放端口列表，默认为 [22, 80, 443]</td></tr></tbody></table><p><a href=#node_admin><code>NODE_ADMIN</code></a> 参数组用于配置节点的管理员用户、数据目录与命令别名。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#node_data><code>node_data</code></a></td><td style=text-align:center><code>path</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>节点主数据目录，默认为 <code>/data</code></td></tr><tr><td style=text-align:left><a href=#node_admin_enabled><code>node_admin_enabled</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在目标节点上创建管理员用户吗？</td></tr><tr><td style=text-align:left><a href=#node_admin_uid><code>node_admin_uid</code></a></td><td style=text-align:center><code>int</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>节点管理员用户的 uid 和 gid</td></tr><tr><td style=text-align:left><a href=#node_admin_username><code>node_admin_username</code></a></td><td style=text-align:center><code>username</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>节点管理员用户的名称，默认为 <code>dba</code></td></tr><tr><td style=text-align:left><a href=#node_admin_sudo><code>node_admin_sudo</code></a></td><td style=text-align:center><code>enum</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>管理员用户的 sudo 权限：nopass, all, limit</td></tr><tr><td style=text-align:left><a href=#node_admin_ssh_exchange><code>node_admin_ssh_exchange</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>是否在节点集群之间交换管理员 ssh 密钥</td></tr><tr><td style=text-align:left><a href=#node_admin_pk_current><code>node_admin_pk_current</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>将当前用户的 ssh 公钥添加到管理员的 authorized_keys 中吗？</td></tr><tr><td style=text-align:left><a href=#node_admin_pk_list><code>node_admin_pk_list</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>要添加到管理员用户的 ssh 公钥</td></tr><tr><td style=text-align:left><a href=#node_aliases><code>node_aliases</code></a></td><td style=text-align:center><code>dict</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>配置主机上的 Shell Alias 命令，KV字典</td></tr></tbody></table><p><a href=#node_time><code>NODE_TIME</code></a> 参数组用于配置节点的时区、NTP 时间同步与定时任务。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#node_timezone><code>node_timezone</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>设置主机节点时区，空字符串跳过</td></tr><tr><td style=text-align:left><a href=#node_ntp_enabled><code>node_ntp_enabled</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>启用 chronyd 时间同步服务吗？</td></tr><tr><td style=text-align:left><a href=#node_ntp_servers><code>node_ntp_servers</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>/etc/chrony.conf 中的 ntp 服务器列表</td></tr><tr><td style=text-align:left><a href=#node_crontab_overwrite><code>node_crontab_overwrite</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>写入 /etc/crontab 时，追加写入还是全部覆盖？</td></tr><tr><td style=text-align:left><a href=#node_crontab><code>node_crontab</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在 /etc/crontab 中的 crontab 条目</td></tr></tbody></table><p><a href=#node_vip><code>NODE_VIP</code></a> 参数组用于配置节点集群的 L2 VIP，由 keepalived 实现。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#vip_enabled><code>vip_enabled</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在此节点集群上启用 L2 vip 吗？</td></tr><tr><td style=text-align:left><a href=#vip_address><code>vip_address</code></a></td><td style=text-align:center><code>ip</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>节点 vip 地址的 ipv4 格式，启用 vip 时为必要参数</td></tr><tr><td style=text-align:left><a href=#vip_vrid><code>vip_vrid</code></a></td><td style=text-align:center><code>int</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>所需的整数，1-254，在同一 VLAN 中应唯一</td></tr><tr><td style=text-align:left><a href=#vip_role><code>vip_role</code></a></td><td style=text-align:center><code>enum</code></td><td style=text-align:center><code>I</code></td><td style=text-align:left>可选，master/backup，默认为 backup</td></tr><tr><td style=text-align:left><a href=#vip_preempt><code>vip_preempt</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C/I</code></td><td style=text-align:left>可选，true/false，默认为 false，启用 vip 抢占</td></tr><tr><td style=text-align:left><a href=#vip_interface><code>vip_interface</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><code>C/I</code></td><td style=text-align:left>节点 vip 网络接口监听，默认为 eth0</td></tr><tr><td style=text-align:left><a href=#vip_dns_suffix><code>vip_dns_suffix</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>节点 vip DNS 名称后缀，默认为空字符串</td></tr><tr><td style=text-align:left><a href=#vip_auth_pass><code>vip_auth_pass</code></a></td><td style=text-align:center><code>password</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>VRRP 认证密码，空则使用 <code>&lt;cls>-&lt;vrid></code> 作为默认值</td></tr><tr><td style=text-align:left><a href=#vip_exporter_port><code>vip_exporter_port</code></a></td><td style=text-align:center><code>port</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>keepalived exporter 监听端口，默认为 9650</td></tr></tbody></table><p><a href=#haproxy><code>HAPROXY</code></a> 参数组用于配置节点上的 HAProxy 负载均衡器与服务暴露。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#haproxy_enabled><code>haproxy_enabled</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在此节点上启用 haproxy 吗？</td></tr><tr><td style=text-align:left><a href=#haproxy_clean><code>haproxy_clean</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>G/C/A</code></td><td style=text-align:left>清除所有现有的 haproxy 配置吗？</td></tr><tr><td style=text-align:left><a href=#haproxy_reload><code>haproxy_reload</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>A</code></td><td style=text-align:left>配置后重新加载 haproxy 吗？</td></tr><tr><td style=text-align:left><a href=#haproxy_auth_enabled><code>haproxy_auth_enabled</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>G</code></td><td style=text-align:left>启用 haproxy 管理页面的身份验证？</td></tr><tr><td style=text-align:left><a href=#haproxy_admin_username><code>haproxy_admin_username</code></a></td><td style=text-align:center><code>username</code></td><td style=text-align:center><code>G</code></td><td style=text-align:left>haproxy 管理用户名，默认为 <code>admin</code></td></tr><tr><td style=text-align:left><a href=#haproxy_admin_password><code>haproxy_admin_password</code></a></td><td style=text-align:center><code>password</code></td><td style=text-align:center><code>G</code></td><td style=text-align:left>haproxy 管理密码，默认为 <code>pigsty</code></td></tr><tr><td style=text-align:left><a href=#haproxy_exporter_port><code>haproxy_exporter_port</code></a></td><td style=text-align:center><code>port</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>haproxy exporter 的端口，默认为 9101</td></tr><tr><td style=text-align:left><a href=#haproxy_client_timeout><code>haproxy_client_timeout</code></a></td><td style=text-align:center><code>interval</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>haproxy 客户端连接超时，默认为 24h</td></tr><tr><td style=text-align:left><a href=#haproxy_server_timeout><code>haproxy_server_timeout</code></a></td><td style=text-align:center><code>interval</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>haproxy 服务器端连接超时，默认为 24h</td></tr><tr><td style=text-align:left><a href=#haproxy_services><code>haproxy_services</code></a></td><td style=text-align:center><code>service[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>要在节点上对外暴露的 haproxy 服务列表</td></tr></tbody></table><p><a href=#node_exporter><code>NODE_EXPORTER</code></a> 参数组用于配置节点监控 Exporter。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#node_exporter_enabled><code>node_exporter_enabled</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>在此节点上配置 node_exporter 吗？</td></tr><tr><td style=text-align:left><a href=#node_exporter_port><code>node_exporter_port</code></a></td><td style=text-align:center><code>port</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>node exporter 监听端口，默认为 9100</td></tr><tr><td style=text-align:left><a href=#node_exporter_options><code>node_exporter_options</code></a></td><td style=text-align:center><code>arg</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>node_exporter 的额外服务器选项</td></tr></tbody></table><p><a href=#vector><code>VECTOR</code></a> 参数组用于配置 Vector 日志收集器。</p><table class=full-width><thead><tr><th style=text-align:left>参数</th><th style=text-align:center>类型</th><th style=text-align:center>级别</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><a href=#vector_enabled><code>vector_enabled</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>启用 vector 日志收集器吗？</td></tr><tr><td style=text-align:left><a href=#vector_clean><code>vector_clean</code></a></td><td style=text-align:center><code>bool</code></td><td style=text-align:center><code>G/A</code></td><td style=text-align:left>初始化期间清除 vector 数据目录吗？</td></tr><tr><td style=text-align:left><a href=#vector_data><code>vector_data</code></a></td><td style=text-align:center><code>path</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>vector 数据目录，默认为 /data/vector</td></tr><tr><td style=text-align:left><a href=#vector_port><code>vector_port</code></a></td><td style=text-align:center><code>port</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>vector 指标监听端口，默认为 9598</td></tr><tr><td style=text-align:left><a href=#vector_read_from><code>vector_read_from</code></a></td><td style=text-align:center><code>enum</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>vector 从头还是从尾开始读取日志</td></tr><tr><td style=text-align:left><a href=#vector_log_endpoint><code>vector_log_endpoint</code></a></td><td style=text-align:center><code>string[]</code></td><td style=text-align:center><code>C</code></td><td style=text-align:left>日志发送目标端点，默认发送至 infra 组</td></tr></tbody></table><hr><h2 id=node_id><code>NODE_ID</code></h2><p>每个节点都有<strong>身份参数</strong>，通过在<code>&lt;cluster>.hosts</code>与<code>&lt;cluster>.vars</code>中的相关参数进行配置。</p><p>Pigsty使用<strong>IP地址</strong>作为<strong>数据库节点</strong>的唯一标识，<strong>该IP地址必须是数据库实例监听并对外提供服务的IP地址</strong>，但不宜使用公网IP地址。
尽管如此，用户并不一定非要通过该IP地址连接至该数据库。例如，通过SSH隧道或跳板机中转的方式间接操作管理目标节点也是可行的。
但在标识数据库节点时，首要IPv4地址依然是节点的核心标识符。<strong>这一点非常重要，用户应当在配置时保证这一点</strong>。
IP地址即配置清单中主机的<code>inventory_hostname</code> ，体现为<code>&lt;cluster>.hosts</code>对象中的<code>key</code>。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node-test</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>10.10.10.11</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>nodename</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>node-test-1 }</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>10.10.10.12</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>nodename</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>node-test-2 }</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>10.10.10.13</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>nodename</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>node-test-3 }</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>vars</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>node_cluster</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>node-test</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>除此之外，在Pigsty监控系统中，节点还有两个重要的身份参数：<a href=#nodename><code>nodename</code></a> 与 <a href=#node_cluster><code>node_cluster</code></a>，这两者将在监控系统中被用作节点的 <strong>实例标识</strong>（<code>ins</code>） 与 <strong>集群标识</strong> （<code>cls</code>）。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#000>node_load1{cls=&#34;pg-meta&#34;, ins=&#34;pg-meta-1&#34;, ip=&#34;10.10.10.10&#34;, job=&#34;nodes&#34;}</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#000>node_load1{cls=&#34;pg-test&#34;, ins=&#34;pg-test-1&#34;, ip=&#34;10.10.10.11&#34;, job=&#34;nodes&#34;}</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#000>node_load1{cls=&#34;pg-test&#34;, ins=&#34;pg-test-2&#34;, ip=&#34;10.10.10.12&#34;, job=&#34;nodes&#34;}</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#000>node_load1{cls=&#34;pg-test&#34;, ins=&#34;pg-test-3&#34;, ip=&#34;10.10.10.13&#34;, job=&#34;nodes&#34;}</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>在执行默认的PostgreSQL部署时，因为Pigsty默认采用节点独占1:1部署，因此可以通过 <a href=#node_id_from_pg><code>node_id_from_pg</code></a> 参数，将数据库实例的身份参数（ <a href=/docs/pgsql/param#pg_cluster><code>pg_cluster</code></a> 借用至节点的<code>ins</code>与<code>cls</code>标签上。</p><table class=full-width><thead><tr><th style=text-align:center>名称</th><th style=text-align:center>类型</th><th style=text-align:center>层级</th><th>必要性</th><th>说明</th></tr></thead><tbody><tr><td style=text-align:center><code>inventory_hostname</code></td><td style=text-align:center><code>ip</code></td><td style=text-align:center><strong>-</strong></td><td><strong>必选</strong></td><td><strong>节点IP地址</strong></td></tr><tr><td style=text-align:center><a href=#nodename><code>nodename</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><strong>I</strong></td><td>可选</td><td><strong>节点名称</strong></td></tr><tr><td style=text-align:center><a href=#node_cluster><code>node_cluster</code></a></td><td style=text-align:center><code>string</code></td><td style=text-align:center><strong>C</strong></td><td>可选</td><td><strong>节点集群名称</strong></td></tr></tbody></table><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#8f5902;font-style:italic>#nodename:                # [实例] # 节点实例标识，如缺失则使用现有主机名，可选，无默认值</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_cluster</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>nodes       # [集群]</span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># 节点集群标识，如缺失则使用默认值&#39;nodes&#39;，可选</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>nodename_overwrite</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># 用 nodename 覆盖节点的主机名吗？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>nodename_exchange</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># 在剧本主机之间交换 nodename 吗？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_id_from_pg</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>             </span><span style=color:#8f5902;font-style:italic># 如果可行，是否借用 postgres 身份作为节点身份？</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=nodename><code>nodename</code></h3><p>参数名称： <code>nodename</code>， 类型： <code>string</code>， 层次：<code>I</code></p><p>主机节点的身份参数，如果没有显式设置，则会使用现有的主机 Hostname 作为节点名。本参数虽然是身份参数，但因为有合理默认值，所以是可选项。</p><p>如果启用了 <a href=#node_id_from_pg><code>node_id_from_pg</code></a> 选项（默认启用），且 <code>nodename</code> 没有被显式指定，
那么 <a href=#nodename><code>nodename</code></a> 会尝试使用 <code>${pg_cluster}-${pg_seq}</code> 作为实例身份参数，如果集群没有定义 PGSQL 模块，那么会回归到默认值，也就是主机节点的 HOSTNAME。</p><h3 id=node_cluster><code>node_cluster</code></h3><p>参数名称： <code>node_cluster</code>， 类型： <code>string</code>， 层次：<code>C</code></p><p>该选项可为节点显式指定一个集群名称，通常在节点集群层次定义才有意义。使用默认空值将直接使用固定值<code>nodes</code>作为节点集群标识。</p><p>如果启用了 <a href=#node_id_from_pg><code>node_id_from_pg</code></a> 选项（默认启用），且 <code>node_cluster</code> 没有被显式指定，那么 <a href=#node_cluster><code>node_cluster</code></a> 会尝试使用 <code>${pg_cluster}</code> 作为集群身份参数，如果集群没有定义 PGSQL 模块，那么会回归到默认值 <code>nodes</code>。</p><h3 id=nodename_overwrite><code>nodename_overwrite</code></h3><p>参数名称： <code>nodename_overwrite</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否使用 <a href=#nodename><code>nodename</code></a> 覆盖主机名？默认值为 <code>true</code>，在这种情况下，如果你设置了一个非空的 <a href=#nodename><code>nodename</code></a> ，那么它会被用作当前主机的 HOSTNAME 。</p><p>当 <code>nodename</code> 配置为空时，如果 <a href=#node_id_from_pg><code>node_id_from_pg</code></a> 参数被配置为 <code>true</code> （默认为真），那么 Pigsty 会尝试借用1:1定义在节点上的 PostgreSQL 实例的身份参数作为主机的节点名。
也就是 <code>{{ pg_cluster }}-{{ pg_seq }}</code>，如果该节点没有安装 PGSQL 模块，则会回归到默认什么都不做的状态。</p><p>因此，如果您将 <a href=#nodename><code>nodename</code></a> 留空，并且没有启用 <a href=#node_id_from_pg><code>node_id_from_pg</code></a> 参数时，Pigsty不会对现有主机名进行任何修改。</p><h3 id=nodename_exchange><code>nodename_exchange</code></h3><p>参数名称： <code>nodename_exchange</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否在剧本节点间交换主机名？默认值为：<code>false</code></p><p>启用此参数时，同一批组执行 <a href=/docs/node/playbook#nodeyml><strong><code>node.yml</code></strong></a> 剧本的节点之间会相互交换节点名称，写入<code>/etc/hosts</code>中。</p><h3 id=node_id_from_pg><code>node_id_from_pg</code></h3><p>参数名称： <code>node_id_from_pg</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>从节点上 1:1 部署的 PostgreSQL 实例/集群上借用身份参数？ 默认值为 <code>true</code>。</p><p>Pigsty 中的 PostgreSQL 实例与节点默认使用 1:1 部署，因此，您可以从数据库实例上“借用” 身份参数。
此参数默认启用，这意味着一套 PostgreSQL 集群如果没有特殊配置，主机节点集群和实例的身份参数默认值是与数据库身份参数保持一致的。对于问题分析，监控数据处理都提供了额外便利。</p><hr><h2 id=node_dns><code>NODE_DNS</code></h2><p>Pigsty会为节点配置静态DNS解析记录与动态DNS服务器。</p><p>如果您的节点供应商已经为您配置了DNS服务器，您可以将 <a href=#node_dns_method><code>node_dns_method</code></a> 设置为 <code>none</code> 跳过DNS设置。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_write_etc_hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>        </span><span style=color:#8f5902;font-style:italic># modify `/etc/hosts` on target node?</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_default_etc_hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>           </span><span style=color:#8f5902;font-style:italic># static dns records in `/etc/hosts`</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#4e9a06>&#34;${admin_ip} i.pigsty&#34;</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_etc_hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[]</span><span style=color:#f8f8f8>                </span><span style=color:#8f5902;font-style:italic># extra static dns records in `/etc/hosts`</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_dns_method: add              # how to handle dns servers</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>add,none,overwrite</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_dns_servers</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#4e9a06>&#39;${admin_ip}&#39;</span><span style=color:#000;font-weight:700>]</span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># dynamic nameserver in `/etc/resolv.conf`</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_dns_options</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>                 </span><span style=color:#8f5902;font-style:italic># dns resolv options in `/etc/resolv.conf`</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#000>options single-request-reopen timeout:1</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=node_write_etc_hosts>node_write_etc_hosts</h3><p>参数名称： <code>node_write_etc_hosts</code>， 类型： <code>bool</code>， 层次：<code>G|C|I</code></p><p>是否修改目标节点上的 <code>/etc/hosts</code>？例如，在容器环境中通常不允许修改此配置文件。</p><h3 id=node_default_etc_hosts><code>node_default_etc_hosts</code></h3><p>参数名称： <code>node_default_etc_hosts</code>， 类型： <code>string[]</code>， 层次：<code>G</code></p><p>默认写入所有节点 <code>/etc/hosts</code> 的静态DNS记录，默认值为：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#000;font-weight:700>[</span><span style=color:#4e9a06>&#34;${admin_ip} i.pigsty&#34;</span><span style=color:#000;font-weight:700>]</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p><a href=#node_default_etc_hosts><code>node_default_etc_hosts</code></a> 是一个数组，每个元素都是一条 DNS 记录，格式为 <code>&lt;ip> &lt;name></code>，您可以指定多个用空格分隔的域名。</p><p>这个参数是用于配置全局静态DNS解析记录的，如果您希望为单个集群与实例配置特定的静态DNS解析，则可以使用 <a href=#node_etc_hosts><code>node_etc_hosts</code></a> 参数。</p><h3 id=node_etc_hosts><code>node_etc_hosts</code></h3><p>参数名称： <code>node_etc_hosts</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p>写入节点 <code>/etc/hosts</code> 的额外的静态DNS记录，默认值为：<code>[]</code> 空数组。</p><p>本参数与 <a href=#node_default_etc_hosts><code>node_default_etc_hosts</code></a>，形式一样，但用途不同：适合在集群/实例层面进行配置。</p><h3 id=node_dns_method><code>node_dns_method</code></h3><p>参数名称： <code>node_dns_method</code>， 类型： <code>enum</code>， 层次：<code>C</code></p><p>如何配置DNS服务器？有三种选项：<code>add</code>、<code>none</code>、<code>overwrite</code>，默认值为 <code>add</code>。</p><ul><li><code>add</code>：将 <a href=#node_dns_servers><code>node_dns_servers</code></a> 中的记录<strong>追加</strong>至<code>/etc/resolv.conf</code>，并保留已有DNS服务器。（默认）</li><li><code>overwrite</code>：使用将 <a href=#node_dns_servers><code>node_dns_servers</code></a> 中的记录覆盖<code>/etc/resolv.conf</code></li><li><code>none</code>：跳过DNS服务器配置，如果您的环境中已经配置有DNS服务器，则可以直接跳过DNS配置。</li></ul><h3 id=node_dns_servers><code>node_dns_servers</code></h3><p>参数名称： <code>node_dns_servers</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p>配置 <code>/etc/resolv.conf</code> 中的动态DNS服务器列表：默认值为： <code>["${admin_ip}"]</code>，即将管理节点作为首要DNS服务器。</p><h3 id=node_dns_options><code>node_dns_options</code></h3><p>参数名称： <code>node_dns_options</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p><code>/etc/resolv.conf</code> 中的DNS解析选项，默认值为：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>- <span style=color:#4e9a06>&#34;options single-request-reopen timeout:1&#34;</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>如果 <a href=#node_dns_method><code>node_dns_method</code></a> 配置为<code>add</code>或<code>overwrite</code>，则本配置项中的记录会被首先写入<code>/etc/resolv.conf</code> 中。具体格式请参考Linux文档关于<code>/etc/resolv.conf</code>的说明</p><hr><h2 id=node_package><code>NODE_PACKAGE</code></h2><p>Pigsty会为纳入管理的节点配置Yum源，并安装软件包，以及配置 uv Python 虚拟环境。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_repo_modules</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>local         </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># upstream repo to be added on node, local by default.</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_repo_remove</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>            </span><span style=color:#8f5902;font-style:italic># remove existing repo on node?</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_packages</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#000>openssh-server]  </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># packages to be installed current nodes with latest version</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>#node_default_packages:           # default packages to be installed on all nodes</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_uv_env</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>/data/venv          </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># uv venv path, /data/venv by default, empty to skip</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_pip_packages</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#39;&#39;</span><span style=color:#f8f8f8>             </span><span style=color:#8f5902;font-style:italic># pip packages to be installed in uv venv</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=node_repo_modules><code>node_repo_modules</code></h3><p>参数名称： <code>node_repo_modules</code>， 类型： <code>string</code>， 层次：<code>C/A</code></p><p>需要在节点上添加的软件源模块列表，形式同 <a href=/docs/infra/param#repo_modules><code>repo_modules</code></a>。默认值为 <code>local</code>，即使用 <a href=/docs/infra/param#repo_upstream><code>repo_upstream</code></a> 中 <code>local</code> 所指定的本地软件源。</p><p>当 Pigsty 纳管节点时，会根据此参数的值来过滤 <a href=/docs/infra/param#repo_upstream><code>repo_upstream</code></a> 中的条目，只有 <code>module</code> 字段与此参数值匹配的条目才会被添加到节点的软件源中。</p><h3 id=node_repo_remove><code>node_repo_remove</code></h3><p>参数名称： <code>node_repo_remove</code>， 类型： <code>bool</code>， 层次：<code>C/A</code></p><p>是否移除节点已有的软件仓库定义？默认值为：<code>true</code>。</p><p>如果启用，则Pigsty会 <strong>移除</strong> 节点上<code>/etc/yum.repos.d</code>中原有的配置文件，并备份至<code>/etc/yum.repos.d/backup</code>。
在 Debian/Ubuntu 系统上，则是 <code>/etc/apt/sources.list(.d)</code> 备份至 <code>/etc/apt/backup</code>。</p><h3 id=node_packages><code>node_packages</code></h3><p>参数名称： <code>node_packages</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p>在当前节点上要安装并升级的软件包列表，默认值为：<code>[openssh-server]</code> ，即在安装时会将 sshd 升级到最新版本（避免安全漏洞）。</p><p>每一个数组元素都是字符串：由逗号分隔的软件包名称。形式上与 <a href=#node_default_packages><code>node_packages_default</code></a> 相同。本参数通常用于在节点/集群层面指定需要额外安装的软件包。</p><p>在本参数中指定的软件包，会 <strong>升级到可用的最新版本</strong>，如果您需要保持现有节点软件版本不变（存在即可），请使用 <a href=#node_default_packages><code>node_default_packages</code></a> 参数。</p><h3 id=node_default_packages><code>node_default_packages</code></h3><p>参数名称： <code>node_default_packages</code>， 类型： <code>string[]</code>， 层次：<code>G</code></p><p>默认在所有节点上安装的软件包，默认值为一组按操作系统族区分的软件包列表（字符串数组，每个元素为逗号分隔的包名）：</p><p>字符串数组类型，每一行都是 <strong>由逗号分隔</strong> 的软件包列表字符串，指定默认在所有节点上安装的软件包列表。</p><p>在此变量中指定的软件包，只要求 <strong>存在</strong>，而不要求 <strong>最新</strong>。如果您需要安装最新版本的软件包，请使用 <a href=#node_packages><code>node_packages</code></a> 参数。</p><p>本参数没有默认值，即默认值为未定义状态。如果用户不在配置文件中显式指定本参数，则 Pigsty 会从根据当前节点的操作系统族，从定义于 <a href=https://github.com/pgsty/pigsty/blob/main/roles/node_id/vars/><code>roles/node_id/vars</code></a> 中的 <code>node_packages_default</code> 变量中加载获取默认值。</p><p>默认值（EL系操作系统）：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>- <span style=color:#000>lz4,unzip,bzip2,pv,jq,git,ncdu,make,patch,bash,lsof,wget,tuned,nvme-cli,numactl,sysstat,iotop,htop,rsync,tcpdump</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span>- <span style=color:#000>python3,socat,net-tools,ipvsadm,telnet,ca-certificates,openssl,keepalived,etcd,haproxy,chrony,cronie,pig,uv</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span>- <span style=color:#000>zlib,yum,audit,bind-utils,readline,vim-minimal,node_exporter,grubby,openssh-server,openssh-clients,chkconfig,vector</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>默认值（Debian/Ubuntu）：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>- <span style=color:#000>lz4,unzip,bzip2,pv,jq,git,ncdu,make,patch,bash,lsof,wget,tuned,nvme-cli,numactl,sysstat,iotop,htop,rsync,tcpdump</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span>- <span style=color:#000>python3,socat,net-tools,ipvsadm,telnet,ca-certificates,openssl,keepalived,etcd,haproxy,chrony,cron,pig,uv</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span>- <span style=color:#000>zlib1g,acl,dnsutils,libreadline-dev,vim-tiny,node-exporter,openssh-server,openssh-client,vector</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>本参数形式上与 <a href=#node_packages><code>node_packages</code></a> 相同，但本参数通常用于全局层面指定所有节点都必须安装的默认软件包</p><h3 id=node_uv_env><code>node_uv_env</code></h3><p>参数名称： <code>node_uv_env</code>， 类型： <code>path</code>， 层次：<code>C</code></p><p>uv 虚拟环境路径，默认值为：<code>/data/venv</code>。设置为空字符串 <code>''</code> 则跳过 uv 虚拟环境的配置。</p><p>当此参数非空时，Pigsty 会在节点上使用 <code>uv venv</code> 命令创建 Python 虚拟环境，并根据 <a href=#node_pip_packages><code>node_pip_packages</code></a> 安装指定的 pip 包。</p><p>在中国区域（<code>region: china</code>）时，会自动配置 <code>/etc/uv/uv.toml</code> 使用阿里云 PyPI 镜像加速下载。</p><h3 id=node_pip_packages><code>node_pip_packages</code></h3><p>参数名称： <code>node_pip_packages</code>， 类型： <code>string</code>， 层次：<code>C</code></p><p>在 uv 虚拟环境中安装的 pip 包列表，默认值为：空字符串 <code>''</code>。</p><p>使用空格分隔多个包名，例如：<code>'ansible pgcli requests pandas'</code>。</p><p>仅当 <a href=#node_uv_env><code>node_uv_env</code></a> 非空时此参数才会生效。</p><hr><h2 id=node_tune><code>NODE_TUNE</code></h2><p>主机节点特性、内核模块与参数调优模板。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_disable_numa</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># disable node numa, reboot required</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_disable_swap</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># disable node swap, use with caution</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_static_network</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>         </span><span style=color:#8f5902;font-style:italic># preserve dns resolver settings after reboot</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_disk_prefetch</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>         </span><span style=color:#8f5902;font-style:italic># setup disk prefetch on HDD to increase performance</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_kernel_modules</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#f8f8f8> </span><span style=color:#000>softdog, ip_vs, ip_vs_rr, ip_vs_wrr, ip_vs_sh ]</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_hugepage_count</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#f8f8f8>            </span><span style=color:#8f5902;font-style:italic># number of 2MB hugepage, take precedence over ratio</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_hugepage_ratio</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#f8f8f8>            </span><span style=color:#8f5902;font-style:italic># node mem hugepage ratio, 0 disable it by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_overcommit_ratio</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># node mem overcommit ratio, 0 disable it by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_tune: oltp                   # node tuned profile</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>none,oltp,olap,crit,tiny</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_sysctl_params</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>               </span><span style=color:#8f5902;font-style:italic># sysctl parameters in k:v format in addition to tuned</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>fs.nr_open</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>8388608</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=node_disable_numa><code>node_disable_numa</code></h3><p>参数名称： <code>node_disable_numa</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否关闭NUMA？默认不关闭NUMA：<code>false</code>。</p><p>注意，关闭NUMA需要重启机器后方可生效！如果您不清楚如何绑核，在生产环境使用数据库时建议关闭 NUMA。</p><h3 id=node_disable_swap><code>node_disable_swap</code></h3><p>参数名称： <code>node_disable_swap</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否关闭 SWAP ？ 默认不关闭SWAP：<code>false</code>。</p><p>通常情况下不建议关闭 SWAP，例外情况是如果您有足够的内存用于独占式 PostgreSQL 部署，则可以关闭 SWAP 提高性能。</p><p>例外：当您的节点用于部署 Kubernetes 模块时，应当禁用SWAP。</p><h3 id=node_static_network><code>node_static_network</code></h3><p>参数名称： <code>node_static_network</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否使用静态DNS服务器, 类型：<code>bool</code>，层级：C，默认值为：<code>true</code>，默认启用。</p><p>启用静态网络，意味着您的DNS Resolv配置不会因为机器重启与网卡变动被覆盖，建议启用，或由网络工程师负责配置。</p><h3 id=node_disk_prefetch><code>node_disk_prefetch</code></h3><p>参数名称： <code>node_disk_prefetch</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否启用磁盘预读？默认不启用：<code>false</code>。</p><p>针对HDD部署的实例可以优化性能，使用机械硬盘时建议启用。</p><h3 id=node_kernel_modules><code>node_kernel_modules</code></h3><p>参数名称： <code>node_kernel_modules</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p>启用哪些内核模块？默认启用以下内核模块：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_kernel_modules</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#f8f8f8> </span><span style=color:#000>softdog, ip_vs, ip_vs_rr, ip_vs_wrr, ip_vs_sh ]</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>形式上是由内核模块名称组成的数组，声明了需要在节点上安装的内核模块。</p><h3 id=node_hugepage_count><code>node_hugepage_count</code></h3><p>参数名称： <code>node_hugepage_count</code>， 类型： <code>int</code>， 层次：<code>C</code></p><p>在节点上分配 2MB 大页的数量，默认为 <code>0</code>，另一个相关的参数是 <a href=#node_hugepage_ratio><code>node_hugepage_ratio</code></a>。</p><p>如果这两个参数 <code>node_hugepage_count</code> 和 <code>node_hugepage_ratio</code> 都为 <code>0</code>（默认），则大页将完全被禁用，本参数的优先级相比 <a href=#node_hugepage_ratio><code>node_hugepage_ratio</code></a> 更高，因为它更加精确。</p><p>如果设定了一个非零值，它将被写入 <code>/etc/sysctl.d/hugepage.conf</code> 中应用生效；负值将不起作用，高于 90% 节点内存的数字将被限制为节点内存的 90%</p><p>如果不为零，它应该略大于 <a href=/docs/pgsql/param#pg_shared_buffer_ratio><code>pg_shared_buffer_ratio</code></a> 的对应值，这样才能让 PostgreSQL 用上大页。</p><h3 id=node_hugepage_ratio><code>node_hugepage_ratio</code></h3><p>参数名称： <code>node_hugepage_ratio</code>， 类型： <code>float</code>， 层次：<code>C</code></p><p>节点内存大页占内存的比例，默认为 <code>0</code>，有效范围：<code>0</code> ~ <code>0.40</code></p><p>此内存比例将以大页的形式分配，并为PostgreSQL预留。 <a href=#node_hugepage_count><code>node_hugepage_count</code></a> 是具有更高优先级和精度的参数版本。</p><p>默认值：<code>0</code>，这将设置 <code>vm.nr_hugepages=0</code> 并完全不使用大页。</p><p>本参数应该等于或略大于 <a href=/docs/pgsql/param#pg_shared_buffer_ratio><code>pg_shared_buffer_ratio</code></a>，如果不为零。</p><p>例如，如果您为Postgres共享缓冲区默认分配了25%的内存，您可以将此值设置为 0.27 ~ 0.30，并在初始化后使用 <code>/pg/bin/pg-tune-hugepage</code> 精准回收浪费的大页。</p><h3 id=node_overcommit_ratio><code>node_overcommit_ratio</code></h3><p>参数名称： <code>node_overcommit_ratio</code>， 类型： <code>int</code>， 层次：<code>C</code></p><p>节点内存超额分配比率，默认为：<code>0</code>。这是一个从 <code>0</code> 到 <code>100+</code> 的整数。</p><p>默认值：<code>0</code>，这将设置 <code>vm.overcommit_memory=0</code>，否则将使用 <code>vm.overcommit_memory=2</code>， 并使用此值作为 <code>vm.overcommit_ratio</code>。</p><p>建议在 pgsql 独占节点上设置 <code>vm.overcommit_ratio</code>，避免内存过度提交。</p><h3 id=node_tune-1><code>node_tune</code></h3><p>参数名称： <code>node_tune</code>， 类型： <code>enum</code>， 层次：<code>C</code></p><p>针对机器进行调优的预制方案，基于<code>tuned</code> 提供服务。有四种预制模式：</p><ul><li><code>tiny</code>：微型虚拟机</li><li><code>oltp</code>：常规OLTP模板，优化延迟（默认值）</li><li><code>olap</code>：常规OLAP模板，优化吞吐量</li><li><code>crit</code>：核心金融业务模板，优化脏页数量</li></ul><p>通常，数据库的调优模板 <a href=/docs/pgsql/param#pg_conf><code>pg_conf</code></a> 应当与机器调优模板配套。</p><h3 id=node_sysctl_params><code>node_sysctl_params</code></h3><p>参数名称： <code>node_sysctl_params</code>， 类型： <code>dict</code>， 层次：<code>C</code></p><p>使用 K:V 形式的 sysctl 内核参数（通过 Ansible <code>sysctl</code> 模块写入并立即生效），作为 <code>tuned</code> profile 的补充。</p><p>默认值为：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_sysctl_params</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>fs.nr_open</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>8388608</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>默认设置 <code>fs.nr_open=8388608</code> 用于确保内核每进程 FD 上限不小于 Pigsty systemd unit 中的 <code>LimitNOFILE=8388608</code>，避免在部分发行版 / systemd 组合上服务启动时 <code>setrlimit</code> 失败。</p><p>这是一个 KV 结构的字典参数，Key 是内核 <code>sysctl</code> 参数名，Value 是参数值。你也可以考虑直接在 <code>roles/node/templates</code> 中的 tuned 模板中直接定义额外的 sysctl 参数。</p><hr><h2 id=node_sec><code>NODE_SEC</code></h2><p>节点安全相关参数，包括 SELinux 与防火墙配置。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_selinux_mode: permissive             # selinux mode</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>disabled, permissive, enforcing</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_mode: zone                  # firewall mode</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>zone (default, enabled), off (disable), none (skip &amp; self-managed)</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_intranet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>           </span><span style=color:#8f5902;font-style:italic># which intranet cidr considered as internal network</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>10.0.0.0</span><span style=color:#000>/8</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>192.168.0.0</span><span style=color:#000>/16</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>172.16.0.0</span><span style=color:#000>/12</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_public_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>        </span><span style=color:#8f5902;font-style:italic># expose these ports to public network in zone mode</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>22</span><span style=color:#f8f8f8>                            </span><span style=color:#8f5902;font-style:italic># enable ssh access</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>80</span><span style=color:#f8f8f8>                            </span><span style=color:#8f5902;font-style:italic># enable http access</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>443</span><span style=color:#f8f8f8>                           </span><span style=color:#8f5902;font-style:italic># enable https access</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=node_selinux_mode><code>node_selinux_mode</code></h3><p>参数名称： <code>node_selinux_mode</code>， 类型： <code>enum</code>， 层次：<code>C</code></p><p>SELinux 运行模式，默认值为：<code>permissive</code>（宽容模式）。</p><p>可选值：</p><ul><li><code>disabled</code>：完全禁用 SELinux（等同于旧版本的 <code>node_disable_selinux: true</code>）</li><li><code>permissive</code>：宽容模式，记录违规但不阻止（推荐，默认值）</li><li><code>enforcing</code>：强制模式，严格执行 SELinux 策略</li></ul><p>如果您没有专业的操作系统/安全专家，建议使用 <code>permissive</code> 或 <code>disabled</code> 模式。</p><p>请注意，SELinux 默认只在 EL 系列系统上启用，如果你想要在 Debian/Ubuntu 系统上启用 SELinux，请自行安装并启用 SELinux 配置。
另外，SELinux 模式的更改可能需要重启系统才能完全生效。</p><h3 id=node_firewall_mode><code>node_firewall_mode</code></h3><p>参数名称： <code>node_firewall_mode</code>， 类型： <code>enum</code>， 层次：<code>C</code></p><p>防火墙运行模式，默认值为：<code>zone</code>（启用防火墙并按分区规则管理）。
自 v4.1 起，默认值从 <code>none</code> 调整为 <code>zone</code>，即默认启用防火墙。</p><p>可选值：</p><ul><li><code>zone</code>：启用防火墙并配置规则：内网信任，公网只开放指定端口（默认值）。</li><li><code>off</code>：关闭并禁用防火墙（等同于旧版本的 <code>node_disable_firewall: true</code>）。</li><li><code>none</code>：不修改防火墙状态与规则，由用户完全自管。</li></ul><p>在 EL 系统上使用 <code>firewalld</code> 服务，在 Debian/Ubuntu 系统上使用 <code>ufw</code> 服务。为保证跨发行版行为一致，Pigsty 默认采用 <code>zone</code> 模式：自动启用系统防火墙，内网全通，公网仅开放 <a href=#node_firewall_public_port><code>node_firewall_public_port</code></a>。</p><p>如果您需要完全自行维护防火墙规则（例如仅依赖云安全组，或已有企业级防火墙策略），可以设置为 <code>none</code> 跳过 Pigsty 的防火墙管理；若要显式关闭系统防火墙，请使用 <code>off</code>。</p><p>需要公网暴露的生产环境建议使用 <code>zone</code> 模式，配合 <a href=#node_firewall_intranet><code>node_firewall_intranet</code></a> 和 <a href=#node_firewall_public_port><code>node_firewall_public_port</code></a> 进行精细化访问控制。<code>zone</code> 模式会在防火墙未运行时自动启用防火墙。</p><h3 id=node_firewall_intranet><code>node_firewall_intranet</code></h3><p>参数名称： <code>node_firewall_intranet</code>， 类型： <code>cidr[]</code>， 层次：<code>C</code></p><p>内网 CIDR 地址列表（自 v4.0 版本引入），默认值为：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_intranet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>10.0.0.0</span><span style=color:#000>/8</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>172.16.0.0</span><span style=color:#000>/12</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>192.168.0.0</span><span style=color:#000>/16</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>此参数定义了被视为"内部网络"的 IP 地址范围。来自这些网络的流量将被允许访问所有服务端口，而无需单独配置开放规则。</p><p>这些 CIDR 范围内的主机将被视为可信内网主机，享有更宽松的防火墙规则。同时，在 PG/PGB HBA 规则中，这里定义的内网范围也会被视作 “内网” 对待。
由于默认防火墙模式为 <code>zone</code>，该列表在默认配置下即生效。</p><h3 id=node_firewall_public_port><code>node_firewall_public_port</code></h3><p>参数名称： <code>node_firewall_public_port</code>， 类型： <code>port[]</code>， 层次：<code>C</code></p><p>公网开放端口列表，默认值为：<code>[22, 80, 443]</code>。</p><p>此参数定义了对公网（非内网 CIDR）开放的端口列表。默认开放的端口包括：</p><ul><li><code>22</code>：SSH 服务端口</li><li><code>80</code>：HTTP 服务端口</li><li><code>443</code>：HTTPS 服务端口</li></ul><p>您可以根据实际需求调整此列表。例如，如果您需要对外暴露 PostgreSQL，可以显式添加 <code>5432</code>：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_public_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#0000cf;font-weight:700>22</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>80</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>443</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>5432</span><span style=color:#000;font-weight:700>]</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>Pigsty 中 PostgreSQL 默认安全策略仅允许管理员通过公网访问数据库端口。
如果您想要让其他用户也能通过公网访问数据库，请确保在 PG/PGB HBA 规则中正确配置相应的访问权限。</p><p>如果你想要将其他服务端口对公网开放，也可以将它们添加到此列表中。
建议始终保持最小暴露原则，只开放真正需要的服务端口。</p><p>请注意，只有当 <a href=#node_firewall_mode><code>node_firewall_mode</code></a> 设置为 <code>zone</code> 时，此参数才会生效；若设置为 <code>none</code> 或 <code>off</code> 则不会应用此端口策略。</p><hr><h2 id=node_admin><code>NODE_ADMIN</code></h2><p>这一节关于主机节点上的管理员，谁能登陆，怎么登陆。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_data</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>/data                 </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># node main data directory, `/data` by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_admin_enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># create a admin user on target node?</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_admin_uid</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>88</span><span style=color:#f8f8f8>                </span><span style=color:#8f5902;font-style:italic># uid and gid for node admin user</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_admin_username</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>dba         </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># name of node admin user, `dba` by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_admin_sudo: nopass           # admin user&#39;s sudo privilege</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>nopass, all, limit</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_admin_ssh_exchange</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>     </span><span style=color:#8f5902;font-style:italic># exchange admin ssh key among node cluster</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_admin_pk_current</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>       </span><span style=color:#8f5902;font-style:italic># add current user&#39;s ssh pk to admin authorized_keys</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_admin_pk_list</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[]</span><span style=color:#f8f8f8>            </span><span style=color:#8f5902;font-style:italic># ssh public keys to be added to admin user</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_aliases</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{}<span style=color:#f8f8f8>                  </span><span style=color:#8f5902;font-style:italic># shell aliases to write into `/etc/profile.d/node.alias.sh`</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=node_data><code>node_data</code></h3><p>参数名称： <code>node_data</code>， 类型： <code>path</code>， 层次：<code>C</code></p><p>节点的主数据目录，默认为 <code>/data</code>。</p><p>如果该目录不存在，则该目录会被创建。该目录由 <code>root:root</code> 拥有，权限为 <code>0755</code>。</p><h3 id=node_admin_enabled><code>node_admin_enabled</code></h3><p>参数名称： <code>node_admin_enabled</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否在本节点上创建一个专用管理员用户？默认值为：<code>true</code>。</p><p>Pigsty默认会在每个节点上创建一个管理员用户（拥有免密sudo与ssh权限），默认的管理员名为<code>dba (uid=88)</code>的管理用户，可以从元节点上通过SSH免密访问环境中的其他节点并执行免密sudo。</p><h3 id=node_admin_uid><code>node_admin_uid</code></h3><p>参数名称： <code>node_admin_uid</code>， 类型： <code>int</code>， 层次：<code>C</code></p><p>管理员用户UID，默认值为：<code>88</code>。</p><p>请尽可能确保 UID 在所有节点上都相同，可以避免一些无谓的权限问题。</p><p>如果默认 UID 88 已经被占用，您可以选择一个其他 UID ，手工分配时请注意UID命名空间冲突。</p><h3 id=node_admin_username><code>node_admin_username</code></h3><p>参数名称： <code>node_admin_username</code>， 类型： <code>username</code>， 层次：<code>C</code></p><p>管理员用户名，默认为 <code>dba</code> 。</p><h3 id=node_admin_sudo><code>node_admin_sudo</code></h3><p>参数名称： <code>node_admin_sudo</code>， 类型： <code>enum</code>， 层次：<code>C</code></p><p>管理员用户的 sudo 权限级别，默认值为：<code>nopass</code>（免密 sudo）。</p><p>可选值：</p><ul><li><code>nopass</code>：授予免密 sudo 权限（默认，允许执行所有命令但无需密码）</li><li><code>all</code>：授予完整 sudo 权限（需要密码）</li><li><code>limit</code>：授予有限的 sudo 权限（仅允许执行特定命令）</li></ul><p>Pigsty 默认使用 <code>nopass</code> 模式，管理员用户可以无需密码执行任意 sudo 命令，这对于自动化运维非常方便。</p><p>在安全要求较高的生产环境中，您可能需要将此参数调整为 <code>limit</code> 或 <code>all</code>，以限制管理员的权限范围。</p><h3 id=node_admin_ssh_exchange><code>node_admin_ssh_exchange</code></h3><p>参数名称： <code>node_admin_ssh_exchange</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>在节点集群间交换节点管理员SSH密钥, 类型：<code>bool</code>，层级：C，默认值为：<code>true</code></p><p>启用时，Pigsty会在执行剧本时，在成员间交换SSH公钥，允许管理员 <a href=#node_admin_username><code>node_admin_username</code></a> 从不同节点上相互访问。</p><h3 id=node_admin_pk_current><code>node_admin_pk_current</code></h3><p>参数名称： <code>node_admin_pk_current</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否将当前节点 & 用户的公钥加入管理员账户，默认值是： <code>true</code></p><p>启用时，将会把当前节点上执行此剧本的管理用户的SSH公钥（<code>~/.ssh/id_rsa.pub</code>）拷贝至目标节点管理员用户的 <code>authorized_keys</code> 中。</p><p>生产环境部署时，请务必注意此参数，此参数会将当前执行命令用户的默认公钥安装至所有机器的管理用户上。</p><h3 id=node_admin_pk_list><code>node_admin_pk_list</code></h3><p>参数名称： <code>node_admin_pk_list</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p>可登陆管理员的公钥列表，默认值为：<code>[]</code> 空数组。</p><p>数组的每一个元素为字符串，内容为写入到管理员用户<code>~/.ssh/authorized_keys</code>中的公钥，持有对应私钥的用户可以以管理员身份登录。</p><p>生产环境部署时，请务必注意此参数，仅将信任的密钥加入此列表中。</p><h3 id=node_aliases><code>node_aliases</code></h3><p>参数名称： <code>node_aliases</code>， 类型： <code>dict</code>， 层次：<code>C</code></p><p>用于写入主机 <code>/etc/profile.d/node.alias.sh</code> 的 shell 别名，默认值为：<code>{}</code> 空字典。</p><p>此参数允许您为主机的 shell 环境配置方便使用的 alias，此处定义的 K:V 字典将以 <code>alias k=v</code> 的形式写入到目标节点的 <code>profile.d</code> 文件中生效。</p><p>例如，以下命令声明了一个名为 <code>dp</code> 的别名，用于快速执行 <code>docker compose pull</code> 命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_alias</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>dp</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#39;docker compose pull&#39;</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><hr><h2 id=node_time><code>NODE_TIME</code></h2><p>关于主机时间/时区/NTP/定时任务的相关配置。</p><p>时间同步对于数据库服务来说非常重要，请确保系统 <code>chronyd</code> 授时服务正常运行。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_timezone</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#39;&#39;</span><span style=color:#f8f8f8>                 </span><span style=color:#8f5902;font-style:italic># 设置节点时区，空字符串表示跳过</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_ntp_enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>            </span><span style=color:#8f5902;font-style:italic># 启用chronyd时间同步服务？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_ntp_servers</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>                 </span><span style=color:#8f5902;font-style:italic># `/etc/chrony.conf`中的ntp服务器</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#000>pool pool.ntp.org iburst</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_crontab_overwrite</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>      </span><span style=color:#8f5902;font-style:italic># 覆盖还是追加到`/etc/crontab`？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_crontab</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>]</span><span style=color:#f8f8f8>                 </span><span style=color:#8f5902;font-style:italic># `/etc/crontab`中的crontab条目</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=node_timezone><code>node_timezone</code></h3><p>参数名称： <code>node_timezone</code>， 类型： <code>string</code>， 层次：<code>C</code></p><p>设置节点时区，空字符串表示跳过。默认值是空字符串，默认不会修改默认的时区（即使用通常的默认值UTC）</p><p>在中国地区使用时，建议设置为 <code>Asia/Hong_Kong</code> / <code>Asia/ShangHai</code>。</p><h3 id=node_ntp_enabled><code>node_ntp_enabled</code></h3><p>参数名称： <code>node_ntp_enabled</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>启用chronyd时间同步服务？默认值为：<code>true</code></p><p>此时 Pigsty 将使用 <a href=#node_ntp_servers><code>node_ntp_servers</code></a> 中指定的 NTP服务器列表覆盖节点的 <code>/etc/chrony.conf</code>。</p><p>如果您的节点已经配置好了 NTP 服务器，那么可以将此参数设置为 <code>false</code> 跳过时间同步配置。</p><h3 id=node_ntp_servers><code>node_ntp_servers</code></h3><p>参数名称： <code>node_ntp_servers</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p>在 <code>/etc/chrony.conf</code> 中使用的 NTP 服务器列表。默认值为：<code>["pool pool.ntp.org iburst"]</code></p><p>本参数是一个数组，每一个数组元素是一个字符串，代表一行 NTP 服务器配置。仅当 <a href=#node_ntp_enabled><code>node_ntp_enabled</code></a> 启用时生效。</p><p>Pigsty 默认使用全球 NTP 服务器 <code>pool.ntp.org</code>，您可以根据自己的网络环境修改此参数，例如 <code>cn.pool.ntp.org iburst</code>，或内网的时钟服务。</p><p>您也可以在配置中使用 <code>${admin_ip}</code> 占位符，使用管理节点上的时间服务器。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_ntp_servers</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#39;pool ${admin_ip} iburst&#39;</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>]</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=node_crontab_overwrite><code>node_crontab_overwrite</code></h3><p>参数名称： <code>node_crontab_overwrite</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>处理 <a href=#node_crontab><code>node_crontab</code></a> 中的定时任务时，是追加还是覆盖？默认值为：<code>true</code>，即覆盖。</p><p>如果您希望在节点上追加定时任务，可以将此参数设置为 <code>false</code>，Pigsty 将会在节点的 crontab 上 <strong>追加</strong>，而非 <strong>覆盖所有</strong> 定时任务。</p><h3 id=node_crontab><code>node_crontab</code></h3><p>参数名称： <code>node_crontab</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p>定义在节点 <code>/etc/crontab</code> 中的定时任务：默认值为：<code>[]</code> 空数组。</p><p>每一个数组元素都是一个字符串，代表一行定时任务。使用标准的系统 crontab 格式：<code>分 时 日 月 周 用户 命令</code>。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_crontab</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#4e9a06>&#39;00 03 * * * root /usr/bin/some-system-task&#39;</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><blockquote><p><strong>注意</strong>：对于 PostgreSQL 备份等 postgres 用户的定时任务，请使用 <a href=/docs/pgsql/param#pg_crontab><code>pg_crontab</code></a> 参数，
而非 <code>node_crontab</code>。因为 <code>node_crontab</code> 在 NODE 初始化阶段写入 <code>/etc/crontab</code>，此时 <code>postgres</code> 用户可能尚未创建，
会导致 cron 报错 <code>bad username</code> 并忽略整个 crontab 文件。</p></blockquote><p>当 <a href=#node_crontab_overwrite><code>node_crontab_overwrite</code></a> 为 <code>true</code>（默认）时，移除节点时会恢复默认的 <code>/etc/crontab</code>。</p><hr><h2 id=node_vip><code>NODE_VIP</code></h2><p>您可以为节点集群绑定一个可选的 L2 VIP，默认不启用此特性。L2 VIP 只对一组节点集群有意义，该 VIP 会根据配置的优先级在集群中的节点之间进行切换，确保节点服务的高可用。</p><p>请注意，L2 VIP <strong>只能</strong> 在同一 L2 网段中使用，这可能会对您的网络拓扑产生额外的限制，如果不想受此限制，您可以考虑使用 DNS LB 或者 Haproxy 实现类似的功能。</p><p>当启用此功能时，您需要为这个 L2 VIP 显式分配可用的 <a href=#vip_address><code>vip_address</code></a> 与 <a href=#vip_vrid><code>vip_vrid</code></a>，用户应当确保这两者在同一网段内唯一。</p><p>请注意，NODE VIP 与 PG VIP 不同，PG VIP 是为 PostgreSQL 实例服务的 VIP，由 vip-manager 组件管理并绑定在 PG 集群主库上。
而 NODE VIP 由 Keepalived 组件管理，绑定在节点集群上。可以是主备模式，也可以是负载均衡模式，两者可以并存。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>vip_enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>                </span><span style=color:#8f5902;font-style:italic># enable vip on this node cluster?</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># vip_address:         [IDENTITY] # node vip address in ipv4 format, required if vip is enabled</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># vip_vrid:            [IDENTITY] # required, integer, 1-254, should be unique among same VLAN</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vip_role</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>backup                 </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># optional, `master/backup`, backup by default, use as init role</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vip_preempt</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>                </span><span style=color:#8f5902;font-style:italic># optional, `true/false`, false by default, enable vip preemption</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vip_interface</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>eth0              </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># node vip network interface to listen, `eth0` by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vip_dns_suffix</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#39;&#39;</span><span style=color:#f8f8f8>                </span><span style=color:#8f5902;font-style:italic># node vip dns name suffix, empty string by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vip_auth_pass</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#39;&#39;</span><span style=color:#f8f8f8>                 </span><span style=color:#8f5902;font-style:italic># vrrp auth password, empty to use `&lt;cls&gt;-&lt;vrid&gt;` as default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vip_exporter_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>9650</span><span style=color:#f8f8f8>           </span><span style=color:#8f5902;font-style:italic># keepalived exporter listen port, 9650 by default</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=vip_enabled><code>vip_enabled</code></h3><p>参数名称： <code>vip_enabled</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否在当前这个节点集群中配置一个由 Keepalived 管理的 L2 VIP ？ 默认值为： <code>false</code>。</p><h3 id=vip_address><code>vip_address</code></h3><p>参数名称： <code>vip_address</code>， 类型： <code>ip</code>， 层次：<code>C</code></p><p>节点 VIP 地址，IPv4 格式（不带 CIDR 网段后缀），当节点启用 <a href=#vip_enabled><code>vip_enabled</code></a> 时，这是一个必选参数。</p><p>本参数没有默认值，这意味着您必须显式地为节点集群分配一个唯一的 VIP 地址。</p><h3 id=vip_vrid><code>vip_vrid</code></h3><p>参数名称： <code>vip_vrid</code>， 类型： <code>int</code>， 层次：<code>C</code></p><p>VRID 是一个范围从 <code>1</code> 到 <code>254</code> 的正整数，用于标识一个网络中的 VIP，当节点启用 <a href=#vip_enabled><code>vip_enabled</code></a> 时，这是一个必选参数。</p><p>本参数没有默认值，这意味着您必须显式地为节点集群分配一个网段内唯一的 ID。</p><h3 id=vip_role><code>vip_role</code></h3><p>参数名称： <code>vip_role</code>， 类型： <code>enum</code>， 层次：<code>I</code></p><p>节点 VIP 角色，可选值为： <code>master</code> 或 <code>backup</code>，默认值为 <code>backup</code></p><p>该参数的值会被设置为 keepalived 的初始状态。</p><h3 id=vip_preempt><code>vip_preempt</code></h3><p>参数名称： <code>vip_preempt</code>， 类型： <code>bool</code>， 层次：<code>C/I</code></p><p>是否启用 VIP 抢占？可选参数，默认值为 <code>false</code>，即不抢占 VIP。</p><p>所谓抢占，是指一个 <code>backup</code> 角色的节点，当其优先级高于当前存活且正常工作的 <code>master</code> 角色的节点时，是否取抢占其 VIP？</p><h3 id=vip_interface><code>vip_interface</code></h3><p>参数名称： <code>vip_interface</code>， 类型： <code>string</code>， 层次：<code>C/I</code></p><p>节点 VIP 监听使用的网卡，默认为 <code>eth0</code>。</p><p>您应当使用与节点主IP地址（即：你填入清单中IP地址）所使用网卡相同的名称。</p><p>如果你的节点有着不同的网卡名称，你可以在实例/节点层次对其进行覆盖。</p><h3 id=vip_dns_suffix><code>vip_dns_suffix</code></h3><p>参数名称： <code>vip_dns_suffix</code>， 类型： <code>string</code>， 层次：<code>C/I</code></p><p>节点集群 L2 VIP 使用的DNS名称，默认是空字符串，即直接使用集群名本身作为DNS名。</p><h3 id=vip_auth_pass><code>vip_auth_pass</code></h3><p>参数名称： <code>vip_auth_pass</code>， 类型： <code>password</code>， 层次：<code>C</code></p><p>VRRP 认证密码，用于 keepalived VRRP 协议认证。默认为空字符串。</p><p>当为空时，Pigsty 会自动使用 <code>&lt;cluster_name>-&lt;vrid></code> 模式生成密码。
在有安全要求的生产环境中，建议设置一个显式的强密码。</p><h3 id=vip_exporter_port><code>vip_exporter_port</code></h3><p>参数名称： <code>vip_exporter_port</code>， 类型： <code>port</code>， 层次：<code>C/I</code></p><p>keepalived exporter 监听端口号，默认为：<code>9650</code>。</p><hr><h2 id=haproxy><code>HAPROXY</code></h2><p>HAProxy 默认在所有节点上安装启用，并以类似于 Kubernetes NodePort 的方式对外暴露服务。</p><p><a href=/docs/pgsql><code>PGSQL</code></a> 模块对外 <a href=/docs/pgsql/service/>服务</a> 使用到了 Haproxy。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>             </span><span style=color:#8f5902;font-style:italic># 在此节点上启用haproxy？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_clean</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>              </span><span style=color:#8f5902;font-style:italic># 清理所有现有的haproxy配置？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_reload</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>              </span><span style=color:#8f5902;font-style:italic># 配置后重新加载haproxy？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_auth_enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>        </span><span style=color:#8f5902;font-style:italic># 为haproxy管理页面启用身份验证</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_admin_username</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>admin    </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># haproxy管理用户名，默认为`admin`</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_admin_password</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>pigsty   </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># haproxy管理密码，默认为`pigsty`</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_exporter_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>9101</span><span style=color:#f8f8f8>       </span><span style=color:#8f5902;font-style:italic># haproxy管理/导出端口，默认为9101</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_client_timeout</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>24h      </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># 客户端连接超时，默认为24小时</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_server_timeout</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>24h      </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># 服务器端连接超时，默认为24小时</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_services</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[]</span><span style=color:#f8f8f8>              </span><span style=color:#8f5902;font-style:italic># 需要在节点上暴露的haproxy服务列表</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=haproxy_enabled><code>haproxy_enabled</code></h3><p>参数名称： <code>haproxy_enabled</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>在此节点上启用haproxy？默认值为： <code>true</code>。</p><h3 id=haproxy_clean><code>haproxy_clean</code></h3><p>参数名称： <code>haproxy_clean</code>， 类型： <code>bool</code>， 层次：<code>G/C/A</code></p><p>清理所有现有的haproxy配置？默认值为 <code>false</code>。</p><h3 id=haproxy_reload><code>haproxy_reload</code></h3><p>参数名称： <code>haproxy_reload</code>， 类型： <code>bool</code>， 层次：<code>A</code></p><p>配置后重新加载 haproxy？默认值为 <code>true</code>，配置更改后会重新加载haproxy。</p><p>如果您希望在应用配置前进行手工检查，您可以使用命令参数关闭此选项，并进行检查后再应用。</p><h3 id=haproxy_auth_enabled><code>haproxy_auth_enabled</code></h3><p>参数名称： <code>haproxy_auth_enabled</code>， 类型： <code>bool</code>， 层次：<code>G</code></p><p>为haproxy管理页面启用身份验证，默认值为 <code>true</code>，它将要求管理页面进行http基本身份验证。</p><p>建议不要禁用认证，因为您的流量控制页面将对外暴露，这是比较危险的。</p><h3 id=haproxy_admin_username><code>haproxy_admin_username</code></h3><p>参数名称： <code>haproxy_admin_username</code>， 类型： <code>username</code>， 层次：<code>G</code></p><p>haproxy 管理员用户名，默认为：<code>admin</code>。</p><h3 id=haproxy_admin_password><code>haproxy_admin_password</code></h3><p>参数名称： <code>haproxy_admin_password</code>， 类型： <code>password</code>， 层次：<code>G</code></p><p>haproxy管理密码，默认为 <code>pigsty</code></p><blockquote><p>在生产环境中请务必修改此密码！</p></blockquote><h3 id=haproxy_exporter_port><code>haproxy_exporter_port</code></h3><p>参数名称： <code>haproxy_exporter_port</code>， 类型： <code>port</code>， 层次：<code>C</code></p><p>haproxy 流量管理/指标对外暴露的端口，默认为：<code>9101</code></p><h3 id=haproxy_client_timeout><code>haproxy_client_timeout</code></h3><p>参数名称： <code>haproxy_client_timeout</code>， 类型： <code>interval</code>， 层次：<code>C</code></p><p>客户端连接超时，默认为 <code>24h</code>。</p><p>设置一个超时可以避免难以清理的超长的连接，但如果您真的需要一个长连接，您可以将其设置为更长的时间。</p><h3 id=haproxy_server_timeout><code>haproxy_server_timeout</code></h3><p>参数名称： <code>haproxy_server_timeout</code>， 类型： <code>interval</code>， 层次：<code>C</code></p><p>服务端连接超时，默认为 <code>24h</code>。</p><p>设置一个超时可以避免难以清理的超长的连接，但如果您真的需要一个长连接，您可以将其设置为更长的时间。</p><h3 id=haproxy_services><code>haproxy_services</code></h3><p>参数名称： <code>haproxy_services</code>， 类型： <code>service[]</code>， 层次：<code>C</code></p><p>需要在此节点上通过 Haproxy 对外暴露的服务列表，默认值为： <code>[]</code> 空数组。</p><p>每一个数组元素都是一个服务定义，下面是一个服务定义的例子：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>haproxy_services</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>                   </span><span style=color:#8f5902;font-style:italic># list of haproxy service</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#8f5902;font-style:italic># expose pg-test read only replicas</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#204a87;font-weight:700>name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>pg-test-ro               </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># [REQUIRED] service name, unique</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>5440</span><span style=color:#f8f8f8>                      </span><span style=color:#8f5902;font-style:italic># [REQUIRED] service port, unique</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>ip</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#34;*&#34;</span><span style=color:#f8f8f8>                         </span><span style=color:#8f5902;font-style:italic># [OPTIONAL] service listen addr, &#34;*&#34; by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>protocol</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>tcp                  </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># [OPTIONAL] service protocol, &#39;tcp&#39; by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>balance</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>leastconn             </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># [OPTIONAL] load balance algorithm, roundrobin by default (or leastconn)</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>maxconn</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>20000</span><span style=color:#f8f8f8>                  </span><span style=color:#8f5902;font-style:italic># [OPTIONAL] max allowed front-end connection, 20000 by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>default</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#39;inter 3s fastinter 1s downinter 5s rise 3 fall 3 on-marked-down shutdown-sessions slowstart 30s maxconn 3000 maxqueue 128 weight 100&#39;</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>options</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>      </span>- <span style=color:#000>option httpchk</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>      </span>- <span style=color:#000>option http-keep-alive</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>      </span>- <span style=color:#000>http-check send meth OPTIONS uri /read-only</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>      </span>- <span style=color:#000>http-check expect status 200</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>servers</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>      </span>- {<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>name: pg-test-1 ,ip: 10.10.10.11 , port: 5432 , options: check port 8008 , backup</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8> </span>}<span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>      </span>- {<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>name: pg-test-2 ,ip: 10.10.10.12 , port: 5432 , options</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>check port 8008 }</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>      </span>- {<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>name: pg-test-3 ,ip: 10.10.10.13 , port: 5432 , options</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>check port 8008 }</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>每个服务定义会被渲染为 <code>/etc/haproxy/&lt;service.name>.cfg</code> 配置文件，并在 Haproxy 重载后生效。</p><hr><h2 id=node_exporter><code>NODE_EXPORTER</code></h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_exporter_enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>       </span><span style=color:#8f5902;font-style:italic># setup node_exporter on this node?</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_exporter_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>9100</span><span style=color:#f8f8f8>          </span><span style=color:#8f5902;font-style:italic># node exporter listen port, 9100 by default</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_exporter_options</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#4e9a06>&#39;--no-collector.softnet --no-collector.nvme --collector.tcpstat --collector.processes&#39;</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=node_exporter_enabled><code>node_exporter_enabled</code></h3><p>参数名称： <code>node_exporter_enabled</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>在当前节点上启用节点指标收集器？默认启用：<code>true</code></p><h3 id=node_exporter_port><code>node_exporter_port</code></h3><p>参数名称： <code>node_exporter_port</code>， 类型： <code>port</code>， 层次：<code>C</code></p><p>对外暴露节点指标使用的端口，默认为 <code>9100</code>。</p><h3 id=node_exporter_options><code>node_exporter_options</code></h3><p>参数名称： <code>node_exporter_options</code>， 类型： <code>arg</code>， 层次：<code>C</code></p><p>节点指标采集器的命令行参数，默认值为：</p><p><code>--no-collector.softnet --no-collector.nvme --collector.tcpstat --collector.processes</code></p><p>该选项会启用/禁用一些指标收集器，请根据您的需要进行调整。</p><hr><h2 id=vector><code>VECTOR</code></h2><p>Vector 是 Pigsty v4.0 使用的日志收集组件，会收集各个模块产生的日志并发送至基础设施节点上的 VictoriaLogs 服务。</p><ul><li><p><code>INFRA</code>： 基础设施组件的日志只会在 Infra 节点上收集。</p><ul><li><code>nginx-access</code>: <code>/var/log/nginx/access.log</code></li><li><code>nginx-error</code>: <code>/var/log/nginx/error.log</code></li><li><code>grafana</code>: <code>/var/log/grafana/grafana.log</code></li></ul></li><li><p><code>NODES</code>：主机相关日志，所有节点上都会启用收集。</p><ul><li>通过 <code>journald</code> 统一采集系统服务日志（<code>job=syslog</code>），不依赖固定的 <code>/var/log/*</code> 文件路径。</li></ul></li><li><p><code>PGSQL</code>：PostgreSQL 相关的日志，只有节点配置了 <a href=/docs/pgsql>PGSQL</a> 模块才会启用收集。</p><ul><li><code>postgres</code>: <code>/pg/log/postgres/*</code></li><li><code>patroni</code>: <code>/pg/log/patroni.log</code></li><li><code>pgbouncer</code>: <code>/pg/log/pgbouncer/pgbouncer.log</code></li><li><code>pgbackrest</code>: <code>/pg/log/pgbackrest/*.log</code></li></ul></li><li><p><code>REDIS</code>：Redis 相关日志，只有节点配置了 <a href=/docs/redis>REDIS</a> 模块才会启用收集。</p><ul><li><code>redis</code>: <code>/var/log/redis/*.log</code></li></ul></li></ul><blockquote><p>日志目录会根据这些参数的配置自动调整：<a href=/docs/pgsql/param#pg_log_dir><code>pg_log_dir</code></a>, <a href=/docs/pgsql/param#patroni_log_dir><code>patroni_log_dir</code></a>, <a href=/docs/pgsql/param#pgbouncer_log_dir><code>pgbouncer_log_dir</code></a>, <a href=/docs/pgsql/param#pgbackrest_log_dir><code>pgbackrest_log_dir</code></a></p></blockquote><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>vector_enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>              </span><span style=color:#8f5902;font-style:italic># 启用 vector 日志收集器吗？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vector_clean</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8>               </span><span style=color:#8f5902;font-style:italic># 初始化时清除 vector 数据目录吗？</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vector_data</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>/data/vector        </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># vector 数据目录，默认为 /data/vector</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vector_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>9598</span><span style=color:#f8f8f8>                 </span><span style=color:#8f5902;font-style:italic># vector 指标端口，默认为 9598</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vector_read_from</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>beginning      </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># vector 从头还是从尾开始读取日志</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>vector_log_endpoint</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#f8f8f8> </span><span style=color:#000>infra ]   </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># 日志发送目标端点，默认发送至 infra 组</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=vector_enabled><code>vector_enabled</code></h3><p>参数名称： <code>vector_enabled</code>， 类型： <code>bool</code>， 层次：<code>C</code></p><p>是否启用 Vector 日志收集服务？默认值为： <code>true</code></p><p>Vector 是 Pigsty v4.0 使用的日志收集代理，替代了之前版本使用的 Promtail，用于收集节点和服务的日志并发送至 VictoriaLogs。</p><h3 id=vector_clean><code>vector_clean</code></h3><p>参数名称： <code>vector_clean</code>， 类型： <code>bool</code>， 层次：<code>G/A</code></p><p>是否在安装 Vector 时清除已有数据目录？默认值为： <code>false</code>。</p><p>默认不会清理，当您选择清理时，Pigsty 会在部署 Vector 时移除现有数据目录 <a href=#vector_data><code>vector_data</code></a>，这意味着 Vector 会重新收集当前节点上的所有日志并发送至 VictoriaLogs。</p><h3 id=vector_data><code>vector_data</code></h3><p>参数名称： <code>vector_data</code>， 类型： <code>path</code>， 层次：<code>C</code></p><p>Vector 数据目录路径，默认值为：<code>/data/vector</code>。</p><p>Vector 会将日志读取的偏移量和缓冲数据存储在此目录中。</p><h3 id=vector_port><code>vector_port</code></h3><p>参数名称： <code>vector_port</code>， 类型： <code>port</code>， 层次：<code>C</code></p><p>Vector 指标监听端口号，默认为：<code>9598</code></p><p>此端口用于暴露 Vector 自身的监控指标，可被 VictoriaMetrics 抓取。</p><h3 id=vector_read_from><code>vector_read_from</code></h3><p>参数名称： <code>vector_read_from</code>， 类型： <code>enum</code>， 层次：<code>C</code></p><p>Vector 日志读取起始位置，默认值为：<code>beginning</code>。</p><p>可选值为 <code>beginning</code>（从头开始）或 <code>end</code>（从尾开始）。<code>beginning</code> 会读取现有日志文件的全部内容，<code>end</code> 只读取新产生的日志。</p><h3 id=vector_log_endpoint><code>vector_log_endpoint</code></h3><p>参数名称： <code>vector_log_endpoint</code>， 类型： <code>string[]</code>， 层次：<code>C</code></p><p>日志发送目标端点列表，默认值为：<code>[ infra ]</code>。</p><p>指定将日志发送至哪个节点组的 VictoriaLogs 服务。默认发送至 <code>infra</code> 组的节点。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-82bbb07e4b385ccd2f29e3417328b1c8>3 - 预置剧本</h1><div class=lead>如何使用预置的 ansible 剧本来管理 Node 集群，常用管理命令速查。</div><p>Pigsty 提供两个与 NODE 模块相关的剧本：</p><ul><li><a href=#nodeyml><code>node.yml</code></a>：纳管节点，调整节点到期望状态</li><li><a href=#node-rmyml><code>node-rm.yml</code></a>：从 Pigsty 中移除纳管节点</li></ul><p>另提供两个包装命令工具：<code>bin/node-add</code> 与 <code>bin/node-rm</code>，用于快速调用剧本。</p><hr><h2 id=nodeyml><code>node.yml</code></h2><p>向 Pigsty 添加节点的 <a href=https://github.com/pgsty/pigsty/blob/main/node.yml><code>node.yml</code></a> 包含以下子任务：</p><pre tabindex=0><code>node-id       ：生成节点身份标识
node_name     ：设置主机名
node_hosts    ：配置 /etc/hosts 记录
node_resolv   ：配置 DNS 解析器 /etc/resolv.conf
node_firewall ：设置防火墙 &amp; selinux
node_ca       ：添加并信任CA证书
node_repo     ：添加上游软件仓库
node_pkg      ：安装 rpm/deb 软件包
node_uv       ：配置 uv Python 虚拟环境
node_feature  ：配置 numa、grub、静态网络等特性
node_kernel   ：配置操作系统内核模块
node_tune     ：配置 tuned 调优模板
node_sysctl   ：设置额外的 sysctl 参数
node_profile  ：写入 /etc/profile.d/node.sh
node_ulimit   ：配置资源限制
node_data     ：配置数据目录
node_admin    ：配置管理员用户和ssh密钥
node_timezone ：配置时区
node_ntp      ：配置 NTP 服务器/客户端
node_crontab  ：添加/覆盖 crontab 定时任务
node_vip      ：为节点集群设置可选的 L2 VIP
haproxy       ：在节点上设置 haproxy 以暴露服务
monitor       ：配置节点监控：node_exporter &amp; vector
</code></pre><hr><h2 id=node-rmyml><code>node-rm.yml</code></h2><p>从 Pigsty 中移除节点的剧本 <a href=https://github.com/pgsty/pigsty/blob/main/node-rm.yml><code>node-rm.yml</code></a> 包含以下子任务：</p><pre tabindex=0><code>node_deregister   : 移除节点注册信息（VictoriaMetrics / Vector / DNS）
  - rm_metrics    : 移除已注册的 VictoriaMetrics 监控目标
  - rm_logs       : 移除已注册的 Vector 日志采集配置
  - rm_dns        : 移除已注册的 Node VIP DNS 解析记录
haproxy_deregister: 移除用于 haproxy 管理界面的 nginx 代理记录
  - rm_proxy      : 移除 nginx upstream/location 记录
vip            : 移除节点的 keepalived 与 L2 VIP（如果启用 VIP）
haproxy        : 移除 haproxy 负载均衡器
node_exporter  : 移除节点监控：Node Exporter
vip_exporter   : 移除 keepalived_exporter （如果启用 VIP）
vector         : 移除日志收集代理 vector
node_crontab   : 恢复默认 /etc/crontab（当 node_crontab_overwrite=true 时）
profile        : 移除 /etc/profile.d/node.sh 环境配置文件
</code></pre><hr><h2 id=常用命令速查>常用命令速查</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 基础节点管理</span>
</span></span><span style=display:flex><span>./node.yml -l &lt;cls<span style=color:#000;font-weight:700>|</span>ip<span style=color:#000;font-weight:700>|</span>group&gt;          <span style=color:#8f5902;font-style:italic># 向 Pigsty 中添加节点</span>
</span></span><span style=display:flex><span>./node-rm.yml -l &lt;cls<span style=color:#000;font-weight:700>|</span>ip<span style=color:#000;font-weight:700>|</span>group&gt;       <span style=color:#8f5902;font-style:italic># 从 Pigsty 中移除节点</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 节点管理快捷命令</span>
</span></span><span style=display:flex><span>bin/node-add node-test                 <span style=color:#8f5902;font-style:italic># 初始化节点集群 &#39;node-test&#39;</span>
</span></span><span style=display:flex><span>bin/node-add 10.10.10.10               <span style=color:#8f5902;font-style:italic># 初始化节点 &#39;10.10.10.10&#39;</span>
</span></span><span style=display:flex><span>bin/node-rm node-test                  <span style=color:#8f5902;font-style:italic># 移除节点集群 &#39;node-test&#39;</span>
</span></span><span style=display:flex><span>bin/node-rm 10.10.10.10                <span style=color:#8f5902;font-style:italic># 移除节点 &#39;10.10.10.10&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 节点主体初始化</span>
</span></span><span style=display:flex><span>./node.yml -t node                     <span style=color:#8f5902;font-style:italic># 完成节点主体初始化（haproxy，监控除外）</span>
</span></span><span style=display:flex><span>./node.yml -t haproxy                  <span style=color:#8f5902;font-style:italic># 在节点上设置 haproxy</span>
</span></span><span style=display:flex><span>./node.yml -t monitor                  <span style=color:#8f5902;font-style:italic># 配置节点监控：node_exporter &amp; vector</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># VIP 管理</span>
</span></span><span style=display:flex><span>./node.yml -t node_vip                 <span style=color:#8f5902;font-style:italic># 为节点集群设置可选的 L2 VIP</span>
</span></span><span style=display:flex><span>./node.yml -t vip_config,vip_reload    <span style=color:#8f5902;font-style:italic># 刷新节点 L2 VIP 配置</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># HAProxy 管理</span>
</span></span><span style=display:flex><span>./node.yml -t haproxy_config,haproxy_reload   <span style=color:#8f5902;font-style:italic># 刷新节点上的服务定义</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 注册管理</span>
</span></span><span style=display:flex><span>./node.yml -t node_register            <span style=color:#8f5902;font-style:italic># 重新将节点注册到 VictoriaMetrics 中</span>
</span></span><span style=display:flex><span>./node.yml -t register_nginx           <span style=color:#8f5902;font-style:italic># 重新将节点 haproxy 管控界面注册到 Nginx 中</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 具体任务</span>
</span></span><span style=display:flex><span>./node.yml -t node-id                  <span style=color:#8f5902;font-style:italic># 生成节点身份标识</span>
</span></span><span style=display:flex><span>./node.yml -t node_name                <span style=color:#8f5902;font-style:italic># 设置主机名</span>
</span></span><span style=display:flex><span>./node.yml -t node_hosts               <span style=color:#8f5902;font-style:italic># 配置节点 /etc/hosts 记录</span>
</span></span><span style=display:flex><span>./node.yml -t node_resolv              <span style=color:#8f5902;font-style:italic># 配置节点 DNS 解析器 /etc/resolv.conf</span>
</span></span><span style=display:flex><span>./node.yml -t node_firewall            <span style=color:#8f5902;font-style:italic># 配置防火墙 &amp; selinux</span>
</span></span><span style=display:flex><span>./node.yml -t node_ca                  <span style=color:#8f5902;font-style:italic># 配置节点的CA证书</span>
</span></span><span style=display:flex><span>./node.yml -t node_repo                <span style=color:#8f5902;font-style:italic># 配置节点上游软件仓库</span>
</span></span><span style=display:flex><span>./node.yml -t node_pkg                 <span style=color:#8f5902;font-style:italic># 在节点上安装 yum 软件包</span>
</span></span><span style=display:flex><span>./node.yml -t node_uv                  <span style=color:#8f5902;font-style:italic># 配置 uv Python 虚拟环境</span>
</span></span><span style=display:flex><span>./node.yml -t node_feature             <span style=color:#8f5902;font-style:italic># 配置 numa、grub、静态网络等特性</span>
</span></span><span style=display:flex><span>./node.yml -t node_kernel              <span style=color:#8f5902;font-style:italic># 配置操作系统内核模块</span>
</span></span><span style=display:flex><span>./node.yml -t node_tune                <span style=color:#8f5902;font-style:italic># 配置 tuned 调优模板</span>
</span></span><span style=display:flex><span>./node.yml -t node_sysctl              <span style=color:#8f5902;font-style:italic># 设置额外的 sysctl 参数</span>
</span></span><span style=display:flex><span>./node.yml -t node_profile             <span style=color:#8f5902;font-style:italic># 配置节点环境变量：/etc/profile.d/node.sh</span>
</span></span><span style=display:flex><span>./node.yml -t node_ulimit              <span style=color:#8f5902;font-style:italic># 配置节点资源限制</span>
</span></span><span style=display:flex><span>./node.yml -t node_data                <span style=color:#8f5902;font-style:italic># 配置节点首要数据目录</span>
</span></span><span style=display:flex><span>./node.yml -t node_admin               <span style=color:#8f5902;font-style:italic># 配置管理员用户和ssh密钥</span>
</span></span><span style=display:flex><span>./node.yml -t node_timezone            <span style=color:#8f5902;font-style:italic># 配置节点时区</span>
</span></span><span style=display:flex><span>./node.yml -t node_ntp                 <span style=color:#8f5902;font-style:italic># 配置节点 NTP 服务器/客户端</span>
</span></span><span style=display:flex><span>./node.yml -t node_crontab             <span style=color:#8f5902;font-style:italic># 添加/覆盖 crontab 定时任务</span>
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-f85610345b10eb3ebcd5b3f4d040bbb5>4 - 管理预案</h1><div class=lead>Node 集群管理 SOP：创建，销毁，扩容，缩容，节点故障与磁盘故障的处理。</div><p>下面是 Node 模块中常用的管理操作：</p><ul><li><a href=#%E6%B7%BB%E5%8A%A0%E8%8A%82%E7%82%B9>添加节点</a></li><li><a href=#%E7%A7%BB%E9%99%A4%E8%8A%82%E7%82%B9>移除节点</a></li><li><a href=#%E5%88%9B%E5%BB%BA%E7%AE%A1%E7%90%86%E5%91%98>创建管理员</a></li><li><a href=#%E7%BB%91%E5%AE%9Avip>绑定VIP</a></li><li><a href=#%E6%B7%BB%E5%8A%A0%E8%8A%82%E7%82%B9%E7%9B%91%E6%8E%A7>添加节点监控</a></li><li><a href=#%E5%85%B6%E4%BB%96%E5%B8%B8%E8%A7%81%E4%BB%BB%E5%8A%A1>其他常见任务</a></li></ul><p>更多问题请参考 <a href=/docs/node/faq/>FAQ：NODE</a></p><hr><h2 id=添加节点>添加节点</h2><p>要将节点添加到 Pigsty，您需要对该节点具有无密码的 ssh/sudo 访问权限。</p><p>您也可以选择一次性添加一个集群，或使用通配符匹配配置清单中要加入 Pigsty 的节点。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># ./node.yml -l &lt;cls|ip|group&gt;        # 向 Pigsty 中添加节点的实际剧本</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># bin/node-add &lt;selector|ip...&gt;       # 向 Pigsty 中添加节点</span>
</span></span><span style=display:flex><span>bin/node-add node-test                <span style=color:#8f5902;font-style:italic># 初始化节点集群 &#39;node-test&#39;</span>
</span></span><span style=display:flex><span>bin/node-add 10.10.10.10              <span style=color:#8f5902;font-style:italic># 初始化节点 &#39;10.10.10.10&#39;</span>
</span></span></code></pre></div><p><strong>示例：将 PG 集群 <code>pg-test</code> 的三个节点纳入 Pigsty 管理</strong></p><link rel=stylesheet href=/css/asciinema-player.css><script src=/js/asciinema-player.min.js></script><div id=asciinema-7069a298b7596d78fe1fbba39686127a class="asciinema-container td-max-width-on-larger-screens" style="margin:1em 0"></div><script>(function(){var n,s="asciinema-7069a298b7596d78fe1fbba39686127a",o="/demo/node-add.cast",e="auto",i=null;function a(){var e=document.documentElement.getAttribute("data-bs-theme");return e==="dark"?"solarized-dark":e==="light"?"solarized-light":window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"solarized-dark":"solarized-light"}function r(){return e==="auto"?a():e}function t(){var e,t=document.getElementById(s);t.innerHTML="",e={theme:r(),speed:"1.2",startAt:0,fit:"width"},e.autoPlay=!0,e.loop=!0,e.markers=[[4,"执行"]],i=AsciinemaPlayer.create(o,t,e)}t(),e==="auto"&&(n=new MutationObserver(function(e){e.forEach(function(e){e.attributeName==="data-bs-theme"&&t()})}),n.observe(document.documentElement,{attributes:!0}),window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",function(){var e=document.documentElement.getAttribute("data-bs-theme");(!e||e==="auto")&&t()}))})()</script><hr><h2 id=移除节点>移除节点</h2><p>要从 Pigsty 中移除一个节点，您可以使用以下命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># ./node-rm.yml -l &lt;cls|ip|group&gt;    # 从 pigsty 中移除节点的实际剧本</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># bin/node-rm &lt;cls|ip|selector&gt; ...  # 从 pigsty 中移除节点</span>
</span></span><span style=display:flex><span>bin/node-rm node-test                <span style=color:#8f5902;font-style:italic># 移除节点集群 &#39;node-test&#39;</span>
</span></span><span style=display:flex><span>bin/node-rm 10.10.10.10              <span style=color:#8f5902;font-style:italic># 移除节点 &#39;10.10.10.10&#39;</span>
</span></span></code></pre></div><p>您也可以选择一次性移除一个集群，或使用通配符匹配配置清单中要从 Pigsty 移除的节点。</p><div id=asciinema-1a9591d6a68c0eefe3529d84981541a6 class="asciinema-container td-max-width-on-larger-screens" style="margin:1em 0"></div><script>(function(){var n,s="asciinema-1a9591d6a68c0eefe3529d84981541a6",o="/demo/node-rm.cast",e="auto",i=null;function a(){var e=document.documentElement.getAttribute("data-bs-theme");return e==="dark"?"solarized-dark":e==="light"?"solarized-light":window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"solarized-dark":"solarized-light"}function r(){return e==="auto"?a():e}function t(){var e,t=document.getElementById(s);t.innerHTML="",e={theme:r(),speed:"1.2",startAt:0,fit:"width"},e.autoPlay=!0,e.loop=!0,i=AsciinemaPlayer.create(o,t,e)}t(),e==="auto"&&(n=new MutationObserver(function(e){e.forEach(function(e){e.attributeName==="data-bs-theme"&&t()})}),n.observe(document.documentElement,{attributes:!0}),window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",function(){var e=document.documentElement.getAttribute("data-bs-theme");(!e||e==="auto")&&t()}))})()</script><hr><h2 id=创建管理员>创建管理员</h2><p>如果当前用户没有对节点的无密码 ssh/sudo 访问权限，您可以使用另一个管理员用户来初始化该节点：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>node.yml -t node_admin -k -K -e <span style=color:#000>ansible_user</span><span style=color:#ce5c00;font-weight:700>=</span>&lt;另一个管理员&gt;   <span style=color:#8f5902;font-style:italic># 为另一个管理员输入 ssh/sudo 密码以完成此任务</span>
</span></span></code></pre></div><hr><h2 id=绑定vip>绑定VIP</h2><p>您可以在节点集群上绑定一个可选的 L2 VIP，使用 <a href=/docs/node/param#vip_enabled><code>vip_enabled</code></a> 参数。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>proxy</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>10.10.10.29</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>nodename</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>proxy-1 }  </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># 您可以显式指定初始的 VIP 角色：MASTER / BACKUP</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>10.10.10.30</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span>{<span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>nodename: proxy-2 }   # , vip_role</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>master }</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span><span style=color:#204a87;font-weight:700>vars</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>node_cluster</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>proxy</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>vip_enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>vip_vrid</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>128</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>vip_address</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>10.10.10.99</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>    </span><span style=color:#204a87;font-weight:700>vip_interface</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>eth1</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./node.yml -l proxy -t node_vip     <span style=color:#8f5902;font-style:italic># 首次启用 VIP</span>
</span></span><span style=display:flex><span>./node.yml -l proxy -t vip_refresh  <span style=color:#8f5902;font-style:italic># 刷新 vip 配置（例如指定 master）</span>
</span></span></code></pre></div><hr><h2 id=添加节点监控>添加节点监控</h2><p>如果您想要在现有节点上添加或重新配置监控，可以使用以下命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./node.yml -t node_exporter,node_register  <span style=color:#8f5902;font-style:italic># 配置监控并注册</span>
</span></span><span style=display:flex><span>./node.yml -t vector                        <span style=color:#8f5902;font-style:italic># 配置日志收集</span>
</span></span></code></pre></div><hr><h2 id=其他常见任务>其他常见任务</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Play</span>
</span></span><span style=display:flex><span>./node.yml -t node                            <span style=color:#8f5902;font-style:italic># 完成节点主体初始化（haproxy，监控除外）</span>
</span></span><span style=display:flex><span>./node.yml -t haproxy                         <span style=color:#8f5902;font-style:italic># 在节点上设置 haproxy</span>
</span></span><span style=display:flex><span>./node.yml -t monitor                         <span style=color:#8f5902;font-style:italic># 配置节点监控：node_exporter &amp; vector</span>
</span></span><span style=display:flex><span>./node.yml -t node_vip                        <span style=color:#8f5902;font-style:italic># 为没启用过 VIP 的集群安装、配置、启用 L2 VIP</span>
</span></span><span style=display:flex><span>./node.yml -t vip_config,vip_reload           <span style=color:#8f5902;font-style:italic># 刷新节点 L2 VIP 配置</span>
</span></span><span style=display:flex><span>./node.yml -t haproxy_config,haproxy_reload   <span style=color:#8f5902;font-style:italic># 刷新节点上的服务定义</span>
</span></span><span style=display:flex><span>./node.yml -t node_register                   <span style=color:#8f5902;font-style:italic># 重新将节点注册到 VictoriaMetrics 中</span>
</span></span><span style=display:flex><span>./node.yml -t register_nginx                  <span style=color:#8f5902;font-style:italic># 重新将节点 haproxy 管控界面注册到 Nginx 中</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Task</span>
</span></span><span style=display:flex><span>./node.yml -t node-id        <span style=color:#8f5902;font-style:italic># 生成节点身份标识</span>
</span></span><span style=display:flex><span>./node.yml -t node_name      <span style=color:#8f5902;font-style:italic># 设置主机名</span>
</span></span><span style=display:flex><span>./node.yml -t node_hosts     <span style=color:#8f5902;font-style:italic># 配置节点 /etc/hosts 记录</span>
</span></span><span style=display:flex><span>./node.yml -t node_resolv    <span style=color:#8f5902;font-style:italic># 配置节点 DNS 解析器 /etc/resolv.conf</span>
</span></span><span style=display:flex><span>./node.yml -t node_firewall  <span style=color:#8f5902;font-style:italic># 配置防火墙 &amp; selinux</span>
</span></span><span style=display:flex><span>./node.yml -t node_ca        <span style=color:#8f5902;font-style:italic># 配置节点的CA证书</span>
</span></span><span style=display:flex><span>./node.yml -t node_repo      <span style=color:#8f5902;font-style:italic># 配置节点上游软件仓库</span>
</span></span><span style=display:flex><span>./node.yml -t node_pkg       <span style=color:#8f5902;font-style:italic># 在节点上安装 yum 软件包</span>
</span></span><span style=display:flex><span>./node.yml -t node_feature   <span style=color:#8f5902;font-style:italic># 配置 numa、grub、静态网络等特性</span>
</span></span><span style=display:flex><span>./node.yml -t node_kernel    <span style=color:#8f5902;font-style:italic># 配置操作系统内核模块</span>
</span></span><span style=display:flex><span>./node.yml -t node_tune      <span style=color:#8f5902;font-style:italic># 配置 tuned 调优模板</span>
</span></span><span style=display:flex><span>./node.yml -t node_sysctl    <span style=color:#8f5902;font-style:italic># 设置额外的 sysctl 参数</span>
</span></span><span style=display:flex><span>./node.yml -t node_profile   <span style=color:#8f5902;font-style:italic># 配置节点环境变量：/etc/profile.d/node.sh</span>
</span></span><span style=display:flex><span>./node.yml -t node_ulimit    <span style=color:#8f5902;font-style:italic># 配置节点资源限制</span>
</span></span><span style=display:flex><span>./node.yml -t node_data      <span style=color:#8f5902;font-style:italic># 配置节点首要数据目录</span>
</span></span><span style=display:flex><span>./node.yml -t node_admin     <span style=color:#8f5902;font-style:italic># 配置管理员用户和ssh密钥</span>
</span></span><span style=display:flex><span>./node.yml -t node_timezone  <span style=color:#8f5902;font-style:italic># 配置节点时区</span>
</span></span><span style=display:flex><span>./node.yml -t node_ntp       <span style=color:#8f5902;font-style:italic># 配置节点 NTP 服务器/客户端</span>
</span></span><span style=display:flex><span>./node.yml -t node_crontab   <span style=color:#8f5902;font-style:italic># 添加/覆盖 crontab 定时任务</span>
</span></span><span style=display:flex><span>./node.yml -t node_vip       <span style=color:#8f5902;font-style:italic># 为节点集群设置可选的 L2 VIP</span>
</span></span></code></pre></div><hr><h2 id=管理-haproxy-密码>管理 HAProxy 密码</h2><p><a href=/docs/node/param#haproxy_admin_password><code>haproxy_admin_password</code></a>（默认 <code>pigsty</code>）用于 HAProxy 管理界面认证，渲染到 <code>/etc/haproxy/haproxy.cfg</code> 中。</p><p>修改密码后，使用以下命令刷新配置（热重载，不中断连接）：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./node.yml -l &lt;目标节点&gt; -t haproxy_config,haproxy_reload
</span></span></code></pre></div><hr><h2 id=防火墙管理>防火墙管理</h2><p>Pigsty 使用 <a href=/docs/node/param#node_firewall_mode><code>node_firewall_mode</code></a> 控制防火墙行为。
在 RHEL/Rocky 系统上使用 <strong>firewalld</strong>，在 Debian/Ubuntu 系统上使用 <strong>ufw</strong>。</p><p>自 v4.1 起，默认情况下这个参数是 <code>zone</code>：Pigsty 会在各发行版上统一启用系统防火墙，并应用“内网信任、公网最小暴露”的规则。
在 <code>zone</code> 模式下，内网流量不受防火墙限制，但非内网网段只能访问特定端口。
如果你希望完全自行维护防火墙，请将该参数设置为 <code>none</code>（Pigsty 不再管理防火墙状态与规则）。
如果您在云服务器上部署并对互联网开放，这一点尤为重要。</p><p>我们建议你只开放必要的端口，例如：22 (SSH), 80/443 (HTTP/HTTPS)，这三个是必要的端口，谨慎对外开放 5432 数据库端口。</p><h3 id=应用防火墙规则>应用防火墙规则</h3><p>默认就是 <code>zone</code>。如果之前设置过 <code>none/off</code>，可以改回 <code>zone</code> 以重新启用并应用分区规则：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_mode</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000>zone             </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># 启用防火墙并配置区域规则</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_intranet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>               </span><span style=color:#8f5902;font-style:italic># 信任这些网段（完全放行）</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>10.0.0.0</span><span style=color:#000>/8</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>192.168.0.0</span><span style=color:#000>/16</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>172.16.0.0</span><span style=color:#000>/12</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_public_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>            </span><span style=color:#8f5902;font-style:italic># 对公网开放这些端口</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>22</span><span style=color:#f8f8f8>                                </span><span style=color:#8f5902;font-style:italic># SSH</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>80</span><span style=color:#f8f8f8>                                </span><span style=color:#8f5902;font-style:italic># HTTP</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>443</span><span style=color:#f8f8f8>                               </span><span style=color:#8f5902;font-style:italic># HTTPS</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><p>然后执行：<code>./node.yml -l &lt;目标> -t node_firewall</code></p><h3 id=开放更多端口>开放更多端口</h3><p>要开放更多端口，将其添加到 <code>node_firewall_public_port</code> 并重新执行：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_public_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#0000cf;font-weight:700>22</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>80</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>443</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>5432</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8> </span><span style=color:#0000cf;font-weight:700>6379</span><span style=color:#000;font-weight:700>]</span><span style=color:#f8f8f8>  </span><span style=color:#8f5902;font-style:italic># 添加 PostgreSQL 和 Redis 端口</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./node.yml -l &lt;目标&gt; -t node_firewall
</span></span></code></pre></div><h3 id=配置内网网段>配置内网网段</h3><p><code>node_firewall_intranet</code> 中的网段会被添加到 <strong>trusted 区域</strong>，拥有完全访问权限：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_intranet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>10.0.0.0</span><span style=color:#000>/8          </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># A 类私网</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>192.168.0.0</span><span style=color:#000>/16      </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># C 类私网</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>172.16.0.0</span><span style=color:#000>/12       </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># B 类私网</span><span style=color:#f8f8f8>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8>  </span>- <span style=color:#0000cf;font-weight:700>100.64.0.0</span><span style=color:#000>/10       </span><span style=color:#f8f8f8> </span><span style=color:#8f5902;font-style:italic># 运营商级 NAT（如需要）</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><h3 id=删除规则手动>删除规则（手动）</h3><blockquote><p><strong>重要提示</strong>：Pigsty 的防火墙管理是<strong>只增不删</strong>的。从配置中移除条目并重新执行
<strong>不会</strong>删除已存在的规则。您需要手动删除规则。</p></blockquote><ul class="nav nav-tabs" id=tabs-2 role=tablist><li class=nav-item><button class="nav-link active" id=tabs-02-00-tab data-bs-toggle=tab data-bs-target=#tabs-02-00 role=tab data-td-tp-persist="el (firewalld)" aria-controls=tabs-02-00 aria-selected=true>
EL (firewalld)</button></li><li class=nav-item><button class=nav-link id=tabs-02-01-tab data-bs-toggle=tab data-bs-target=#tabs-02-01 role=tab data-td-tp-persist="debian (ufw)" aria-controls=tabs-02-01 aria-selected=false>
Debian (ufw)</button></li></ul><div class=tab-content id=tabs-2-content><div class="tab-body tab-pane fade show active" id=tabs-02-00 role=tabpanel aria-labelled-by=tabs-02-00-tab tabindex=2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 从 public 区域删除指定端口</span>
</span></span><span style=display:flex><span>sudo firewall-cmd --zone<span style=color:#ce5c00;font-weight:700>=</span>public --remove-port<span style=color:#ce5c00;font-weight:700>=</span>5432/tcp
</span></span><span style=display:flex><span>sudo firewall-cmd --runtime-to-permanent
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 从 trusted 区域删除指定网段</span>
</span></span><span style=display:flex><span>sudo firewall-cmd --zone<span style=color:#ce5c00;font-weight:700>=</span>trusted --remove-source<span style=color:#ce5c00;font-weight:700>=</span>10.0.0.0/8
</span></span><span style=display:flex><span>sudo firewall-cmd --runtime-to-permanent
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 查看当前规则</span>
</span></span><span style=display:flex><span>sudo firewall-cmd --zone<span style=color:#ce5c00;font-weight:700>=</span>public --list-ports
</span></span><span style=display:flex><span>sudo firewall-cmd --zone<span style=color:#ce5c00;font-weight:700>=</span>trusted --list-sources
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 重置为初始状态（删除所有自定义规则）</span>
</span></span><span style=display:flex><span>sudo firewall-cmd --complete-reload
</span></span></code></pre></div></div><div class="tab-body tab-pane fade" id=tabs-02-01 role=tabpanel aria-labelled-by=tabs-02-01-tab tabindex=2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 删除指定端口规则</span>
</span></span><span style=display:flex><span>sudo ufw delete allow 5432/tcp
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 删除指定网段规则</span>
</span></span><span style=display:flex><span>sudo ufw delete allow from 10.0.0.0/8
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 查看当前规则（带编号）</span>
</span></span><span style=display:flex><span>sudo ufw status numbered
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 按编号删除规则</span>
</span></span><span style=display:flex><span>sudo ufw delete &lt;规则编号&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 重置为初始状态（删除所有规则，保持 ufw 启用状态）</span>
</span></span><span style=display:flex><span>sudo ufw reset
</span></span></code></pre></div></div></div><h3 id=关闭防火墙>关闭防火墙</h3><p>要完全关闭防火墙，将 <code>node_firewall_mode</code> 设置为 <code>off</code>：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_firewall_mode</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#204a87;font-weight:700>off</span><span style=color:#f8f8f8>    </span><span style=color:#8f5902;font-style:italic># 完全禁用防火墙</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./node.yml -l &lt;目标&gt; -t node_firewall
</span></span></code></pre></div><p>或者手动关闭：</p><ul class="nav nav-tabs" id=tabs-3 role=tablist><li class=nav-item><button class="nav-link active" id=tabs-03-00-tab data-bs-toggle=tab data-bs-target=#tabs-03-00 role=tab data-td-tp-persist="el (firewalld)" aria-controls=tabs-03-00 aria-selected=true>
EL (firewalld)</button></li><li class=nav-item><button class=nav-link id=tabs-03-01-tab data-bs-toggle=tab data-bs-target=#tabs-03-01 role=tab data-td-tp-persist="debian (ufw)" aria-controls=tabs-03-01 aria-selected=false>
Debian (ufw)</button></li></ul><div class=tab-content id=tabs-3-content><div class="tab-body tab-pane fade show active" id=tabs-03-00 role=tabpanel aria-labelled-by=tabs-03-00-tab tabindex=3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl disable --now firewalld
</span></span></code></pre></div></div><div class="tab-body tab-pane fade" id=tabs-03-01 role=tabpanel aria-labelled-by=tabs-03-01-tab tabindex=3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo ufw disable
</span></span></code></pre></div></div></div></div><div class=td-content style=page-break-before:always><h1 id=pg-09468f551281e08aa947b92b9aa4f1a7>5 - 监控告警</h1><div class=lead>如何在 Pigsty 中监控 Node？如何使用 Node 本身的管控面板？有哪些告警规则值得关注？</div><p>Pigsty 中的 NODE 模块提供了 8 个监控面板和完善的告警规则。</p><hr><h2 id=监控面板>监控面板</h2><p>NODE 模块提供 8 个监控仪表板：</p><h3 id=node-overview>NODE Overview</h3><p>展示当前环境所有主机节点的总体情况概览。</p><p><a href=https://demo.pigsty.cc/d/node-overview><img src=/img/dashboard/node-overview.jpg alt=node-overview.jpg></a></p><h3 id=node-cluster>NODE Cluster</h3><p>显示特定主机集群的详细监控数据。</p><p><a href=https://demo.pigsty.cc/d/node-cluster><img src=/img/dashboard/node-cluster.jpg alt=node-cluster.jpg></a></p><h3 id=node-instance>Node Instance</h3><p>呈现单个主机节点的详细监控信息。</p><p><a href=https://demo.pigsty.cc/d/node-instance><img src=/img/dashboard/node-instance.jpg alt=node-instance.jpg></a></p><h3 id=node-alert>NODE Alert</h3><p>集中展示环境中所有主机的告警信息。</p><p><a href=https://demo.pigsty.cc/d/node-alert><img src=/img/dashboard/node-alert.jpg alt=node-alert.jpg></a></p><h3 id=node-vip>NODE VIP</h3><p>监控 L2 虚拟 IP 的详细状态。</p><p><a href=https://demo.pigsty.cc/d/node-vip><img src=/img/dashboard/node-vip.jpg alt=node-vip.jpg></a></p><h3 id=node-haproxy>Node Haproxy</h3><p>追踪 HAProxy 负载均衡器的运行情况。</p><p><a href=https://demo.pigsty.cc/d/node-haproxy><img src=/img/dashboard/node-haproxy.jpg alt=node-haproxy.jpg></a></p><h3 id=node-disk>Node Disk</h3><p>聚焦单盘 I/O 延迟、吞吐与队列深度等存储指标。</p><p><a href=https://demo.pigsty.cc/d/node-disk><img src=/img/panel/node-disk.webp alt=node-disk.webp></a></p><h3 id=node-vector>Node Vector</h3><p>查看 Vector 采集与转发状态，以及日志管道健康度。</p><p><a href=https://demo.pigsty.cc/d/node-vector><img src=/img/dashboard/node-vector.webp alt=node-vector.webp></a></p><hr><h2 id=告警规则>告警规则</h2><p>Pigsty 针对 NODE 实现了以下告警规则：</p><h3 id=可用性告警>可用性告警</h3><table class=full-width><thead><tr><th>规则</th><th style=text-align:center>级别</th><th>说明</th></tr></thead><tbody><tr><td><code>NodeDown</code></td><td style=text-align:center>CRIT</td><td>节点离线</td></tr><tr><td><code>HaproxyDown</code></td><td style=text-align:center>CRIT</td><td>HAProxy 服务离线</td></tr><tr><td><code>VectorDown</code></td><td style=text-align:center>WARN</td><td>日志收集代理离线（Vector）</td></tr><tr><td><code>DockerDown</code></td><td style=text-align:center>WARN</td><td>容器引擎离线</td></tr><tr><td><code>KeepalivedDown</code></td><td style=text-align:center>WARN</td><td>Keepalived 守护进程离线</td></tr></tbody></table><h3 id=cpu-告警>CPU 告警</h3><table class=full-width><thead><tr><th>规则</th><th style=text-align:center>级别</th><th>说明</th></tr></thead><tbody><tr><td><code>NodeCpuHigh</code></td><td style=text-align:center>WARN</td><td>CPU 使用率超过 70%</td></tr></tbody></table><h3 id=调度告警>调度告警</h3><table class=full-width><thead><tr><th>规则</th><th style=text-align:center>级别</th><th>说明</th></tr></thead><tbody><tr><td><code>NodeLoadHigh</code></td><td style=text-align:center>WARN</td><td>标准化负载超过 100%</td></tr></tbody></table><h3 id=内存告警>内存告警</h3><table class=full-width><thead><tr><th>规则</th><th style=text-align:center>级别</th><th>说明</th></tr></thead><tbody><tr><td><code>NodeOutOfMem</code></td><td style=text-align:center>WARN</td><td>可用内存少于 10%</td></tr><tr><td><code>NodeMemSwapped</code></td><td style=text-align:center>WARN</td><td>Swap 使用率超过 1%</td></tr></tbody></table><h3 id=文件系统告警>文件系统告警</h3><table class=full-width><thead><tr><th>规则</th><th style=text-align:center>级别</th><th>说明</th></tr></thead><tbody><tr><td><code>NodeFsSpaceFull</code></td><td style=text-align:center>WARN</td><td>磁盘使用率超过 90%</td></tr><tr><td><code>NodeFsFilesFull</code></td><td style=text-align:center>WARN</td><td>Inode 使用率超过 90%</td></tr><tr><td><code>NodeFdFull</code></td><td style=text-align:center>WARN</td><td>文件描述符使用率超过 90%</td></tr></tbody></table><h3 id=磁盘告警>磁盘告警</h3><table class=full-width><thead><tr><th>规则</th><th style=text-align:center>级别</th><th>说明</th></tr></thead><tbody><tr><td><code>NodeDiskSlow</code></td><td style=text-align:center>INFO</td><td>读写延迟超过 32ms</td></tr></tbody></table><h3 id=网络协议告警>网络协议告警</h3><table class=full-width><thead><tr><th>规则</th><th style=text-align:center>级别</th><th>说明</th></tr></thead><tbody><tr><td><code>NodeTcpErrHigh</code></td><td style=text-align:center>WARN</td><td>TCP 错误率超过 1/分钟</td></tr><tr><td><code>NodeTcpRetransHigh</code></td><td style=text-align:center>INFO</td><td>TCP 重传率超过 1%</td></tr></tbody></table><h3 id=时间同步告警>时间同步告警</h3><table class=full-width><thead><tr><th>规则</th><th style=text-align:center>级别</th><th>说明</th></tr></thead><tbody><tr><td><code>NodeTimeDrift</code></td><td style=text-align:center>WARN</td><td>系统时间未同步</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-21159d62f30ba4efa931b151d5790100>6 - 指标列表</h1><div class=lead>Pigsty NODE 模块提供的完整监控指标列表与释义</div><p><a href=/docs/node><strong><code>NODE</code></strong></a> 模块包含有 727 类可用监控指标。</p><table><thead><tr><th>Metric Name</th><th>Type</th><th>Labels</th><th>Description</th></tr></thead><tbody><tr><td>ALERTS</td><td>Unknown</td><td><code>alertname</code>, <code>ip</code>, <code>level</code>, <code>severity</code>, <code>ins</code>, <code>job</code>, <code>alertstate</code>, <code>category</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>ALERTS_FOR_STATE</td><td>Unknown</td><td><code>alertname</code>, <code>ip</code>, <code>level</code>, <code>severity</code>, <code>ins</code>, <code>job</code>, <code>category</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>deprecated_flags_inuse_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>go_gc_duration_seconds</td><td>summary</td><td><code>quantile</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>A summary of the pause duration of garbage collection cycles.</td></tr><tr><td>go_gc_duration_seconds_count</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>go_gc_duration_seconds_sum</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>go_goroutines</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of goroutines that currently exist.</td></tr><tr><td>go_info</td><td>gauge</td><td><code>version</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Information about the Go environment.</td></tr><tr><td>go_memstats_alloc_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes allocated and still in use.</td></tr><tr><td>go_memstats_alloc_bytes_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes allocated, even if freed.</td></tr><tr><td>go_memstats_buck_hash_sys_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes used by the profiling bucket hash table.</td></tr><tr><td>go_memstats_frees_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of frees.</td></tr><tr><td>go_memstats_gc_sys_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes used for garbage collection system metadata.</td></tr><tr><td>go_memstats_heap_alloc_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of heap bytes allocated and still in use.</td></tr><tr><td>go_memstats_heap_idle_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of heap bytes waiting to be used.</td></tr><tr><td>go_memstats_heap_inuse_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of heap bytes that are in use.</td></tr><tr><td>go_memstats_heap_objects</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of allocated objects.</td></tr><tr><td>go_memstats_heap_released_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of heap bytes released to OS.</td></tr><tr><td>go_memstats_heap_sys_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of heap bytes obtained from system.</td></tr><tr><td>go_memstats_last_gc_time_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of seconds since 1970 of last garbage collection.</td></tr><tr><td>go_memstats_lookups_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of pointer lookups.</td></tr><tr><td>go_memstats_mallocs_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of mallocs.</td></tr><tr><td>go_memstats_mcache_inuse_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes in use by mcache structures.</td></tr><tr><td>go_memstats_mcache_sys_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes used for mcache structures obtained from system.</td></tr><tr><td>go_memstats_mspan_inuse_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes in use by mspan structures.</td></tr><tr><td>go_memstats_mspan_sys_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes used for mspan structures obtained from system.</td></tr><tr><td>go_memstats_next_gc_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of heap bytes when next garbage collection will take place.</td></tr><tr><td>go_memstats_other_sys_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes used for other system allocations.</td></tr><tr><td>go_memstats_stack_inuse_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes in use by the stack allocator.</td></tr><tr><td>go_memstats_stack_sys_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes obtained from system for stack allocator.</td></tr><tr><td>go_memstats_sys_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes obtained from system.</td></tr><tr><td>go_threads</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of OS threads created.</td></tr><tr><td>haproxy:cls:usage</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>haproxy:ins:uptime</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>haproxy:ins:usage</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>haproxy_backend_active_servers</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of active UP servers with a non-zero weight</td></tr><tr><td>haproxy_backend_agg_check_status</td><td>gauge</td><td><code>state</code>, <code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Backend&rsquo;s aggregated gauge of servers&rsquo; state check status</td></tr><tr><td>haproxy_backend_agg_server_check_status</td><td>gauge</td><td><code>state</code>, <code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>[DEPRECATED] Backend&rsquo;s aggregated gauge of servers&rsquo; status</td></tr><tr><td>haproxy_backend_agg_server_status</td><td>gauge</td><td><code>state</code>, <code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Backend&rsquo;s aggregated gauge of servers&rsquo; status</td></tr><tr><td>haproxy_backend_backup_servers</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of backup UP servers with a non-zero weight</td></tr><tr><td>haproxy_backend_bytes_in_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of request bytes since process started</td></tr><tr><td>haproxy_backend_bytes_out_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of response bytes since process started</td></tr><tr><td>haproxy_backend_check_last_change_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>How long ago the last server state changed, in seconds</td></tr><tr><td>haproxy_backend_check_up_down_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed checks causing UP to DOWN server transitions, per server/backend, since the worker process started</td></tr><tr><td>haproxy_backend_client_aborts_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of requests or connections aborted by the client since the worker process started</td></tr><tr><td>haproxy_backend_connect_time_average_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Avg. connect time for last 1024 successful connections.</td></tr><tr><td>haproxy_backend_connection_attempts_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of outgoing connection attempts on this backend/server since the worker process started</td></tr><tr><td>haproxy_backend_connection_errors_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed connections to server since the worker process started</td></tr><tr><td>haproxy_backend_connection_reuses_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of reused connection on this backend/server since the worker process started</td></tr><tr><td>haproxy_backend_current_queue</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of current queued connections</td></tr><tr><td>haproxy_backend_current_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of current sessions on the frontend, backend or server</td></tr><tr><td>haproxy_backend_downtime_seconds_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total time spent in DOWN state, for server or backend</td></tr><tr><td>haproxy_backend_failed_header_rewriting_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed HTTP header rewrites since the worker process started</td></tr><tr><td>haproxy_backend_http_cache_hits_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP requests not found in the cache on this frontend/backend since the worker process started</td></tr><tr><td>haproxy_backend_http_cache_lookups_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP requests looked up in the cache on this frontend/backend since the worker process started</td></tr><tr><td>haproxy_backend_http_comp_bytes_bypassed_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes that bypassed HTTP compression for this object since the worker process started (CPU/memory/bandwidth limitation)</td></tr><tr><td>haproxy_backend_http_comp_bytes_in_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes submitted to the HTTP compressor for this object since the worker process started</td></tr><tr><td>haproxy_backend_http_comp_bytes_out_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes emitted by the HTTP compressor for this object since the worker process started</td></tr><tr><td>haproxy_backend_http_comp_responses_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP responses that were compressed for this object since the worker process started</td></tr><tr><td>haproxy_backend_http_requests_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP requests processed by this object since the worker process started</td></tr><tr><td>haproxy_backend_http_responses_total</td><td>counter</td><td><code>ip</code>, <code>proxy</code>, <code>ins</code>, <code>code</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Total number of HTTP responses with status 100-199 returned by this object since the worker process started</td></tr><tr><td>haproxy_backend_internal_errors_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of internal errors since process started</td></tr><tr><td>haproxy_backend_last_session_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>How long ago some traffic was seen on this object on this worker process, in seconds</td></tr><tr><td>haproxy_backend_limit_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Frontend/listener/server&rsquo;s maxconn, backend&rsquo;s fullconn</td></tr><tr><td>haproxy_backend_loadbalanced_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of requests routed by load balancing since the worker process started (ignores queue pop and stickiness)</td></tr><tr><td>haproxy_backend_max_connect_time_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Maximum observed time spent waiting for a connection to complete</td></tr><tr><td>haproxy_backend_max_queue</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of queued connections encountered since process started</td></tr><tr><td>haproxy_backend_max_queue_time_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Maximum observed time spent in the queue</td></tr><tr><td>haproxy_backend_max_response_time_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Maximum observed time spent waiting for a server response</td></tr><tr><td>haproxy_backend_max_session_rate</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of sessions per second observed since the worker process started</td></tr><tr><td>haproxy_backend_max_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of current sessions encountered since process started</td></tr><tr><td>haproxy_backend_max_total_time_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Maximum observed total request+response time (request+queue+connect+response+processing)</td></tr><tr><td>haproxy_backend_queue_time_average_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Avg. queue time for last 1024 successful connections.</td></tr><tr><td>haproxy_backend_redispatch_warnings_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of server redispatches due to connection failures since the worker process started</td></tr><tr><td>haproxy_backend_requests_denied_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of denied requests since process started</td></tr><tr><td>haproxy_backend_response_errors_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of invalid responses since the worker process started</td></tr><tr><td>haproxy_backend_response_time_average_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Avg. response time for last 1024 successful connections.</td></tr><tr><td>haproxy_backend_responses_denied_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of denied responses since process started</td></tr><tr><td>haproxy_backend_retry_warnings_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of server connection retries since the worker process started</td></tr><tr><td>haproxy_backend_server_aborts_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of requests or connections aborted by the server since the worker process started</td></tr><tr><td>haproxy_backend_sessions_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of sessions since process started</td></tr><tr><td>haproxy_backend_status</td><td>gauge</td><td><code>state</code>, <code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current status of the service, per state label value.</td></tr><tr><td>haproxy_backend_total_time_average_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Avg. total time for last 1024 successful connections.</td></tr><tr><td>haproxy_backend_uweight</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Server&rsquo;s user weight, or sum of active servers&rsquo; user weights for a backend</td></tr><tr><td>haproxy_backend_weight</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Server&rsquo;s effective weight, or sum of active servers&rsquo; effective weights for a backend</td></tr><tr><td>haproxy_frontend_bytes_in_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of request bytes since process started</td></tr><tr><td>haproxy_frontend_bytes_out_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of response bytes since process started</td></tr><tr><td>haproxy_frontend_connections_rate_max</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of connections per second observed since the worker process started</td></tr><tr><td>haproxy_frontend_connections_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of new connections accepted on this frontend since the worker process started</td></tr><tr><td>haproxy_frontend_current_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of current sessions on the frontend, backend or server</td></tr><tr><td>haproxy_frontend_denied_connections_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of incoming connections blocked on a listener/frontend by a tcp-request connection rule since the worker process started</td></tr><tr><td>haproxy_frontend_denied_sessions_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of incoming sessions blocked on a listener/frontend by a tcp-request connection rule since the worker process started</td></tr><tr><td>haproxy_frontend_failed_header_rewriting_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed HTTP header rewrites since the worker process started</td></tr><tr><td>haproxy_frontend_http_cache_hits_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP requests not found in the cache on this frontend/backend since the worker process started</td></tr><tr><td>haproxy_frontend_http_cache_lookups_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP requests looked up in the cache on this frontend/backend since the worker process started</td></tr><tr><td>haproxy_frontend_http_comp_bytes_bypassed_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes that bypassed HTTP compression for this object since the worker process started (CPU/memory/bandwidth limitation)</td></tr><tr><td>haproxy_frontend_http_comp_bytes_in_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes submitted to the HTTP compressor for this object since the worker process started</td></tr><tr><td>haproxy_frontend_http_comp_bytes_out_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes emitted by the HTTP compressor for this object since the worker process started</td></tr><tr><td>haproxy_frontend_http_comp_responses_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP responses that were compressed for this object since the worker process started</td></tr><tr><td>haproxy_frontend_http_requests_rate_max</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of http requests observed since the worker process started</td></tr><tr><td>haproxy_frontend_http_requests_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP requests processed by this object since the worker process started</td></tr><tr><td>haproxy_frontend_http_responses_total</td><td>counter</td><td><code>ip</code>, <code>proxy</code>, <code>ins</code>, <code>code</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Total number of HTTP responses with status 100-199 returned by this object since the worker process started</td></tr><tr><td>haproxy_frontend_intercepted_requests_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of HTTP requests intercepted on the frontend (redirects/stats/services) since the worker process started</td></tr><tr><td>haproxy_frontend_internal_errors_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of internal errors since process started</td></tr><tr><td>haproxy_frontend_limit_session_rate</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Limit on the number of sessions accepted in a second (frontend only, &lsquo;rate-limit sessions&rsquo; setting)</td></tr><tr><td>haproxy_frontend_limit_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Frontend/listener/server&rsquo;s maxconn, backend&rsquo;s fullconn</td></tr><tr><td>haproxy_frontend_max_session_rate</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of sessions per second observed since the worker process started</td></tr><tr><td>haproxy_frontend_max_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of current sessions encountered since process started</td></tr><tr><td>haproxy_frontend_request_errors_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of invalid requests since process started</td></tr><tr><td>haproxy_frontend_requests_denied_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of denied requests since process started</td></tr><tr><td>haproxy_frontend_responses_denied_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of denied responses since process started</td></tr><tr><td>haproxy_frontend_sessions_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of sessions since process started</td></tr><tr><td>haproxy_frontend_status</td><td>gauge</td><td><code>state</code>, <code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current status of the service, per state label value.</td></tr><tr><td>haproxy_process_active_peers</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of verified active peers connections on the current worker process</td></tr><tr><td>haproxy_process_build_info</td><td>gauge</td><td><code>version</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Build info</td></tr><tr><td>haproxy_process_busy_polling_enabled</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>1 if busy-polling is currently in use on the worker process, otherwise zero (config.busy-polling)</td></tr><tr><td>haproxy_process_bytes_out_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes emitted by current worker process over the last second</td></tr><tr><td>haproxy_process_bytes_out_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes emitted by current worker process since started</td></tr><tr><td>haproxy_process_connected_peers</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of peers having passed the connection step on the current worker process</td></tr><tr><td>haproxy_process_connections_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of connections on this worker process since started</td></tr><tr><td>haproxy_process_current_backend_ssl_key_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of SSL keys created on backends in this worker process over the last second</td></tr><tr><td>haproxy_process_current_connection_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of front connections created on this worker process over the last second</td></tr><tr><td>haproxy_process_current_connections</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of connections on this worker process</td></tr><tr><td>haproxy_process_current_frontend_ssl_key_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of SSL keys created on frontends in this worker process over the last second</td></tr><tr><td>haproxy_process_current_run_queue</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of active tasks+tasklets in the current worker process</td></tr><tr><td>haproxy_process_current_session_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of sessions created on this worker process over the last second</td></tr><tr><td>haproxy_process_current_ssl_connections</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of SSL endpoints on this worker process (front+back)</td></tr><tr><td>haproxy_process_current_ssl_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of SSL connections created on this worker process over the last second</td></tr><tr><td>haproxy_process_current_tasks</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of tasks in the current worker process (active + sleeping)</td></tr><tr><td>haproxy_process_current_zlib_memory</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Amount of memory currently used by HTTP compression on the current worker process (in bytes)</td></tr><tr><td>haproxy_process_dropped_logs_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of dropped logs for current worker process since started</td></tr><tr><td>haproxy_process_failed_resolutions</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed DNS resolutions in current worker process since started</td></tr><tr><td>haproxy_process_frontend_ssl_reuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Percent of frontend SSL connections which did not require a new key</td></tr><tr><td>haproxy_process_hard_max_connections</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit on the number of per-process connections (imposed by Memmax_MB or Ulimit-n)</td></tr><tr><td>haproxy_process_http_comp_bytes_in_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes submitted to the HTTP compressor in this worker process over the last second</td></tr><tr><td>haproxy_process_http_comp_bytes_out_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of bytes emitted by the HTTP compressor in this worker process over the last second</td></tr><tr><td>haproxy_process_idle_time_percent</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Percentage of last second spent waiting in the current worker thread</td></tr><tr><td>haproxy_process_jobs</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of active jobs on the current worker process (frontend connections, master connections, listeners)</td></tr><tr><td>haproxy_process_limit_connection_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit for ConnRate (global.maxconnrate)</td></tr><tr><td>haproxy_process_limit_http_comp</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Limit of CompressBpsOut beyond which HTTP compression is automatically disabled</td></tr><tr><td>haproxy_process_limit_session_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit for SessRate (global.maxsessrate)</td></tr><tr><td>haproxy_process_limit_ssl_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit for SslRate (global.maxsslrate)</td></tr><tr><td>haproxy_process_listeners</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of active listeners on the current worker process</td></tr><tr><td>haproxy_process_max_backend_ssl_key_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest SslBackendKeyRate reached on this worker process since started (in SSL keys per second)</td></tr><tr><td>haproxy_process_max_connection_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest ConnRate reached on this worker process since started (in connections per second)</td></tr><tr><td>haproxy_process_max_connections</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit on the number of per-process connections (configured or imposed by Ulimit-n)</td></tr><tr><td>haproxy_process_max_fds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit on the number of per-process file descriptors</td></tr><tr><td>haproxy_process_max_frontend_ssl_key_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest SslFrontendKeyRate reached on this worker process since started (in SSL keys per second)</td></tr><tr><td>haproxy_process_max_memory_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Worker process&rsquo;s hard limit on memory usage in byes (-m on command line)</td></tr><tr><td>haproxy_process_max_pipes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit on the number of pipes for splicing, 0=unlimited</td></tr><tr><td>haproxy_process_max_session_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest SessRate reached on this worker process since started (in sessions per second)</td></tr><tr><td>haproxy_process_max_sockets</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit on the number of per-process sockets</td></tr><tr><td>haproxy_process_max_ssl_connections</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Hard limit on the number of per-process SSL endpoints (front+back), 0=unlimited</td></tr><tr><td>haproxy_process_max_ssl_rate</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Highest SslRate reached on this worker process since started (in connections per second)</td></tr><tr><td>haproxy_process_max_zlib_memory</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Limit on the amount of memory used by HTTP compression above which it is automatically disabled (in bytes, see global.maxzlibmem)</td></tr><tr><td>haproxy_process_nbproc</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of started worker processes (historical, always 1)</td></tr><tr><td>haproxy_process_nbthread</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of started threads (global.nbthread)</td></tr><tr><td>haproxy_process_pipes_free_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of allocated and available pipes in this worker process</td></tr><tr><td>haproxy_process_pipes_used_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of pipes in use in this worker process</td></tr><tr><td>haproxy_process_pool_allocated_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Amount of memory allocated in pools (in bytes)</td></tr><tr><td>haproxy_process_pool_failures_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of failed pool allocations since this worker was started</td></tr><tr><td>haproxy_process_pool_used_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Amount of pool memory currently used (in bytes)</td></tr><tr><td>haproxy_process_recv_logs_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of log messages received by log-forwarding listeners on this worker process since started</td></tr><tr><td>haproxy_process_relative_process_id</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Relative worker process number (1)</td></tr><tr><td>haproxy_process_requests_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of requests on this worker process since started</td></tr><tr><td>haproxy_process_spliced_bytes_out_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of bytes emitted by current worker process through a kernel pipe since started</td></tr><tr><td>haproxy_process_ssl_cache_lookups_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of SSL session ID lookups in the SSL session cache on this worker since started</td></tr><tr><td>haproxy_process_ssl_cache_misses_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of SSL session ID lookups that didn&rsquo;t find a session in the SSL session cache on this worker since started</td></tr><tr><td>haproxy_process_ssl_connections_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of SSL endpoints on this worker process since started (front+back)</td></tr><tr><td>haproxy_process_start_time_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Start time in seconds</td></tr><tr><td>haproxy_process_stopping</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>1 if the worker process is currently stopping, otherwise zero</td></tr><tr><td>haproxy_process_unstoppable_jobs</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of unstoppable jobs on the current worker process (master connections)</td></tr><tr><td>haproxy_process_uptime_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>How long ago this worker process was started (seconds)</td></tr><tr><td>haproxy_server_bytes_in_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of request bytes since process started</td></tr><tr><td>haproxy_server_bytes_out_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of response bytes since process started</td></tr><tr><td>haproxy_server_check_code</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>layer5-7 code, if available of the last health check.</td></tr><tr><td>haproxy_server_check_duration_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total duration of the latest server health check, in seconds.</td></tr><tr><td>haproxy_server_check_failures_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed individual health checks per server/backend, since the worker process started</td></tr><tr><td>haproxy_server_check_last_change_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>How long ago the last server state changed, in seconds</td></tr><tr><td>haproxy_server_check_status</td><td>gauge</td><td><code>state</code>, <code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Status of last health check, per state label value.</td></tr><tr><td>haproxy_server_check_up_down_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed checks causing UP to DOWN server transitions, per server/backend, since the worker process started</td></tr><tr><td>haproxy_server_client_aborts_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of requests or connections aborted by the client since the worker process started</td></tr><tr><td>haproxy_server_connect_time_average_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Avg. connect time for last 1024 successful connections.</td></tr><tr><td>haproxy_server_connection_attempts_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of outgoing connection attempts on this backend/server since the worker process started</td></tr><tr><td>haproxy_server_connection_errors_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed connections to server since the worker process started</td></tr><tr><td>haproxy_server_connection_reuses_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of reused connection on this backend/server since the worker process started</td></tr><tr><td>haproxy_server_current_queue</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Number of current queued connections</td></tr><tr><td>haproxy_server_current_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Number of current sessions on the frontend, backend or server</td></tr><tr><td>haproxy_server_current_throttle</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Throttling ratio applied to a server&rsquo;s maxconn and weight during the slowstart period (0 to 100%)</td></tr><tr><td>haproxy_server_downtime_seconds_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total time spent in DOWN state, for server or backend</td></tr><tr><td>haproxy_server_failed_header_rewriting_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed HTTP header rewrites since the worker process started</td></tr><tr><td>haproxy_server_idle_connections_current</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Current number of idle connections available for reuse on this server</td></tr><tr><td>haproxy_server_idle_connections_limit</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Limit on the number of available idle connections on this server (server &lsquo;pool_max_conn&rsquo; directive)</td></tr><tr><td>haproxy_server_internal_errors_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of internal errors since process started</td></tr><tr><td>haproxy_server_last_session_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>How long ago some traffic was seen on this object on this worker process, in seconds</td></tr><tr><td>haproxy_server_limit_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Frontend/listener/server&rsquo;s maxconn, backend&rsquo;s fullconn</td></tr><tr><td>haproxy_server_loadbalanced_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of requests routed by load balancing since the worker process started (ignores queue pop and stickiness)</td></tr><tr><td>haproxy_server_max_connect_time_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Maximum observed time spent waiting for a connection to complete</td></tr><tr><td>haproxy_server_max_queue</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of queued connections encountered since process started</td></tr><tr><td>haproxy_server_max_queue_time_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Maximum observed time spent in the queue</td></tr><tr><td>haproxy_server_max_response_time_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Maximum observed time spent waiting for a server response</td></tr><tr><td>haproxy_server_max_session_rate</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of sessions per second observed since the worker process started</td></tr><tr><td>haproxy_server_max_sessions</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Highest value of current sessions encountered since process started</td></tr><tr><td>haproxy_server_max_total_time_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Maximum observed total request+response time (request+queue+connect+response+processing)</td></tr><tr><td>haproxy_server_need_connections_current</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Estimated needed number of connections</td></tr><tr><td>haproxy_server_queue_limit</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Limit on the number of connections in queue, for servers only (maxqueue argument)</td></tr><tr><td>haproxy_server_queue_time_average_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Avg. queue time for last 1024 successful connections.</td></tr><tr><td>haproxy_server_redispatch_warnings_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of server redispatches due to connection failures since the worker process started</td></tr><tr><td>haproxy_server_response_errors_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of invalid responses since the worker process started</td></tr><tr><td>haproxy_server_response_time_average_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Avg. response time for last 1024 successful connections.</td></tr><tr><td>haproxy_server_responses_denied_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of denied responses since process started</td></tr><tr><td>haproxy_server_retry_warnings_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of server connection retries since the worker process started</td></tr><tr><td>haproxy_server_safe_idle_connections_current</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Current number of safe idle connections</td></tr><tr><td>haproxy_server_server_aborts_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of requests or connections aborted by the server since the worker process started</td></tr><tr><td>haproxy_server_sessions_total</td><td>counter</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Total number of sessions since process started</td></tr><tr><td>haproxy_server_status</td><td>gauge</td><td><code>state</code>, <code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Current status of the service, per state label value.</td></tr><tr><td>haproxy_server_total_time_average_seconds</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Avg. total time for last 1024 successful connections.</td></tr><tr><td>haproxy_server_unsafe_idle_connections_current</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Current number of unsafe idle connections</td></tr><tr><td>haproxy_server_used_connections_current</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Current number of connections in use</td></tr><tr><td>haproxy_server_uweight</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Server&rsquo;s user weight, or sum of active servers&rsquo; user weights for a backend</td></tr><tr><td>haproxy_server_weight</td><td>gauge</td><td><code>proxy</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>server</code>, <code>ip</code>, <code>cls</code></td><td>Server&rsquo;s effective weight, or sum of active servers&rsquo; effective weights for a backend</td></tr><tr><td>haproxy_up</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>inflight_requests</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>route</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>Current number of inflight requests.</td></tr><tr><td>jaeger_tracer_baggage_restrictions_updates_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>result</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_baggage_truncations_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_baggage_updates_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>result</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_finished_spans_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>sampled</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_reporter_queue_length</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of spans in the reporter queue</td></tr><tr><td>jaeger_tracer_reporter_spans_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>result</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_sampler_queries_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>result</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_sampler_updates_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>result</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_span_context_decoding_errors_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_started_spans_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>sampled</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_throttled_debug_spans_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_throttler_updates_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>result</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>jaeger_tracer_traces_total</td><td>Unknown</td><td><code>state</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>sampled</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_experimental_features_in_use_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_internal_log_messages_total</td><td>Unknown</td><td><code>level</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_log_flushes_bucket</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>le</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_log_flushes_count</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_log_flushes_sum</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_log_messages_total</td><td>Unknown</td><td><code>level</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_logql_querystats_duplicates_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_logql_querystats_ingester_sent_lines_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_querier_index_cache_corruptions_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_querier_index_cache_encode_errors_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_querier_index_cache_gets_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_querier_index_cache_hits_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>loki_querier_index_cache_puts_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>net_conntrack_dialer_conn_attempted_total</td><td>counter</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>dialer_name</code></td><td>Total number of connections attempted by the given dialer a given name.</td></tr><tr><td>net_conntrack_dialer_conn_closed_total</td><td>counter</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>dialer_name</code></td><td>Total number of connections closed which originated from the dialer of a given name.</td></tr><tr><td>net_conntrack_dialer_conn_established_total</td><td>counter</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>dialer_name</code></td><td>Total number of connections successfully established by the given dialer a given name.</td></tr><tr><td>net_conntrack_dialer_conn_failed_total</td><td>counter</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>reason</code>, <code>instance</code>, <code>cls</code>, <code>dialer_name</code></td><td>Total number of connections failed to dial by the dialer a given name.</td></tr><tr><td>node:cls:avail_bytes</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:cpu_count</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:cpu_usage</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:cpu_usage_15m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:cpu_usage_1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:cpu_usage_5m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_io_bytes_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_iops_1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_mreads_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_mreads_ratio1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_mwrites_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_mwrites_ratio1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_read_bytes_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_reads_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_write_bytes_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:disk_writes_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:free_bytes</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:mem_usage</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:network_io_bytes_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:network_rx_bytes_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:network_rx_pps1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:network_tx_bytes_rate1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:network_tx_pps1m</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:size_bytes</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:space_usage</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:space_usage_max</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:stdload1</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:stdload15</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:stdload5</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cls:time_drift_max</td><td>Unknown</td><td><code>job</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:idle_time_irate1m</td><td>Unknown</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:sched_timeslices_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:sched_wait_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:time_irate1m</td><td>Unknown</td><td><code>ip</code>, <code>mode</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:total_time_irate1m</td><td>Unknown</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:usage</td><td>Unknown</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:usage_avg15m</td><td>Unknown</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:usage_avg1m</td><td>Unknown</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:cpu:usage_avg5m</td><td>Unknown</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_avg_queue_size</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_io_batch_1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_io_bytes_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_io_rt_1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_io_time_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_iops_1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_mreads_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_mreads_ratio1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_mwrites_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_mwrites_ratio1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_read_batch_1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_read_bytes_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_read_rt_1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_read_time_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_reads_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_util_1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_write_batch_1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_write_bytes_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_write_rt_1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_write_time_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:disk_writes_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:network_io_bytes_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:network_rx_bytes_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:network_rx_pps1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:network_tx_bytes_rate1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:dev:network_tx_pps1m</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:env:avail_bytes</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:cpu_count</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:cpu_usage</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:cpu_usage_15m</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:cpu_usage_1m</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:cpu_usage_5m</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:device_space_usage_max</td><td>Unknown</td><td><code>device</code>, <code>mountpoint</code>, <code>job</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:env:free_bytes</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:mem_avail</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:mem_total</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:mem_usage</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:size_bytes</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:space_usage</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:stdload1</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:stdload15</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:env:stdload5</td><td>Unknown</td><td><code>job</code></td><td>N/A</td></tr><tr><td>node:fs:avail_bytes</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:free_bytes</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:inode_free</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:inode_total</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:inode_usage</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:inode_used</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:size_bytes</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:space_deriv1h</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:space_exhaust</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:space_predict_1d</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:fs:space_usage</td><td>Unknown</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>N/A</td></tr><tr><td>node:ins</td><td>Unknown</td><td><code>id</code>, <code>ip</code>, <code>ins</code>, <code>job</code>, <code>nodename</code>, <code>instance</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:avail_bytes</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:cpu_count</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:cpu_usage</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:cpu_usage_15m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:cpu_usage_1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:cpu_usage_5m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:ctx_switch_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_io_bytes_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_iops_1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_mreads_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_mreads_ratio1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_mwrites_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_mwrites_ratio1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_read_bytes_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_reads_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_write_bytes_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:disk_writes_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:fd_alloc_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:fd_usage</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:forks_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:free_bytes</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:inode_usage</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:interrupt_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:mem_avail</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:mem_commit_ratio</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:mem_kernel</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:mem_rss</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:mem_usage</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:network_io_bytes_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:network_rx_bytes_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:network_rx_pps1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:network_tx_bytes_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:network_tx_pps1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:pagefault_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:pagein_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:pageout_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:pgmajfault_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:sched_wait_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:size_bytes</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:space_usage_max</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:stdload1</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:stdload15</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:stdload5</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:swap_usage</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:swapin_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:swapout_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_active_opens_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_dropped_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_error</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_error_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_insegs_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_outsegs_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_overflow_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_passive_opens_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_retrans_ratio1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_retranssegs_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:tcp_segs_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:time_drift</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:udp_in_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:udp_out_rate1m</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node:ins:uptime</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node_arp_entries</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>ARP entries by device</td></tr><tr><td>node_boot_time_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Node boot time, in unixtime.</td></tr><tr><td>node_context_switches_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of context switches.</td></tr><tr><td>node_cooling_device_cur_state</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>type</code>, <code>ip</code>, <code>cls</code></td><td>Current throttle state of the cooling device</td></tr><tr><td>node_cooling_device_max_state</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>type</code>, <code>ip</code>, <code>cls</code></td><td>Maximum throttle state of the cooling device</td></tr><tr><td>node_cpu_guest_seconds_total</td><td>counter</td><td><code>ip</code>, <code>mode</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>Seconds the CPUs spent in guests (VMs) for each mode.</td></tr><tr><td>node_cpu_seconds_total</td><td>counter</td><td><code>ip</code>, <code>mode</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>Seconds the CPUs spent in each mode.</td></tr><tr><td>node_disk_discard_time_seconds_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>This is the total number of seconds spent by all discards.</td></tr><tr><td>node_disk_discarded_sectors_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of sectors discarded successfully.</td></tr><tr><td>node_disk_discards_completed_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of discards completed successfully.</td></tr><tr><td>node_disk_discards_merged_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of discards merged.</td></tr><tr><td>node_disk_filesystem_info</td><td>gauge</td><td><code>ip</code>, <code>usage</code>, <code>version</code>, <code>device</code>, <code>uuid</code>, <code>ins</code>, <code>type</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Info about disk filesystem.</td></tr><tr><td>node_disk_info</td><td>gauge</td><td><code>minor</code>, <code>ip</code>, <code>major</code>, <code>revision</code>, <code>device</code>, <code>model</code>, <code>serial</code>, <code>path</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Info of /sys/block/&lt;block_device>.</td></tr><tr><td>node_disk_io_now</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The number of I/Os currently in progress.</td></tr><tr><td>node_disk_io_time_seconds_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Total seconds spent doing I/Os.</td></tr><tr><td>node_disk_io_time_weighted_seconds_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The weighted # of seconds spent doing I/Os.</td></tr><tr><td>node_disk_read_bytes_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of bytes read successfully.</td></tr><tr><td>node_disk_read_time_seconds_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of seconds spent by all reads.</td></tr><tr><td>node_disk_reads_completed_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of reads completed successfully.</td></tr><tr><td>node_disk_reads_merged_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of reads merged.</td></tr><tr><td>node_disk_write_time_seconds_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>This is the total number of seconds spent by all writes.</td></tr><tr><td>node_disk_writes_completed_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of writes completed successfully.</td></tr><tr><td>node_disk_writes_merged_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The number of writes merged.</td></tr><tr><td>node_disk_written_bytes_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>The total number of bytes written successfully.</td></tr><tr><td>node_dmi_info</td><td>gauge</td><td><code>bios_vendor</code>, <code>ip</code>, <code>product_family</code>, <code>product_version</code>, <code>product_uuid</code>, <code>system_vendor</code>, <code>bios_version</code>, <code>ins</code>, <code>bios_date</code>, <code>cls</code>, <code>job</code>, <code>product_name</code>, <code>instance</code>, <code>chassis_version</code>, <code>chassis_vendor</code>, <code>product_serial</code></td><td>A metric with a constant &lsquo;1&rsquo; value labeled by bios_date, bios_release, bios_vendor, bios_version, board_asset_tag, board_name, board_serial, board_vendor, board_version, chassis_asset_tag, chassis_serial, chassis_vendor, chassis_version, product_family, product_name, product_serial, product_sku, product_uuid, product_version, system_vendor if provided by DMI.</td></tr><tr><td>node_entropy_available_bits</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Bits of available entropy.</td></tr><tr><td>node_entropy_pool_size_bits</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Bits of entropy pool.</td></tr><tr><td>node_exporter_build_info</td><td>gauge</td><td><code>ip</code>, <code>version</code>, <code>revision</code>, <code>goversion</code>, <code>branch</code>, <code>ins</code>, <code>goarch</code>, <code>job</code>, <code>tags</code>, <code>instance</code>, <code>cls</code>, <code>goos</code></td><td>A metric with a constant &lsquo;1&rsquo; value labeled by version, revision, branch, goversion from which node_exporter was built, and the goos and goarch for the build.</td></tr><tr><td>node_filefd_allocated</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>File descriptor statistics: allocated.</td></tr><tr><td>node_filefd_maximum</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>File descriptor statistics: maximum.</td></tr><tr><td>node_filesystem_avail_bytes</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>Filesystem space available to non-root users in bytes.</td></tr><tr><td>node_filesystem_device_error</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>Whether an error occurred while getting statistics for the given device.</td></tr><tr><td>node_filesystem_files</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>Filesystem total file nodes.</td></tr><tr><td>node_filesystem_files_free</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>Filesystem total free file nodes.</td></tr><tr><td>node_filesystem_free_bytes</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>Filesystem free space in bytes.</td></tr><tr><td>node_filesystem_readonly</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>Filesystem read-only status.</td></tr><tr><td>node_filesystem_size_bytes</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>mountpoint</code>, <code>ins</code>, <code>cls</code>, <code>job</code>, <code>instance</code>, <code>fstype</code></td><td>Filesystem size in bytes.</td></tr><tr><td>node_forks_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of forks.</td></tr><tr><td>node_hwmon_chip_names</td><td>gauge</td><td><code>chip_name</code>, <code>ip</code>, <code>ins</code>, <code>chip</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Annotation metric for human-readable chip names</td></tr><tr><td>node_hwmon_energy_joule_total</td><td>counter</td><td><code>sensor</code>, <code>ip</code>, <code>ins</code>, <code>chip</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Hardware monitor for joules used so far (input)</td></tr><tr><td>node_hwmon_sensor_label</td><td>gauge</td><td><code>sensor</code>, <code>ip</code>, <code>ins</code>, <code>chip</code>, <code>job</code>, <code>label</code>, <code>instance</code>, <code>cls</code></td><td>Label for given chip and sensor</td></tr><tr><td>node_intr_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of interrupts serviced.</td></tr><tr><td>node_ipvs_connections_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The total number of connections made.</td></tr><tr><td>node_ipvs_incoming_bytes_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The total amount of incoming data.</td></tr><tr><td>node_ipvs_incoming_packets_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The total number of incoming packets.</td></tr><tr><td>node_ipvs_outgoing_bytes_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The total amount of outgoing data.</td></tr><tr><td>node_ipvs_outgoing_packets_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The total number of outgoing packets.</td></tr><tr><td>node_load1</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>1m load average.</td></tr><tr><td>node_load15</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>15m load average.</td></tr><tr><td>node_load5</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>5m load average.</td></tr><tr><td>node_memory_Active_anon_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Active_anon_bytes.</td></tr><tr><td>node_memory_Active_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Active_bytes.</td></tr><tr><td>node_memory_Active_file_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Active_file_bytes.</td></tr><tr><td>node_memory_AnonHugePages_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field AnonHugePages_bytes.</td></tr><tr><td>node_memory_AnonPages_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field AnonPages_bytes.</td></tr><tr><td>node_memory_Bounce_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Bounce_bytes.</td></tr><tr><td>node_memory_Buffers_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Buffers_bytes.</td></tr><tr><td>node_memory_Cached_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Cached_bytes.</td></tr><tr><td>node_memory_CommitLimit_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field CommitLimit_bytes.</td></tr><tr><td>node_memory_Committed_AS_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Committed_AS_bytes.</td></tr><tr><td>node_memory_DirectMap1G_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field DirectMap1G_bytes.</td></tr><tr><td>node_memory_DirectMap2M_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field DirectMap2M_bytes.</td></tr><tr><td>node_memory_DirectMap4k_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field DirectMap4k_bytes.</td></tr><tr><td>node_memory_Dirty_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Dirty_bytes.</td></tr><tr><td>node_memory_FileHugePages_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field FileHugePages_bytes.</td></tr><tr><td>node_memory_FilePmdMapped_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field FilePmdMapped_bytes.</td></tr><tr><td>node_memory_HardwareCorrupted_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field HardwareCorrupted_bytes.</td></tr><tr><td>node_memory_HugePages_Free</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field HugePages_Free.</td></tr><tr><td>node_memory_HugePages_Rsvd</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field HugePages_Rsvd.</td></tr><tr><td>node_memory_HugePages_Surp</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field HugePages_Surp.</td></tr><tr><td>node_memory_HugePages_Total</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field HugePages_Total.</td></tr><tr><td>node_memory_Hugepagesize_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Hugepagesize_bytes.</td></tr><tr><td>node_memory_Hugetlb_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Hugetlb_bytes.</td></tr><tr><td>node_memory_Inactive_anon_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Inactive_anon_bytes.</td></tr><tr><td>node_memory_Inactive_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Inactive_bytes.</td></tr><tr><td>node_memory_Inactive_file_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Inactive_file_bytes.</td></tr><tr><td>node_memory_KReclaimable_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field KReclaimable_bytes.</td></tr><tr><td>node_memory_KernelStack_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field KernelStack_bytes.</td></tr><tr><td>node_memory_Mapped_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Mapped_bytes.</td></tr><tr><td>node_memory_MemAvailable_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field MemAvailable_bytes.</td></tr><tr><td>node_memory_MemFree_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field MemFree_bytes.</td></tr><tr><td>node_memory_MemTotal_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field MemTotal_bytes.</td></tr><tr><td>node_memory_Mlocked_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Mlocked_bytes.</td></tr><tr><td>node_memory_NFS_Unstable_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field NFS_Unstable_bytes.</td></tr><tr><td>node_memory_PageTables_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field PageTables_bytes.</td></tr><tr><td>node_memory_Percpu_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Percpu_bytes.</td></tr><tr><td>node_memory_SReclaimable_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field SReclaimable_bytes.</td></tr><tr><td>node_memory_SUnreclaim_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field SUnreclaim_bytes.</td></tr><tr><td>node_memory_ShmemHugePages_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field ShmemHugePages_bytes.</td></tr><tr><td>node_memory_ShmemPmdMapped_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field ShmemPmdMapped_bytes.</td></tr><tr><td>node_memory_Shmem_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Shmem_bytes.</td></tr><tr><td>node_memory_Slab_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Slab_bytes.</td></tr><tr><td>node_memory_SwapCached_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field SwapCached_bytes.</td></tr><tr><td>node_memory_SwapFree_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field SwapFree_bytes.</td></tr><tr><td>node_memory_SwapTotal_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field SwapTotal_bytes.</td></tr><tr><td>node_memory_Unevictable_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Unevictable_bytes.</td></tr><tr><td>node_memory_VmallocChunk_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field VmallocChunk_bytes.</td></tr><tr><td>node_memory_VmallocTotal_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field VmallocTotal_bytes.</td></tr><tr><td>node_memory_VmallocUsed_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field VmallocUsed_bytes.</td></tr><tr><td>node_memory_WritebackTmp_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field WritebackTmp_bytes.</td></tr><tr><td>node_memory_Writeback_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Memory information field Writeback_bytes.</td></tr><tr><td>node_netstat_Icmp6_InErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Icmp6InErrors.</td></tr><tr><td>node_netstat_Icmp6_InMsgs</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Icmp6InMsgs.</td></tr><tr><td>node_netstat_Icmp6_OutMsgs</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Icmp6OutMsgs.</td></tr><tr><td>node_netstat_Icmp_InErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic IcmpInErrors.</td></tr><tr><td>node_netstat_Icmp_InMsgs</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic IcmpInMsgs.</td></tr><tr><td>node_netstat_Icmp_OutMsgs</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic IcmpOutMsgs.</td></tr><tr><td>node_netstat_Ip6_InOctets</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Ip6InOctets.</td></tr><tr><td>node_netstat_Ip6_OutOctets</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Ip6OutOctets.</td></tr><tr><td>node_netstat_IpExt_InOctets</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic IpExtInOctets.</td></tr><tr><td>node_netstat_IpExt_OutOctets</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic IpExtOutOctets.</td></tr><tr><td>node_netstat_Ip_Forwarding</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic IpForwarding.</td></tr><tr><td>node_netstat_TcpExt_ListenDrops</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpExtListenDrops.</td></tr><tr><td>node_netstat_TcpExt_ListenOverflows</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpExtListenOverflows.</td></tr><tr><td>node_netstat_TcpExt_SyncookiesFailed</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpExtSyncookiesFailed.</td></tr><tr><td>node_netstat_TcpExt_SyncookiesRecv</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpExtSyncookiesRecv.</td></tr><tr><td>node_netstat_TcpExt_SyncookiesSent</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpExtSyncookiesSent.</td></tr><tr><td>node_netstat_TcpExt_TCPSynRetrans</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpExtTCPSynRetrans.</td></tr><tr><td>node_netstat_TcpExt_TCPTimeouts</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpExtTCPTimeouts.</td></tr><tr><td>node_netstat_Tcp_ActiveOpens</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpActiveOpens.</td></tr><tr><td>node_netstat_Tcp_CurrEstab</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpCurrEstab.</td></tr><tr><td>node_netstat_Tcp_InErrs</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpInErrs.</td></tr><tr><td>node_netstat_Tcp_InSegs</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpInSegs.</td></tr><tr><td>node_netstat_Tcp_OutRsts</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpOutRsts.</td></tr><tr><td>node_netstat_Tcp_OutSegs</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpOutSegs.</td></tr><tr><td>node_netstat_Tcp_PassiveOpens</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpPassiveOpens.</td></tr><tr><td>node_netstat_Tcp_RetransSegs</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic TcpRetransSegs.</td></tr><tr><td>node_netstat_Udp6_InDatagrams</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Udp6InDatagrams.</td></tr><tr><td>node_netstat_Udp6_InErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Udp6InErrors.</td></tr><tr><td>node_netstat_Udp6_NoPorts</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Udp6NoPorts.</td></tr><tr><td>node_netstat_Udp6_OutDatagrams</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Udp6OutDatagrams.</td></tr><tr><td>node_netstat_Udp6_RcvbufErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Udp6RcvbufErrors.</td></tr><tr><td>node_netstat_Udp6_SndbufErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic Udp6SndbufErrors.</td></tr><tr><td>node_netstat_UdpLite6_InErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic UdpLite6InErrors.</td></tr><tr><td>node_netstat_UdpLite_InErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic UdpLiteInErrors.</td></tr><tr><td>node_netstat_Udp_InDatagrams</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic UdpInDatagrams.</td></tr><tr><td>node_netstat_Udp_InErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic UdpInErrors.</td></tr><tr><td>node_netstat_Udp_NoPorts</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic UdpNoPorts.</td></tr><tr><td>node_netstat_Udp_OutDatagrams</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic UdpOutDatagrams.</td></tr><tr><td>node_netstat_Udp_RcvbufErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic UdpRcvbufErrors.</td></tr><tr><td>node_netstat_Udp_SndbufErrors</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Statistic UdpSndbufErrors.</td></tr><tr><td>node_network_address_assign_type</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: address_assign_type</td></tr><tr><td>node_network_carrier</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: carrier</td></tr><tr><td>node_network_carrier_changes_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: carrier_changes_total</td></tr><tr><td>node_network_carrier_down_changes_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: carrier_down_changes_total</td></tr><tr><td>node_network_carrier_up_changes_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: carrier_up_changes_total</td></tr><tr><td>node_network_device_id</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: device_id</td></tr><tr><td>node_network_dormant</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: dormant</td></tr><tr><td>node_network_flags</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: flags</td></tr><tr><td>node_network_iface_id</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: iface_id</td></tr><tr><td>node_network_iface_link</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: iface_link</td></tr><tr><td>node_network_iface_link_mode</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: iface_link_mode</td></tr><tr><td>node_network_info</td><td>gauge</td><td><code>broadcast</code>, <code>ip</code>, <code>device</code>, <code>operstate</code>, <code>ins</code>, <code>job</code>, <code>adminstate</code>, <code>duplex</code>, <code>address</code>, <code>instance</code>, <code>cls</code></td><td>Non-numeric data from /sys/class/net/<iface>, value is always 1.</td></tr><tr><td>node_network_mtu_bytes</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: mtu_bytes</td></tr><tr><td>node_network_name_assign_type</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: name_assign_type</td></tr><tr><td>node_network_net_dev_group</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: net_dev_group</td></tr><tr><td>node_network_protocol_type</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: protocol_type</td></tr><tr><td>node_network_receive_bytes_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_bytes.</td></tr><tr><td>node_network_receive_compressed_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_compressed.</td></tr><tr><td>node_network_receive_drop_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_drop.</td></tr><tr><td>node_network_receive_errs_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_errs.</td></tr><tr><td>node_network_receive_fifo_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_fifo.</td></tr><tr><td>node_network_receive_frame_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_frame.</td></tr><tr><td>node_network_receive_multicast_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_multicast.</td></tr><tr><td>node_network_receive_nohandler_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_nohandler.</td></tr><tr><td>node_network_receive_packets_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic receive_packets.</td></tr><tr><td>node_network_speed_bytes</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: speed_bytes</td></tr><tr><td>node_network_transmit_bytes_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic transmit_bytes.</td></tr><tr><td>node_network_transmit_carrier_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic transmit_carrier.</td></tr><tr><td>node_network_transmit_colls_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic transmit_colls.</td></tr><tr><td>node_network_transmit_compressed_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic transmit_compressed.</td></tr><tr><td>node_network_transmit_drop_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic transmit_drop.</td></tr><tr><td>node_network_transmit_errs_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic transmit_errs.</td></tr><tr><td>node_network_transmit_fifo_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic transmit_fifo.</td></tr><tr><td>node_network_transmit_packets_total</td><td>counter</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device statistic transmit_packets.</td></tr><tr><td>node_network_transmit_queue_length</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Network device property: transmit_queue_length</td></tr><tr><td>node_network_up</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Value is 1 if operstate is &lsquo;up&rsquo;, 0 otherwise.</td></tr><tr><td>node_nf_conntrack_entries</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of currently allocated flow entries for connection tracking.</td></tr><tr><td>node_nf_conntrack_entries_limit</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Maximum size of connection tracking table.</td></tr><tr><td>node_nf_conntrack_stat_drop</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of packets dropped due to conntrack failure.</td></tr><tr><td>node_nf_conntrack_stat_early_drop</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of dropped conntrack entries to make room for new ones, if maximum table size was reached.</td></tr><tr><td>node_nf_conntrack_stat_found</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of searched entries which were successful.</td></tr><tr><td>node_nf_conntrack_stat_ignore</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of packets seen which are already connected to a conntrack entry.</td></tr><tr><td>node_nf_conntrack_stat_insert</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of entries inserted into the list.</td></tr><tr><td>node_nf_conntrack_stat_insert_failed</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of entries for which list insertion was attempted but failed.</td></tr><tr><td>node_nf_conntrack_stat_invalid</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of packets seen which can not be tracked.</td></tr><tr><td>node_nf_conntrack_stat_search_restart</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of conntrack table lookups which had to be restarted due to hashtable resizes.</td></tr><tr><td>node_os_info</td><td>gauge</td><td><code>id</code>, <code>ip</code>, <code>version</code>, <code>version_id</code>, <code>ins</code>, <code>instance</code>, <code>job</code>, <code>pretty_name</code>, <code>id_like</code>, <code>cls</code></td><td>A metric with a constant &lsquo;1&rsquo; value labeled by build_id, id, id_like, image_id, image_version, name, pretty_name, variant, variant_id, version, version_codename, version_id.</td></tr><tr><td>node_os_version</td><td>gauge</td><td><code>id</code>, <code>ip</code>, <code>ins</code>, <code>instance</code>, <code>job</code>, <code>id_like</code>, <code>cls</code></td><td>Metric containing the major.minor part of the OS version.</td></tr><tr><td>node_processes_max_processes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of max PIDs limit</td></tr><tr><td>node_processes_max_threads</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Limit of threads in the system</td></tr><tr><td>node_processes_pids</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of PIDs</td></tr><tr><td>node_processes_state</td><td>gauge</td><td><code>state</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of processes in each state.</td></tr><tr><td>node_processes_threads</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Allocated threads in system</td></tr><tr><td>node_processes_threads_state</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>thread_state</code>, <code>ip</code>, <code>cls</code></td><td>Number of threads in each state.</td></tr><tr><td>node_procs_blocked</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of processes blocked waiting for I/O to complete.</td></tr><tr><td>node_procs_running</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of processes in runnable state.</td></tr><tr><td>node_schedstat_running_seconds_total</td><td>counter</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>Number of seconds CPU spent running a process.</td></tr><tr><td>node_schedstat_timeslices_total</td><td>counter</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>Number of timeslices executed by CPU.</td></tr><tr><td>node_schedstat_waiting_seconds_total</td><td>counter</td><td><code>ip</code>, <code>ins</code>, <code>job</code>, <code>cpu</code>, <code>instance</code>, <code>cls</code></td><td>Number of seconds spent by processing waiting for this CPU.</td></tr><tr><td>node_scrape_collector_duration_seconds</td><td>gauge</td><td><code>ip</code>, <code>collector</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>node_exporter: Duration of a collector scrape.</td></tr><tr><td>node_scrape_collector_success</td><td>gauge</td><td><code>ip</code>, <code>collector</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>node_exporter: Whether a collector succeeded.</td></tr><tr><td>node_selinux_enabled</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>SELinux is enabled, 1 is true, 0 is false</td></tr><tr><td>node_sockstat_FRAG6_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of FRAG6 sockets in state inuse.</td></tr><tr><td>node_sockstat_FRAG6_memory</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of FRAG6 sockets in state memory.</td></tr><tr><td>node_sockstat_FRAG_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of FRAG sockets in state inuse.</td></tr><tr><td>node_sockstat_FRAG_memory</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of FRAG sockets in state memory.</td></tr><tr><td>node_sockstat_RAW6_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of RAW6 sockets in state inuse.</td></tr><tr><td>node_sockstat_RAW_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of RAW sockets in state inuse.</td></tr><tr><td>node_sockstat_TCP6_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of TCP6 sockets in state inuse.</td></tr><tr><td>node_sockstat_TCP_alloc</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of TCP sockets in state alloc.</td></tr><tr><td>node_sockstat_TCP_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of TCP sockets in state inuse.</td></tr><tr><td>node_sockstat_TCP_mem</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of TCP sockets in state mem.</td></tr><tr><td>node_sockstat_TCP_mem_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of TCP sockets in state mem_bytes.</td></tr><tr><td>node_sockstat_TCP_orphan</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of TCP sockets in state orphan.</td></tr><tr><td>node_sockstat_TCP_tw</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of TCP sockets in state tw.</td></tr><tr><td>node_sockstat_UDP6_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of UDP6 sockets in state inuse.</td></tr><tr><td>node_sockstat_UDPLITE6_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of UDPLITE6 sockets in state inuse.</td></tr><tr><td>node_sockstat_UDPLITE_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of UDPLITE sockets in state inuse.</td></tr><tr><td>node_sockstat_UDP_inuse</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of UDP sockets in state inuse.</td></tr><tr><td>node_sockstat_UDP_mem</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of UDP sockets in state mem.</td></tr><tr><td>node_sockstat_UDP_mem_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of UDP sockets in state mem_bytes.</td></tr><tr><td>node_sockstat_sockets_used</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of IPv4 sockets in use.</td></tr><tr><td>node_tcp_connection_states</td><td>gauge</td><td><code>state</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of connection states.</td></tr><tr><td>node_textfile_scrape_error</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>1 if there was an error opening or reading a file, 0 otherwise</td></tr><tr><td>node_time_clocksource_available_info</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>clocksource</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Available clocksources read from &lsquo;/sys/devices/system/clocksource&rsquo;.</td></tr><tr><td>node_time_clocksource_current_info</td><td>gauge</td><td><code>ip</code>, <code>device</code>, <code>ins</code>, <code>clocksource</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Current clocksource read from &lsquo;/sys/devices/system/clocksource&rsquo;.</td></tr><tr><td>node_time_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>System time in seconds since epoch (1970).</td></tr><tr><td>node_time_zone_offset_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>time_zone</code>, <code>ip</code>, <code>cls</code></td><td>System time zone offset in seconds.</td></tr><tr><td>node_timex_estimated_error_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Estimated error in seconds.</td></tr><tr><td>node_timex_frequency_adjustment_ratio</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Local clock frequency adjustment.</td></tr><tr><td>node_timex_loop_time_constant</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Phase-locked loop time constant.</td></tr><tr><td>node_timex_maxerror_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Maximum error in seconds.</td></tr><tr><td>node_timex_offset_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Time offset in between local system and reference clock.</td></tr><tr><td>node_timex_pps_calibration_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Pulse per second count of calibration intervals.</td></tr><tr><td>node_timex_pps_error_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Pulse per second count of calibration errors.</td></tr><tr><td>node_timex_pps_frequency_hertz</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Pulse per second frequency.</td></tr><tr><td>node_timex_pps_jitter_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Pulse per second jitter.</td></tr><tr><td>node_timex_pps_jitter_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Pulse per second count of jitter limit exceeded events.</td></tr><tr><td>node_timex_pps_shift_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Pulse per second interval duration.</td></tr><tr><td>node_timex_pps_stability_exceeded_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Pulse per second count of stability limit exceeded events.</td></tr><tr><td>node_timex_pps_stability_hertz</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Pulse per second stability, average of recent frequency changes.</td></tr><tr><td>node_timex_status</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Value of the status array bits.</td></tr><tr><td>node_timex_sync_status</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Is clock synchronized to a reliable server (1 = yes, 0 = no).</td></tr><tr><td>node_timex_tai_offset_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>International Atomic Time (TAI) offset.</td></tr><tr><td>node_timex_tick_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Seconds between clock ticks.</td></tr><tr><td>node_udp_queues</td><td>gauge</td><td><code>ip</code>, <code>queue</code>, <code>ins</code>, <code>job</code>, <code>exported_ip</code>, <code>instance</code>, <code>cls</code></td><td>Number of allocated memory in the kernel for UDP datagrams in bytes.</td></tr><tr><td>node_uname_info</td><td>gauge</td><td><code>ip</code>, <code>sysname</code>, <code>version</code>, <code>domainname</code>, <code>release</code>, <code>ins</code>, <code>job</code>, <code>nodename</code>, <code>instance</code>, <code>cls</code>, <code>machine</code></td><td>Labeled system information as provided by the uname system call.</td></tr><tr><td>node_up</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>node_vmstat_oom_kill</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>/proc/vmstat information field oom_kill.</td></tr><tr><td>node_vmstat_pgfault</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>/proc/vmstat information field pgfault.</td></tr><tr><td>node_vmstat_pgmajfault</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>/proc/vmstat information field pgmajfault.</td></tr><tr><td>node_vmstat_pgpgin</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>/proc/vmstat information field pgpgin.</td></tr><tr><td>node_vmstat_pgpgout</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>/proc/vmstat information field pgpgout.</td></tr><tr><td>node_vmstat_pswpin</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>/proc/vmstat information field pswpin.</td></tr><tr><td>node_vmstat_pswpout</td><td>unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>/proc/vmstat information field pswpout.</td></tr><tr><td>process_cpu_seconds_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total user and system CPU time spent in seconds.</td></tr><tr><td>process_max_fds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Maximum number of open file descriptors.</td></tr><tr><td>process_open_fds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of open file descriptors.</td></tr><tr><td>process_resident_memory_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Resident memory size in bytes.</td></tr><tr><td>process_start_time_seconds</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Start time of the process since unix epoch in seconds.</td></tr><tr><td>process_virtual_memory_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Virtual memory size in bytes.</td></tr><tr><td>process_virtual_memory_max_bytes</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Maximum amount of virtual memory available in bytes.</td></tr><tr><td>prometheus_remote_storage_exemplars_in_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Exemplars in to remote storage, compare to exemplars out for queue managers.</td></tr><tr><td>prometheus_remote_storage_histograms_in_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>HistogramSamples in to remote storage, compare to histograms out for queue managers.</td></tr><tr><td>prometheus_remote_storage_samples_in_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Samples in to remote storage, compare to samples out for queue managers.</td></tr><tr><td>prometheus_remote_storage_string_interner_zero_reference_releases_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The number of times release has been called for strings that are not interned.</td></tr><tr><td>prometheus_sd_azure_failures_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Number of Azure service discovery refresh failures.</td></tr><tr><td>prometheus_sd_consul_rpc_duration_seconds</td><td>summary</td><td><code>ip</code>, <code>call</code>, <code>quantile</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>endpoint</code></td><td>The duration of a Consul RPC call in seconds.</td></tr><tr><td>prometheus_sd_consul_rpc_duration_seconds_count</td><td>Unknown</td><td><code>ip</code>, <code>call</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>endpoint</code></td><td>N/A</td></tr><tr><td>prometheus_sd_consul_rpc_duration_seconds_sum</td><td>Unknown</td><td><code>ip</code>, <code>call</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>endpoint</code></td><td>N/A</td></tr><tr><td>prometheus_sd_consul_rpc_failures_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The number of Consul RPC call failures.</td></tr><tr><td>prometheus_sd_consulagent_rpc_duration_seconds</td><td>summary</td><td><code>ip</code>, <code>call</code>, <code>quantile</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>endpoint</code></td><td>The duration of a Consul Agent RPC call in seconds.</td></tr><tr><td>prometheus_sd_consulagent_rpc_duration_seconds_count</td><td>Unknown</td><td><code>ip</code>, <code>call</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>endpoint</code></td><td>N/A</td></tr><tr><td>prometheus_sd_consulagent_rpc_duration_seconds_sum</td><td>Unknown</td><td><code>ip</code>, <code>call</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code>, <code>endpoint</code></td><td>N/A</td></tr><tr><td>prometheus_sd_consulagent_rpc_failures_total</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>prometheus_sd_dns_lookup_failures_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The number of DNS-SD lookup failures.</td></tr><tr><td>prometheus_sd_dns_lookups_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The number of DNS-SD lookups.</td></tr><tr><td>prometheus_sd_file_read_errors_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The number of File-SD read errors.</td></tr><tr><td>prometheus_sd_file_scan_duration_seconds</td><td>summary</td><td><code>quantile</code>, <code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The duration of the File-SD scan in seconds.</td></tr><tr><td>prometheus_sd_file_scan_duration_seconds_count</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>prometheus_sd_file_scan_duration_seconds_sum</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>prometheus_sd_file_watcher_errors_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The number of File-SD errors caused by filesystem watch failures.</td></tr><tr><td>prometheus_sd_kubernetes_events_total</td><td>counter</td><td><code>ip</code>, <code>event</code>, <code>ins</code>, <code>job</code>, <code>role</code>, <code>instance</code>, <code>cls</code></td><td>The number of Kubernetes events handled.</td></tr><tr><td>prometheus_target_scrape_pool_exceeded_label_limits_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of times scrape pools hit the label limits, during sync or config reload.</td></tr><tr><td>prometheus_target_scrape_pool_exceeded_target_limit_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of times scrape pools hit the target limit, during sync or config reload.</td></tr><tr><td>prometheus_target_scrape_pool_reloads_failed_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of failed scrape pool reloads.</td></tr><tr><td>prometheus_target_scrape_pool_reloads_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of scrape pool reloads.</td></tr><tr><td>prometheus_target_scrape_pools_failed_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of scrape pool creations that failed.</td></tr><tr><td>prometheus_target_scrape_pools_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of scrape pool creation attempts.</td></tr><tr><td>prometheus_target_scrapes_cache_flush_forced_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>How many times a scrape cache was flushed due to getting big while scrapes are failing.</td></tr><tr><td>prometheus_target_scrapes_exceeded_body_size_limit_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of scrapes that hit the body size limit</td></tr><tr><td>prometheus_target_scrapes_exceeded_sample_limit_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of scrapes that hit the sample limit and were rejected.</td></tr><tr><td>prometheus_target_scrapes_exemplar_out_of_order_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of exemplar rejected due to not being out of the expected order.</td></tr><tr><td>prometheus_target_scrapes_sample_duplicate_timestamp_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of samples rejected due to duplicate timestamps but different values.</td></tr><tr><td>prometheus_target_scrapes_sample_out_of_bounds_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of samples rejected due to timestamp falling outside of the time bounds.</td></tr><tr><td>prometheus_target_scrapes_sample_out_of_order_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Total number of samples rejected due to not being out of the expected order.</td></tr><tr><td>prometheus_template_text_expansion_failures_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The total number of template text expansion failures.</td></tr><tr><td>prometheus_template_text_expansions_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The total number of template text expansions.</td></tr><tr><td>prometheus_treecache_watcher_goroutines</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The current number of watcher goroutines.</td></tr><tr><td>prometheus_treecache_zookeeper_failures_total</td><td>counter</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>The total number of ZooKeeper failures.</td></tr><tr><td>promhttp_metric_handler_errors_total</td><td>counter</td><td><code>ip</code>, <code>cause</code>, <code>ins</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Total number of internal errors encountered by the promhttp metric handler.</td></tr><tr><td>promhttp_metric_handler_requests_in_flight</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>Current number of scrapes being served.</td></tr><tr><td>promhttp_metric_handler_requests_total</td><td>counter</td><td><code>ip</code>, <code>ins</code>, <code>code</code>, <code>job</code>, <code>instance</code>, <code>cls</code></td><td>Total number of scrapes by HTTP status code.</td></tr><tr><td>request_duration_seconds_bucket</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>status_code</code>, <code>route</code>, <code>ws</code>, <code>le</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>request_duration_seconds_count</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>status_code</code>, <code>route</code>, <code>ws</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>request_duration_seconds_sum</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>status_code</code>, <code>route</code>, <code>ws</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>request_message_bytes_bucket</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>route</code>, <code>le</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>request_message_bytes_count</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>route</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>request_message_bytes_sum</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>route</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>response_message_bytes_bucket</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>route</code>, <code>le</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>response_message_bytes_count</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>route</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>response_message_bytes_sum</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>route</code>, <code>ip</code>, <code>cls</code>, <code>method</code></td><td>N/A</td></tr><tr><td>scrape_duration_seconds</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>scrape_samples_post_metric_relabeling</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>scrape_samples_scraped</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>scrape_series_added</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr><tr><td>tcp_connections</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>protocol</code>, <code>ip</code>, <code>cls</code></td><td>Current number of accepted TCP connections.</td></tr><tr><td>tcp_connections_limit</td><td>gauge</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>protocol</code>, <code>ip</code>, <code>cls</code></td><td>The max number of TCP connections that can be accepted (0 means no limit).</td></tr><tr><td>up</td><td>Unknown</td><td><code>instance</code>, <code>ins</code>, <code>job</code>, <code>ip</code>, <code>cls</code></td><td>N/A</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-239230a82e0955081c7a4e1b76e4c445>7 - 常见问题</h1><div class=lead>Pigsty NODE 主机节点模块常见问题答疑</div><hr><h2 id=如何配置主机节点上的ntp服务>如何配置主机节点上的NTP服务？</h2><blockquote><p>NTP对于生产环境各项服务非常重要，如果没有配置 NTP，您可以使用公共 NTP 服务，或管理节点上的 Chronyd 作为标准时间。</p></blockquote><p>如果您的节点已经配置了 NTP，可以通过设置 <code>node_ntp_enabled</code> 为 <code>false</code> 来保留现有配置，不进行任何变更。</p><p>否则，如果您有互联网访问权限，可以使用公共 NTP 服务，例如 <code>pool.ntp.org</code>。</p><p>如果您没有互联网访问权限，可以使用以下方式，确保所有环境内的节点与管理节点时间是同步的，或者使用其他内网环境的 NTP 授时服务。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>node_ntp_servers:                 <span style=color:#8f5902;font-style:italic># /etc/chrony.conf 中的 ntp 服务器列表</span>
</span></span><span style=display:flex><span>  - pool cn.pool.ntp.org iburst
</span></span><span style=display:flex><span>  - pool <span style=color:#4e9a06>${</span><span style=color:#000>admin_ip</span><span style=color:#4e9a06>}</span> iburst       <span style=color:#8f5902;font-style:italic># 假设其他节点都没有互联网访问，那么至少与 Admin 节点保持时间同步。</span>
</span></span></code></pre></div><hr><h2 id=如何在节点上强制同步时间>如何在节点上强制同步时间？</h2><p>为了使用 <code>chronyc</code> 来同步时间。您首先需要配置 NTP 服务。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ansible all -b -a <span style=color:#4e9a06>&#39;chronyc -a makestep&#39;</span>     <span style=color:#8f5902;font-style:italic># 同步时间</span>
</span></span></code></pre></div><p>您可以用任何组或主机 IP 地址替换 <code>all</code>，以限制执行范围。</p><hr><h2 id=远程节点无法通过ssh访问怎么办>远程节点无法通过SSH访问怎么办？</h2><p>如果目标机器隐藏在SSH跳板机后面， 或者进行了一些无法直接使用<code>ssh ip</code>访问的自定义操作， 可以使用诸如 <code>ansible_port</code>
或 <code>ansible_host</code> 这一类 <a href=https://docs.ansible.com/ansible/latest/inventory_guide/connection_details.html>Ansible连接参数</a> 来指定各种 SSH 连接信息，如下所示：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pg-test:
</span></span><span style=display:flex><span>  vars: <span style=color:#ce5c00;font-weight:700>{</span> pg_cluster: pg-test <span style=color:#ce5c00;font-weight:700>}</span>
</span></span><span style=display:flex><span>  hosts:
</span></span><span style=display:flex><span>    10.10.10.11: <span style=color:#ce5c00;font-weight:700>{</span>pg_seq: 1, pg_role: primary, ansible_host: node-1 <span style=color:#ce5c00;font-weight:700>}</span>
</span></span><span style=display:flex><span>    10.10.10.12: <span style=color:#ce5c00;font-weight:700>{</span>pg_seq: 2, pg_role: replica, ansible_port: 22223, ansible_user: admin <span style=color:#ce5c00;font-weight:700>}</span>
</span></span><span style=display:flex><span>    10.10.10.13: <span style=color:#ce5c00;font-weight:700>{</span>pg_seq: 3, pg_role: offline, ansible_port: <span style=color:#0000cf;font-weight:700>22224</span> <span style=color:#ce5c00;font-weight:700>}</span>
</span></span></code></pre></div><hr><h2 id=远程节点ssh与sudo需要密码怎么办>远程节点SSH与SUDO需要密码怎么办？</h2><p><strong>执行部署和更改时</strong>，使用的管理员用户<strong>必须</strong>对所有节点拥有<code>ssh</code>和<code>sudo</code>权限。无需密码免密登录。</p><p>您可以在执行剧本时通过 <code>-k|-K</code> 参数传入 ssh 和 sudo 密码，甚至可以通过 <code>-e ansible_user=&lt;another_user></code> 使用另一个用户来运行剧本。</p><p>但是，Pigsty强烈建议为管理员用户配置SSH<strong>无密码登录</strong>以及无密码的<code>sudo</code>。</p><hr><h2 id=如何使用现有管理员创建专用管理员用户>如何使用现有管理员创建专用管理员用户？</h2><p>使用以下命令，使用该节点上现有的管理员用户，创建由 <a href=/docs/node/param#node_admin_username><code>node_admin_username</code></a>
定义的新的标准的管理员用户。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./node.yml -k -K -e <span style=color:#000>ansible_user</span><span style=color:#ce5c00;font-weight:700>=</span>&lt;another_admin&gt; -t node_admin
</span></span></code></pre></div><hr><h2 id=如何使用节点上的haproxy对外暴露服务>如何使用节点上的HAProxy对外暴露服务？</h2><p>您可以在配置中中使用 <a href=/docs/node/param#haproxy_services><code>haproxy_services</code></a>
来暴露服务，并使用 <code>node.yml -t haproxy_config,haproxy_reload</code> 来更新配置。</p><p>以下是使用它暴露MinIO服务的示例：<a href=/docs/minio/config#%E6%9C%8D%E5%8A%A1%E6%8E%A5%E5%85%A5>暴露MinIO服务</a></p><hr><h2 id=为什么我的-etcyumreposd-全没了>为什么我的 <code>/etc/yum.repos.d/*</code> 全没了？</h2><p>Pigsty会在infra节点上构建的本地软件仓库源中包含所有依赖项。而所有普通节点会根据 <a href=/docs/node/param#node_repo_modules><code>node_repo_modules</code></a> 的默认配置 <code>local</code> 来引用并使用 Infra 节点上的本地软件源。</p><p>这一设计从而避免了互联网访问，增强了安装过程的稳定性与可靠性。所有原有的源定义文件会被移动到 <code>/etc/yum.repos.d/backup</code> 目录中，您只要按需复制回来即可。</p><p>如果您想在普通节点安装过程中保留原有的源定义文件，将 <a href=/docs/node/param#node_repo_remove><code>node_repo_remove</code></a> 设置为<code>false</code>即可。</p><p>如果您想在 Infra 节点构建本地源的过程中保留原有的源定义文件，将 <a href=/docs/infra/param#repo_remove><code>repo_remove</code></a> 设置为<code>false</code>即可。</p><hr><h2 id=为什么我的命令行提示符变样了怎么恢复>为什么我的命令行提示符变样了？怎么恢复？</h2><p>Pigsty 使用的 Shell 命令行提示符是由环境变量 <code>PS1</code> 指定，定义在 <code>/etc/profile.d/node.sh</code> 文件中。</p><p>如果您不喜欢，想要修改或恢复原样，可以将这个文件移除，重新登陆即可。</p><hr><h2 id=为什么我的主机名变了>为什么我的主机名变了？</h2><p>在两种情况下，Pigsty 会修改您的节点主机名：</p><ul><li>显式定义了 <a href=/docs/node/param#nodename_overwrite><code>nodename</code></a> 的值（默认为空）</li><li>节点上声明了 <a href=/docs/pgsql><strong><code>PGSQL</code></strong></a> 模块，且启用了 <a href=/docs/node/param#node_id_from_pg><strong><code>node_id_from_pg</code></strong></a> 参数（默认为 <code>true</code>）</li></ul><p>如果您不希望修改主机名，可以在全局/集群/实例层面修改 <a href=/docs/node/param#nodename_overwrite><strong><code>nodename_overwrite</code></strong></a> 参数为 <code>false</code> （默认值为 <code>true</code>）。</p><p>详情请参考 <a href=/docs/node/param#node_id><strong><code>NODE_ID</code></strong></a> 一节。</p><hr><h2 id=腾讯云的-opencloudos-有什么兼容性问题>腾讯云的 OpenCloudOS 有什么兼容性问题？</h2><p>OpenCloudOS 上的 <code>softdog</code> 内核模块不可用，需要从 <code>node_kernel_modules</code> 中移除。在配置文件全局变量中添加以下配置项以覆盖：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>node_kernel_modules</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8> </span><span style=color:#000;font-weight:700>[</span><span style=color:#f8f8f8> </span><span style=color:#000>ip_vs, ip_vs_rr, ip_vs_wrr, ip_vs_sh ]</span><span style=color:#f8f8f8>
</span></span></span></code></pre></div><hr><h2 id=debian-系统有哪些常见问题>Debian 系统有哪些常见问题？</h2><p>在 Debian/Ubuntu 系统上使用 Pigsty 时，可能遇到以下问题：</p><p><strong>本地语言环境缺失</strong></p><p>如果系统提示 locale 相关错误，可以使用以下命令修复：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>localedef -i en_US -f UTF-8 en_US.UTF-8
</span></span></code></pre></div><p><strong>缺少 rsync 工具</strong></p><p>Pigsty 依赖 rsync 进行文件同步，如果系统未安装，可以使用以下命令安装：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>apt-get install rsync
</span></span></code></pre></div></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=邮件 aria-label=邮件><a target=_blank rel=noopener href=mailto:rh@vonng.com aria-label=邮件><i class="fa fa-envelope"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="GitHub - Vonng" aria-label="GitHub - Vonng"><a target=_blank rel=noopener href=https://github.com/Vonng aria-label="GitHub - Vonng"><i class="fab fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="X - Vonng" aria-label="X - Vonng"><a target=_blank rel=noopener href=https://x.com/RonVonng aria-label="X - Vonng"><i class="fab fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="X - Pigsty" aria-label="X - Pigsty"><a target=_blank rel=noopener href=https://x.com/PlGSTY aria-label="X - Pigsty"><i class="fab fa-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="LinkedIn - Vonng" aria-label="LinkedIn - Vonng"><a target=_blank rel=noopener href=https://www.linkedin.com/in/vonng/ aria-label="LinkedIn - Vonng"><i class="fab fa-linkedin"></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=Discord aria-label=Discord><a target=_blank rel=noopener href=https://discord.gg/wDzt5VyWEz aria-label=Discord><i class="fab fa-discord"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Telegram aria-label=Telegram><a target=_blank rel=noopener href=https://t.me/joinchat/gV9zfZraNPM3YjFh aria-label=Telegram><i class="fab fa-telegram"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=微信 aria-label=微信><a target=_blank rel=noopener href=/img/pigsty/pigsty-cc.jpg aria-label=微信><i class="fab fa-weixin"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=论坛 aria-label=论坛><a target=_blank rel=noopener href=https://github.com/orgs/pgsty/discussions aria-label=论坛><i class="fab fa-discourse"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/pgsty/pigsty aria-label=GitHub><i class="fab fa-github"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2018&ndash;2026
<span class=td-footer__authors>Ruohang Feng</span></span><span class=td-footer__all_rights_reserved>保留所有权利</span><span class=ms-2><a href=/docs/about/privacy target=_blank rel=noopener>隐私政策</a></span></div></div></div></footer></div><script src=/js/main.min.d20e761d6aa4d2ace0488e45da0e775a8b17300a8430f32fbcfa016e6c9e6eb6.js integrity="sha256-0g52HWqk0qzgSI5F2g53WosXMAqEMPMvvPoBbmyebrY=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>